import polars as pl
from typing import Dict, List, Tuple
from datetime import datetime, timedelta, date
import pandas as pd
import numpy as np
from collections import defaultdict





class MarketAnalyzer:
    @staticmethod
    def analyze_market_sentiment(sentiment_data: dict, previous_data: dict = None) -> dict:
        """åˆ†æå¸‚åœºæƒ…ç»ªï¼Œæ”¯æŒä¸ä¸Šä¸ªäº¤æ˜“æ—¥å¯¹æ¯”"""
        # è·å–å„ç§æ•°æ®æ¡†
        limit_up_df = sentiment_data.get('limit_up', pl.DataFrame())
        limit_down_df = sentiment_data.get('limit_down', pl.DataFrame())
        market_df = sentiment_data.get('market_overview', pl.DataFrame())
        strong_stocks_df = sentiment_data.get('strong_stocks', pl.DataFrame())
        previous_limit_up_df = sentiment_data.get('previous_limit_up', pl.DataFrame())
        break_limit_up_df = sentiment_data.get('break_limit_up', pl.DataFrame())
        big_deal_df = sentiment_data.get('big_deal', pl.DataFrame())
        
        # é»˜è®¤å€¼
        result = {
            'limit_up_count': 0,
            'limit_down_count': 0,
            'up_count': 0,
            'down_count': 0,
            'flat_count': 0,
            'strong_stocks_count': 0,
            'previous_limit_up_count': 0,
            'break_limit_up_count': 0,
            'big_deal_count': 0,
            'red_ratio': 0,
            'break_ratio': 0,
            'total_amount': 0,
            # æ–°å¢ï¼šä¸ä¸Šä¸ªäº¤æ˜“æ—¥çš„å˜åŒ–
            'changes': {
                'limit_up_change': 0,
                'limit_down_change': 0,
                'red_ratio_change': 0,
                'total_amount_change': 0,
                'total_amount_change_pct': 0
            }
        }
        
        # æ›´æ–°å„ä¸ªè®¡æ•°
        result['limit_up_count'] = limit_up_df.height if not limit_up_df.is_empty() else 0
        result['limit_down_count'] = limit_down_df.height if not limit_down_df.is_empty() else 0
        result['strong_stocks_count'] = strong_stocks_df.height if not strong_stocks_df.is_empty() else 0
        result['previous_limit_up_count'] = previous_limit_up_df.height if not previous_limit_up_df.is_empty() else 0
        result['break_limit_up_count'] = break_limit_up_df.height if not break_limit_up_df.is_empty() else 0
        result['big_deal_count'] = big_deal_df.height if not big_deal_df.is_empty() else 0
        
        # å¦‚æœå¸‚åœºæ¦‚è§ˆæ•°æ®ä¸ºç©ºï¼Œç›´æ¥è¿”å›é»˜è®¤ç»“æœ
        if market_df.is_empty():
            return result
            
        # æ‰¾åˆ°æ¶¨è·Œå¹…åˆ—
        change_col = 'æ¶¨è·Œå¹…'
        if change_col not in market_df.columns:
            # å°è¯•å…¶ä»–å¯èƒ½çš„åˆ—å
            for col in ['change_pct', 'pct_change']:
                if col in market_df.columns:
                    change_col = col
                    break
            else:
                # å¦‚æœæ‰¾ä¸åˆ°æ¶¨è·Œå¹…åˆ—ï¼Œè¿”å›é»˜è®¤ç»“æœ
                return result
        
        try:
            # è®¡ç®—æ¶¨è·Œå®¶æ•°
            up_count = market_df.filter(pl.col(change_col) > 0).height
            down_count = market_df.filter(pl.col(change_col) < 0).height
            total_count = market_df.height
            
            result['up_count'] = up_count
            result['down_count'] = down_count
            result['flat_count'] = total_count - up_count - down_count
            
            # è®¡ç®—çº¢ç›˜ç‡ï¼ˆä¿ç•™ä¸¤ä½å°æ•°ï¼‰
            result['red_ratio'] = round((up_count / total_count * 100), 2) if total_count > 0 else 0.00

            # è®¡ç®—æ¶¨è·Œå¹…åˆ†å¸ƒ
            change_distribution = MarketAnalyzer._calculate_change_distribution(market_df, change_col)
            result['change_distribution'] = change_distribution

            # è®¡ç®—ç‚¸æ¿ç‡ï¼ˆä¿ç•™ä¸¤ä½å°æ•°ï¼‰
            limit_up_count = result['limit_up_count']
            break_count = result['break_limit_up_count']
            result['break_ratio'] = round((break_count / (break_count + limit_up_count) * 100), 2) if (break_count + limit_up_count) > 0 else 0.00

            # æ‰¾åˆ°æˆäº¤é¢åˆ—
            amount_col = 'æˆäº¤é¢'
            if amount_col not in market_df.columns:
                # å°è¯•å…¶ä»–å¯èƒ½çš„åˆ—å
                for col in ['amount', 'trade_amount', 'æˆäº¤é‡‘é¢', 'æ€»å¸‚å€¼']:
                    if col in market_df.columns:
                        amount_col = col
                        break
                else:
                    # å¦‚æœæ‰¾ä¸åˆ°æˆäº¤é¢åˆ—ï¼Œå°è¯•è®¡ç®—æ²ªæ·±ä¸¤å¸‚æ€»æˆäº¤é¢
                    print("æœªæ‰¾åˆ°æˆäº¤é¢åˆ—ï¼Œå°è¯•è·å–æ²ªæ·±ä¸¤å¸‚æˆäº¤é¢")
                    try:
                        # è·å–æ²ªæ·±ä¸¤å¸‚æˆäº¤é¢
                        import akshare as ak
                        from datetime import datetime
                        today = datetime.now().strftime('%Y%m%d')

                        # è·å–æ²ªæ·±ä¸¤å¸‚æˆäº¤é¢
                        sh_amount = 0
                        sz_amount = 0
                        try:
                            # è·å–ä¸Šè¯æŒ‡æ•°æˆäº¤é¢
                            sh_data = ak.index_zh_a_hist(symbol="000001", period="daily", start_date=today, end_date=today)
                            if not sh_data.empty:
                                sh_amount = sh_data['æˆäº¤é¢'].iloc[-1] if 'æˆäº¤é¢' in sh_data.columns else 0
                        except:
                            pass

                        try:
                            # è·å–æ·±è¯æˆæŒ‡æˆäº¤é¢
                            sz_data = ak.index_zh_a_hist(symbol="399001", period="daily", start_date=today, end_date=today)
                            if not sz_data.empty:
                                sz_amount = sz_data['æˆäº¤é¢'].iloc[-1] if 'æˆäº¤é¢' in sz_data.columns else 0
                        except:
                            pass

                        result['total_amount'] = round((sh_amount + sz_amount) / 100000000, 2)  # è½¬æ¢ä¸ºäº¿å…ƒ
                        return result
                    except Exception as e:
                        print(f"è·å–æ²ªæ·±ä¸¤å¸‚æˆäº¤é¢å¤±è´¥: {str(e)}")
                        result['total_amount'] = 0.00
                        return result

            # è®¡ç®—å¸‚åœºé‡èƒ½ï¼ˆä¿ç•™ä¸¤ä½å°æ•°ï¼‰
            result['total_amount'] = round(market_df[amount_col].sum() / 100000000, 2)  # è½¬æ¢ä¸ºäº¿å…ƒ
        
        except Exception as e:
            print(f"åˆ†æå¸‚åœºæƒ…ç»ªæ—¶å‡ºé”™: {str(e)}")

        # è®¡ç®—ä¸ä¸Šä¸ªäº¤æ˜“æ—¥çš„å˜åŒ–
        if previous_data:
            try:
                # æ¶¨åœæ•°å˜åŒ–
                prev_limit_up = previous_data.get('limit_up_count', 0)
                result['changes']['limit_up_change'] = result['limit_up_count'] - prev_limit_up

                # è·Œåœæ•°å˜åŒ–
                prev_limit_down = previous_data.get('limit_down_count', 0)
                result['changes']['limit_down_change'] = result['limit_down_count'] - prev_limit_down

                # çº¢ç›˜ç‡å˜åŒ–
                prev_red_ratio = previous_data.get('red_ratio', 0)
                result['changes']['red_ratio_change'] = round(result['red_ratio'] - prev_red_ratio, 2)

                # æˆäº¤é¢å˜åŒ–
                prev_total_amount = previous_data.get('total_amount', 0)
                result['changes']['total_amount_change'] = round(result['total_amount'] - prev_total_amount, 2)

                # æˆäº¤é¢å˜åŒ–ç™¾åˆ†æ¯”
                if prev_total_amount > 0:
                    result['changes']['total_amount_change_pct'] = round(
                        (result['total_amount'] - prev_total_amount) / prev_total_amount * 100, 2
                    )
                else:
                    result['changes']['total_amount_change_pct'] = 0

            except Exception as e:
                print(f"è®¡ç®—å¸‚åœºæƒ…ç»ªå˜åŒ–æ—¶å‡ºé”™: {str(e)}")

        return result
    
    @staticmethod
    def analyze_market_history(market_data: pl.DataFrame, days: int = 30) -> dict:
        """åˆ†æå†å²å¸‚åœºæ•°æ®"""
        # ç¡®ä¿æ•°æ®æŒ‰æ—¥æœŸæ’åº
        # æ£€æŸ¥åˆ—åå¹¶è¿›è¡Œæ ‡å‡†åŒ–
        column_mapping = {
            'date': 'date',
            'æ—¥æœŸ': 'date',
            'trade_date': 'date',
            'trading_date': 'date',
            'æˆäº¤é¢': 'amount',
            'amount': 'amount',
            'trade_amount': 'amount',
            'æ¶¨è·Œå¹…': 'change_pct',
            'change_pct': 'change_pct',
            'pct_change': 'change_pct'
        }
        
        # é‡å‘½ååˆ—
        renamed_cols = []
        for col in market_data.columns:
            if col in column_mapping:
                renamed_cols.append(pl.col(col).alias(column_mapping[col]))
            else:
                renamed_cols.append(col)
        
        market_data = market_data.select(renamed_cols)
        
        # ç¡®ä¿æ—¥æœŸæ ¼å¼æ­£ç¡®
        if market_data['date'].dtype == pl.Utf8:
            market_data = market_data.with_columns([
                pl.col('date').str.strptime(pl.Date, '%Y-%m-%d').alias('date')
            ])
        
        market_data = market_data.sort('date')
        
        # è·å–æœ€è¿‘Nå¤©çš„æ•°æ®
        recent_data = market_data.tail(days)
        
        # è®¡ç®—æ¯æ—¥çº¢ç›˜ç‡
        daily_stats = []
        for date in recent_data['date'].unique():
            day_data = recent_data.filter(pl.col('date') == date)
            up_count = day_data.filter(pl.col('change_pct') > 0).height
            total_count = day_data.height
            red_ratio = (up_count / total_count * 100) if total_count > 0 else 0
            
            # è®¡ç®—å½“æ—¥æˆäº¤é¢
            total_amount = day_data['amount'].sum() / 100000000  # è½¬æ¢ä¸ºäº¿å…ƒ
            
            daily_stats.append({
                'date': date,
                'red_ratio': red_ratio,
                'total_amount': total_amount
            })
        
        # è®¡ç®—å†å²å¹³å‡å€¼
        avg_red_ratio = sum(d['red_ratio'] for d in daily_stats) / len(daily_stats)
        avg_amount = sum(d['total_amount'] for d in daily_stats) / len(daily_stats)
        
        return {
            'daily_stats': daily_stats,
            'avg_red_ratio': avg_red_ratio,
            'avg_amount': avg_amount
        }
    
    @staticmethod
    def analyze_limit_up_history(limit_up_data: dict, days: int = 30) -> dict:
        """åˆ†æå†å²æ¶¨åœæ•°æ®"""
        # æå–æ¯æ—¥æ¶¨åœå’Œç‚¸æ¿æ•°æ®
        daily_stats = []
        dates = limit_up_data.get('dates', [])
        limit_up_counts = limit_up_data.get('limit_up_counts', [])
        break_counts = limit_up_data.get('break_counts', [])
        
        for i in range(min(days, len(dates))):
            daily_stats.append({
                'date': dates[i],
                'limit_up_count': limit_up_counts[i],
                'break_count': break_counts[i],
                'break_ratio': (break_counts[i] / (break_counts[i] + limit_up_counts[i]) * 100) 
                              if (break_counts[i] + limit_up_counts[i]) > 0 else 0
            })
        
        # è®¡ç®—å†å²å¹³å‡å€¼
        avg_limit_up = sum(d['limit_up_count'] for d in daily_stats) / len(daily_stats)
        avg_break_ratio = sum(d['break_ratio'] for d in daily_stats) / len(daily_stats)
        
        return {
            'daily_stats': daily_stats,
            'avg_limit_up': avg_limit_up,
            'avg_break_ratio': avg_break_ratio
        }
    
    @staticmethod
    def analyze_sectors(sector_data: dict) -> Dict[str, List[dict]]:
        """åˆ†æè¡Œä¸šæ¿å—è¡¨ç°"""
        # ç›´æ¥è¿”å›ä» get_sectors_summary è·å–çš„æ•°æ®
        return sector_data
    
    @staticmethod
    def analyze_concepts(concept_data: dict) -> Dict[str, List[dict]]:
        """åˆ†ææ¦‚å¿µæ¿å—è¡¨ç°"""
        # ç›´æ¥è¿”å›ä» get_concepts_summary è·å–çš„æ•°æ®
        return concept_data
    
    @staticmethod
    def analyze_concept_status(concept_pl, market_states):
        """
        åˆ†ææ¶¨åœæ¿å—å¹¶è¯†åˆ«é¾™å¤´ã€ä¸­å†›ã€åæ’
        """
        
        # åˆ¤æ–­æ¶¨åœç±»å‹çš„å‡½æ•°
        def get_limit_type(code):
            """æ ¹æ®è‚¡ç¥¨ä»£ç åˆ¤æ–­æ¶¨åœç±»å‹"""
            if code.startswith('30') or code.startswith('68'):
                return '20cm'
            elif code.startswith('8') or code.startswith('4') or code.startswith('9'):
                return '30cm'
            else:
                return '10cm'
        
        # å‡è®¾market_statesæœ‰ä»¥ä¸‹åˆ—ï¼šæ—¥æœŸã€ä»£ç ã€åç§°ã€æ¶¨åœã€æˆäº¤é¢ã€æ¢æ‰‹ç‡ã€æ¶¨åœæ—¶é—´
        # è·å–æ¶¨åœè‚¡ç¥¨
        limit_up_data = market_states.filter(
            (pl.col('æ¶¨åœ') == True) & ( ~pl.col('åç§°').str.contains('ST'))
        )

        # åˆå¹¶æ¦‚å¿µä¿¡æ¯
        merged_data = limit_up_data.join(
            concept_pl.select(['ä»£ç ', 'æ¦‚å¿µ']),  # åªé€‰æ‹©ä»£ç å’Œæ¦‚å¿µåˆ—
            on='ä»£ç ',  # åªç”¨ä»£ç join
            how='inner'
        )
        # æ·»åŠ æ¶¨åœç±»å‹
        merged_data = merged_data.with_columns(
            pl.col('ä»£ç ').map_elements(get_limit_type, return_dtype=pl.Utf8).alias('æ¶¨åœç±»å‹')
        )
        
        # æŒ‰æ—¥æœŸå’Œæ¦‚å¿µåˆ†ç»„ï¼Œç»Ÿè®¡æ¶¨åœæ•°
        concept_stats = merged_data.group_by(['æ—¥æœŸ', 'æ¦‚å¿µ']).agg([
            pl.count().alias('æ¶¨åœæ•°')
        ])
        # æ‰¾å‡ºæ›¾ç»æ¶¨åœæ•° > 3 çš„æ¦‚å¿µ
        hot_concept_names = concept_stats.filter(pl.col('æ¶¨åœæ•°') > 3).select('æ¦‚å¿µ').unique()

        # è·å–è¿™äº›æ¦‚å¿µçš„æ‰€æœ‰æ—¥æœŸæ•°æ®
        hot_concept_stocks = merged_data.join(
            hot_concept_names,
            on='æ¦‚å¿µ',
            how='inner'
        )
        # print(hot_concept_stocks)
        # åˆ†ææ¯ä¸ªçƒ­é—¨æ¦‚å¿µçš„é¾™å¤´ã€ä¸­å†›ã€åæ’
        result_list = []
        
        for date in hot_concept_stocks['æ—¥æœŸ'].unique().to_list():
            date_data = hot_concept_stocks.filter(pl.col('æ—¥æœŸ') == date)
            
            for concept in date_data['æ¦‚å¿µ'].unique().to_list():
                concept_data = date_data.filter(pl.col('æ¦‚å¿µ') == concept)
                sorted_stocks = concept_data.sort('æˆäº¤é¢', descending=True).to_pandas()
                total_stocks = len(sorted_stocks)
                
                # é¾™å¤´
                leader_count = max(1, min(2, int(total_stocks * 0.2)))
                leaders = sorted_stocks.head(leader_count)
                
                for _, stock in leaders.iterrows():
                    result_list.append({
                        'æ—¥æœŸ': date,
                        'æ¦‚å¿µ': concept,
                        'è§’è‰²': 'é¾™å¤´',
                        'æ¶¨åœç±»å‹': stock['æ¶¨åœç±»å‹'],
                        'ä»£ç ': stock['ä»£ç '],
                        'åç§°': stock['åç§°'],
                        'æˆäº¤é¢': stock['æˆäº¤é¢'],
                        'æ’å': leaders.index.get_loc(stock.name) + 1
                    })
                
                # ä¸­å†›
                if total_stocks >= 5:
                    middle_start = leader_count
                    middle_count = max(1, int(total_stocks * 0.3))
                    middle_stocks = sorted_stocks.iloc[middle_start:middle_start + middle_count]
                    
                    for i, (_, stock) in enumerate(middle_stocks.iterrows()):
                        result_list.append({
                            'æ—¥æœŸ': date,
                            'æ¦‚å¿µ': concept,
                            'è§’è‰²': 'ä¸­å†›',
                            'æ¶¨åœç±»å‹': stock['æ¶¨åœç±»å‹'],
                            'ä»£ç ': stock['ä»£ç '],
                            'åç§°': stock['åç§°'],
                            'æˆäº¤é¢': stock['æˆäº¤é¢'],
                            'æ’å': middle_start + i + 1
                        })
                
                # åæ’
                rear_start = leader_count + (middle_count if total_stocks >= 5 else 0)
                if rear_start < total_stocks:
                    rear_stocks = sorted_stocks.iloc[rear_start:]
                    
                    for i, (_, stock) in enumerate(rear_stocks.iterrows()):
                        result_list.append({
                            'æ—¥æœŸ': date,
                            'æ¦‚å¿µ': concept,
                            'è§’è‰²': 'åæ’',
                            'æ¶¨åœç±»å‹': stock['æ¶¨åœç±»å‹'],
                            'ä»£ç ': stock['ä»£ç '],
                            'åç§°': stock['åç§°'],
                            'æˆäº¤é¢': stock['æˆäº¤é¢'],
                            'æ’å': rear_start + i + 1
                        })
        
        return pd.DataFrame(result_list)
 
    @staticmethod
    def analyze_limit_up_details(sentiment_data: dict) -> Dict[str, List[dict]]:
        """åˆ†ææ¶¨åœæ¿è¯¦ç»†ä¿¡æ¯"""
        # å¤„ç†å¼ºåŠ¿è‚¡æ•°æ®
        strong_stocks = sentiment_data['strong_stocks']
        if not strong_stocks.is_empty():
            # ç¡®ä¿é€‰æ‹©æ­£ç¡®çš„åˆ—å
            cols_to_select = []
            for col in ['ä»£ç ', 'è‚¡ç¥¨ä»£ç ', 'åç§°', 'è‚¡ç¥¨ç®€ç§°', 'æ¶¨è·Œå¹…', 'æœ€æ–°ä»·', 'æˆäº¤ä»·æ ¼', 'æ¢æ‰‹ç‡']:
                if col in strong_stocks.columns:
                    cols_to_select.append(col)
            strong_stocks = strong_stocks.head(10).select(cols_to_select)
        
        # å¤„ç†æ˜¨æ—¥æ¶¨åœè‚¡æ•°æ®
        previous_limit_up = sentiment_data['previous_limit_up']
        if not previous_limit_up.is_empty():
            cols_to_select = []
            for col in ['ä»£ç ', 'è‚¡ç¥¨ä»£ç ', 'åç§°', 'è‚¡ç¥¨ç®€ç§°', 'æ¶¨è·Œå¹…', 'æœ€æ–°ä»·', 'æˆäº¤ä»·æ ¼', 'æ¢æ‰‹ç‡']:
                if col in previous_limit_up.columns:
                    cols_to_select.append(col)
            previous_limit_up = previous_limit_up.head(10).select(cols_to_select)
        
        # å¤„ç†ç‚¸æ¿è‚¡æ•°æ®
        break_limit_up = sentiment_data['break_limit_up']
        if not break_limit_up.is_empty():
            cols_to_select = []
            for col in ['ä»£ç ', 'è‚¡ç¥¨ä»£ç ', 'åç§°', 'è‚¡ç¥¨ç®€ç§°', 'æ¶¨è·Œå¹…', 'æœ€æ–°ä»·', 'æˆäº¤ä»·æ ¼', 'æ¢æ‰‹ç‡']:
                if col in break_limit_up.columns:
                    cols_to_select.append(col)
            break_limit_up = break_limit_up.head(10).select(cols_to_select)
        
        # å¤„ç†å¤§å•äº¤æ˜“æ•°æ®
        big_deal = sentiment_data['big_deal']
        if not big_deal.is_empty():
            cols_to_select = []
            for col in ['è‚¡ç¥¨ä»£ç ', 'è‚¡ç¥¨ç®€ç§°', 'æˆäº¤ä»·æ ¼', 'æˆäº¤é‡', 'æˆäº¤é¢', 'å¤§å•æ€§è´¨', 'æ¶¨è·Œå¹…', 'æ¶¨è·Œé¢']:
                if col in big_deal.columns:
                    cols_to_select.append(col)
            big_deal = big_deal.head(10).select(cols_to_select)
        
        return {
            'strong_stocks': strong_stocks.to_dicts(),
            'previous_limit_up': previous_limit_up.to_dicts(),
            'break_limit_up': break_limit_up.to_dicts(),
            'big_deal': big_deal.to_dicts()
        }
    
    @staticmethod
    def analyze_model_one_stocks(previous_limit_up_data: pl.DataFrame, stock_details: dict) -> List[dict]:
        """æ¨¡å‹ä¸€é€‰è‚¡ç­–ç•¥"""
        # æ£€æŸ¥æ•°æ®æ¡†æ˜¯å¦ä¸ºç©º
        if previous_limit_up_data.is_empty():
            print("æ˜¨æ—¥æ¶¨åœè‚¡æ•°æ®ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œæ¨¡å‹ä¸€é€‰è‚¡")
            return []
            
        print(f"æ¨¡å‹ä¸€é€‰è‚¡å¼€å§‹ï¼Œå¯ç”¨åˆ—: {previous_limit_up_data.columns}")
        
        # å®šä¹‰ç­›é€‰æ¡ä»¶
        filter_conditions = []
        
        # æ£€æŸ¥æ‰€éœ€åˆ—æ˜¯å¦å­˜åœ¨
        if 'æ¢æ‰‹ç‡' in previous_limit_up_data.columns:
            filter_conditions.append((pl.col('æ¢æ‰‹ç‡') >= 5))
            filter_conditions.append((pl.col('æ¢æ‰‹ç‡') <= 30))
        
        # æ£€æŸ¥å§”æ¯”åˆ—æ˜¯å¦å­˜åœ¨
        if 'å§”æ¯”' in previous_limit_up_data.columns:
            filter_conditions.append((pl.col('å§”æ¯”') > 0))
        
        # æ£€æŸ¥é‡æ¯”åˆ—æ˜¯å¦å­˜åœ¨
        if 'é‡æ¯”' in previous_limit_up_data.columns:
            filter_conditions.append((pl.col('é‡æ¯”') > 1))
        
        # æ£€æŸ¥ä¸»åŠ›å‡€é‡åˆ—æ˜¯å¦å­˜åœ¨
        if 'ä¸»åŠ›å‡€é‡' in previous_limit_up_data.columns:
            filter_conditions.append((pl.col('ä¸»åŠ›å‡€é‡') > 0))
        
        # æ£€æŸ¥åç§°åˆ—æ˜¯å¦å­˜åœ¨
        name_col = None
        for col in ['åç§°', 'è‚¡ç¥¨ç®€ç§°']:
            if col in previous_limit_up_data.columns:
                name_col = col
                filter_conditions.append((~pl.col(name_col).str.contains('ST')))
                break
        
        # æ£€æŸ¥ä»£ç åˆ—æ˜¯å¦å­˜åœ¨
        code_col = None
        for col in ['ä»£ç ', 'è‚¡ç¥¨ä»£ç ']:
            if col in previous_limit_up_data.columns:
                code_col = col
                filter_conditions.append((~pl.col(code_col).str.contains('^688|^300|^301')))
                break
        
        # å¦‚æœæ²¡æœ‰ä»£ç æˆ–åç§°åˆ—ï¼Œæ— æ³•ç»§ç»­
        if code_col is None:
            print("æ•°æ®ä¸­æ²¡æœ‰å¯ç”¨çš„è‚¡ç¥¨ä»£ç åˆ—")
            return []
        
        # å¦‚æœæ²¡æœ‰ç­›é€‰æ¡ä»¶ï¼Œä½¿ç”¨åŸºæœ¬æ¡ä»¶
        if not filter_conditions:
            print("æ²¡æœ‰å¯ç”¨çš„ç­›é€‰æ¡ä»¶ï¼Œä½¿ç”¨åŸºæœ¬ç­›é€‰")
            # åªç­›é€‰éç§‘åˆ›æ¿å’Œåˆ›ä¸šæ¿
            if code_col:
                filter_conditions.append((~pl.col(code_col).str.contains('^688|^300|^301')))
            # å¦‚æœæœ‰åç§°åˆ—ï¼Œæ’é™¤STè‚¡
            if name_col:
                filter_conditions.append((~pl.col(name_col).str.contains('ST')))
        
        # ä½¿ç”¨å­˜åœ¨çš„ç­›é€‰æ¡ä»¶è¿›è¡Œè¿‡æ»¤
        try:
            if filter_conditions:
                combined_condition = filter_conditions[0]
                for condition in filter_conditions[1:]:
                    combined_condition = combined_condition & condition
                
                filtered_stocks = previous_limit_up_data.filter(combined_condition)
            else:
                # å¦‚æœæ²¡æœ‰ç­›é€‰æ¡ä»¶ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹æ•°æ®
                filtered_stocks = previous_limit_up_data
                
            print(f"ç¬¬ä¸€æ­¥ç­›é€‰åå‰©ä½™è‚¡ç¥¨æ•°: {filtered_stocks.height}")
        except Exception as e:
            print(f"ç­›é€‰è‚¡ç¥¨æ—¶å‡ºé”™: {str(e)}")
            # å¦‚æœç­›é€‰å‡ºé”™ï¼Œè¿”å›åŸå§‹æ•°æ®
            filtered_stocks = previous_limit_up_data
        
        # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
        filtered_stocks_dicts = filtered_stocks.to_dicts()
        
        # ç¬¬äºŒæ­¥ç­›é€‰ï¼šæŠ€æœ¯é¢å’Œå½¢æ€è¿‡æ»¤
        # å¦‚æœæ²¡æœ‰è‚¡ç¥¨è¯¦ç»†æ•°æ®ï¼Œè·³è¿‡è¿™ä¸€æ­¥
        if not stock_details:
            print("æ²¡æœ‰è‚¡ç¥¨è¯¦ç»†æ•°æ®ï¼Œè·³è¿‡æŠ€æœ¯é¢å’Œå½¢æ€ç­›é€‰")
            return filtered_stocks_dicts[:20]  # æœ€å¤šè¿”å›20åªè‚¡ç¥¨
        
        # ç¬¬äºŒæ­¥ç­›é€‰ï¼šæŠ€æœ¯é¢å’Œå½¢æ€è¿‡æ»¤
        result_stocks = []
        for stock in filtered_stocks_dicts:
            code = stock.get(code_col)
            if not code:
                continue
                
            # è·å–ä¸ªè‚¡è¯¦ç»†æ•°æ®
            stock_data = stock_details.get(code)
            if stock_data is None or stock_data.is_empty():
                continue
                
            # è·å–æœ€è¿‘äº¤æ˜“æ—¥æ•°æ®
            recent_data = stock_data.tail(10)  # è·å–æœ€è¿‘10ä¸ªäº¤æ˜“æ—¥æ•°æ®
            if recent_data.height < 3:
                continue
                
            # æ£€æŸ¥æ¶¨è·Œå¹…åˆ—æ˜¯å¦å­˜åœ¨
            change_col = None
            for col in ['æ¶¨è·Œå¹…', 'change_pct']:
                if col in stock:
                    change_col = col
                    break
            
            # è¿‡æ»¤æ¡ä»¶
            try:
                should_skip = False
                
                # æ£€æŸ¥æ¶¨è·Œå¹…
                if change_col and stock[change_col] > -3:
                    should_skip = True
                
                # æ£€æŸ¥æŠ€æœ¯æŒ‡æ ‡ï¼Œé¿å…ä½¿ç”¨ DataFrame çš„å¸ƒå°”å€¼åˆ¤æ–­
                if not should_skip:
                    has_upper_shadow = MarketAnalyzer._has_upper_shadow(recent_data)
                    is_multi_pump = MarketAnalyzer._is_multi_pump(recent_data)
                    has_previous_multi_limit_up = MarketAnalyzer._has_previous_multi_limit_up(recent_data)
                    is_high_position = MarketAnalyzer._is_high_position(recent_data)
                    is_zhihuji_pattern = MarketAnalyzer._is_zhihuji_pattern(recent_data)
                    
                    if (has_upper_shadow or is_multi_pump or has_previous_multi_limit_up or 
                        is_high_position or is_zhihuji_pattern):
                        should_skip = True
                    
                if not should_skip:
                    result_stocks.append(stock)
                    
            except Exception as e:
                print(f"åˆ†æè‚¡ç¥¨ {code} æ—¶å‡ºé”™: {str(e)}")
                continue
            
        print(f"ç¬¬äºŒæ­¥ç­›é€‰åå‰©ä½™è‚¡ç¥¨æ•°: {len(result_stocks)}")
        return result_stocks[:20]  # æœ€å¤šè¿”å›20åªè‚¡ç¥¨
        
    @staticmethod
    def _has_upper_shadow(data: pl.DataFrame) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰æ˜æ˜¾ä¸Šå½±çº¿"""
        latest = data.tail(1)
        if latest.is_empty():
            return False
            
        high = float(latest['high'].item())
        close = float(latest['close'].item())
        open_price = float(latest['open'].item())
        
        upper_shadow = high - max(close, open_price)
        body = abs(close - open_price)
        
        return upper_shadow > body * 0.5  # ä¸Šå½±çº¿é•¿åº¦è¶…è¿‡å®ä½“çš„50%
        
    @staticmethod
    def _is_multi_pump(data: pl.DataFrame) -> bool:
        """æ£€æŸ¥æ˜¯å¦å­˜åœ¨å¤šæ¬¡æ‹‰å‡"""
        if data.height < 3:
            return False
            
        # è®¡ç®—æ—¥å†…æŒ¯å¹…
        try:
            data = data.with_columns([
                ((pl.col('high') - pl.col('low')) / pl.col('low') * 100).alias('amplitude')
            ])
            
            # ç»Ÿè®¡å¤§æŒ¯å¹…å¤©æ•°
            large_amplitude_days = data.filter(pl.col('amplitude') > 5).height  # æŒ¯å¹…è¶…è¿‡5%ç®—å¤§æŒ¯å¹…
            
            return large_amplitude_days >= 2  # 2å¤©ä»¥ä¸Šå¤§æŒ¯å¹…è§†ä¸ºå¤šæ¬¡æ‹‰å‡
        except Exception as e:
            print(f"æ£€æŸ¥å¤šæ¬¡æ‹‰å‡æ—¶å‡ºé”™: {str(e)}")
            return False
        
    @staticmethod
    def _has_previous_multi_limit_up(data: pl.DataFrame) -> bool:
        """æ£€æŸ¥ä¸‹è·Œå‰æ˜¯å¦æœ‰è¿ç»­æ¶¨åœ"""
        if data.height < 3:
            return False
            
        try:
            # è·å–æœ€è¿‘3å¤©æ•°æ®
            recent_data = data.tail(3)
            if recent_data.is_empty() or recent_data.height < 3:
                return False
                
            # ç¡®ä¿æ¶¨è·Œå¹…åˆ—å­˜åœ¨
            change_col = 'change_pct' if 'change_pct' in recent_data.columns else 'æ¶¨è·Œå¹…'
            if change_col not in recent_data.columns:
                return False
                
            changes = recent_data[change_col].to_list()
            
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨è¿ç»­æ¶¨åœåä¸‹è·Œ
            for i in range(len(changes)-2):
                if changes[i] >= 9.8 and changes[i+1] >= 9.8 and changes[i+2] < 0:
                    return True
            return False
        except Exception as e:
            print(f"æ£€æŸ¥è¿ç»­æ¶¨åœæ—¶å‡ºé”™: {str(e)}")
            return False
        
    @staticmethod
    def _is_high_position(data: pl.DataFrame) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¤„äºé«˜ä½"""
        if data.height < 10:
            return False
            
        try:
            latest = data.tail(1)
            if latest.is_empty():
                return False
                
            latest_close = float(latest['close'].item())
            min_price = float(data['low'].min())
            
            # å½“å‰ä»·æ ¼è¶…è¿‡æœ€ä½ä»·50%è§†ä¸ºé«˜ä½
            return (latest_close - min_price) / min_price > 0.5
        except Exception as e:
            print(f"æ£€æŸ¥é«˜ä½æ—¶å‡ºé”™: {str(e)}")
            return False
        
    @staticmethod
    def _is_zhihuji_pattern(data: pl.DataFrame) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºç»‡å¸ƒæœºå½¢æ€"""
        if data.height < 3:
            return False
            
        try:
            recent_data = data.tail(3)
            if recent_data.is_empty() or recent_data.height < 3:
                return False
                
            # è®¡ç®—å®ä½“å’Œå½±çº¿
            recent_data = recent_data.with_columns([
                (pl.col('close') - pl.col('open')).alias('body'),
                (pl.col('high') - pl.col('low')).alias('total_range'),
                ((pl.col('high') - pl.max_horizontal(pl.col('close'), pl.col('open'))) +
                 (pl.min_horizontal(pl.col('close'), pl.col('open')) - pl.col('low'))).alias('shadows')
            ])
            
            # ç»‡å¸ƒæœºç‰¹å¾ï¼šå°å®ä½“ã€é•¿ä¸Šä¸‹å½±çº¿ã€äº¤æ›¿å‡ºç°
            small_body = abs(recent_data['body']) < recent_data['total_range'] * 0.3
            long_shadows = recent_data['shadows'] > recent_data['total_range'] * 0.6
            
            # è®¡ç®—ç¬¦åˆæ¡ä»¶çš„å¤©æ•°
            condition_met_days = (small_body & long_shadows).sum()
            
            return condition_met_days >= 2  # 3å¤©å†…å‡ºç°2æ¬¡ä»¥ä¸Šç»‡å¸ƒæœºå½¢æ€
        except Exception as e:
            print(f"æ£€æŸ¥ç»‡å¸ƒæœºå½¢æ€æ—¶å‡ºé”™: {str(e)}")
            return False
    
    @staticmethod
    def analyze_new_high_stocks(market_states_data: pl.DataFrame, days: int = 5, selected_date=None,
                               exclude_st: bool = True, include_non_main_board: bool = False) -> List[dict]:
        """åˆ†ææ–°é«˜è‚¡ç¥¨"""
        try:
            import time
            from datetime import datetime, timedelta

            if selected_date is None:
                selected_date = datetime.now().date()
            elif isinstance(selected_date, str):
                selected_date = datetime.strptime(selected_date, '%Y-%m-%d').date()

            print(f"ğŸš€ å¼€å§‹åˆ†æ{days}æ—¥æ–°é«˜è‚¡ç¥¨...")
            start_time = time.time()

            # 1. æ”¹è¿›æ—¥æœŸèŒƒå›´è®¡ç®—
            end_date = selected_date - timedelta(days=1)
            # è€ƒè™‘äº¤æ˜“æ—¥ï¼Œè€Œä¸æ˜¯è‡ªç„¶æ—¥
            start_date = end_date - timedelta(days=days * 2)  # é¢„ç•™è¶³å¤Ÿçš„å¤©æ•°

            # 2. æ”¹è¿›å†å²æ•°æ®è·å–
            historical_data = market_states_data.filter(
                (pl.col('æ—¥æœŸ') >= start_date) &
                (pl.col('æ—¥æœŸ') <= end_date)
            )

            if historical_data.is_empty():
                print(f"âš ï¸  æœªæ‰¾åˆ°å†å²æ•°æ® ({start_date} åˆ° {end_date})")
                return []

            # 3. æ”¹è¿›å†å²æœ€é«˜ä»·è®¡ç®—
            historical_highs = historical_data.group_by('ä»£ç ').agg([
                pl.col('æœ€é«˜').max().alias('å†å²æœ€é«˜ä»·'),
                pl.col('æ—¥æœŸ').n_unique().alias('äº¤æ˜“å¤©æ•°')  # ä½¿ç”¨n_uniqueæ›´å‡†ç¡®
            ]).filter(
                pl.col('äº¤æ˜“å¤©æ•°') >= min(days, 3)  # è‡³å°‘3ä¸ªäº¤æ˜“æ—¥
            )

            # 4. è·å–ç›®æ ‡æ—¥æœŸæ•°æ®
            target_data = market_states_data.filter(pl.col('æ—¥æœŸ') == selected_date)

            if target_data.is_empty():
                print(f"âš ï¸  æœªæ‰¾åˆ° {selected_date} çš„æ•°æ®")
                return []

            # 5. åº”ç”¨è¿‡æ»¤é€‰é¡¹
            if exclude_st:
                # è¿‡æ»¤æ‰STè‚¡ç¥¨ï¼ˆåç§°åŒ…å«STã€*STã€é€€ç­‰ï¼‰
                target_data = target_data.filter(
                    ~pl.col('åç§°').str.contains(r'ST|é€€|æš‚åœ')
                )
                print(f"ğŸ”§ å·²è¿‡æ»¤STè‚¡ç¥¨ï¼Œå‰©ä½™ {target_data.height} åªè‚¡ç¥¨")

            if not include_non_main_board:
                # åªä¿ç•™ä¸»æ¿è‚¡ç¥¨ï¼ˆä»£ç ä»¥00ã€60å¼€å¤´ï¼‰
                target_data = target_data.filter(
                    pl.col('ä»£ç ').str.starts_with('00') |
                    pl.col('ä»£ç ').str.starts_with('60')
                )
                print(f"ğŸ”§ å·²è¿‡æ»¤éä¸»æ¿è‚¡ç¥¨ï¼Œå‰©ä½™ {target_data.height} åªè‚¡ç¥¨")

            # 6. æ”¹è¿›ç»“æœè®¡ç®—å’Œåˆ—é€‰æ‹©
            # é¦–å…ˆæ£€æŸ¥ç›®æ ‡æ•°æ®ä¸­å®é™…å­˜åœ¨çš„åˆ—
            available_columns = target_data.columns
            print(f"ç›®æ ‡æ•°æ®å¯ç”¨åˆ—: {available_columns}")

            # åŸºç¡€å¿…éœ€åˆ—
            base_columns = ['ä»£ç ', 'åç§°', 'æ”¶ç›˜', 'æˆäº¤é‡', 'æ¶¨è·Œå¹…']

            # å¯é€‰çš„æ¶¨è·Œå¹…åˆ—
            optional_columns = ['5æ—¥æ¶¨è·Œå¹…', '10æ—¥æ¶¨è·Œå¹…', '20æ—¥æ¶¨è·Œå¹…']

            # æ„å»ºå®é™…å¯ç”¨çš„åˆ—åˆ—è¡¨
            select_columns = base_columns.copy()
            for col in optional_columns:
                if col in available_columns:
                    select_columns.append(col)
                else:
                    print(f"è­¦å‘Š: åˆ— '{col}' ä¸å­˜åœ¨äºæ•°æ®ä¸­")

            result = target_data.join(historical_highs, on='ä»£ç ', how='inner').filter(
                pl.col('æ”¶ç›˜') > pl.col('å†å²æœ€é«˜ä»·')
            ).with_columns([
                ((pl.col('æ”¶ç›˜') - pl.col('å†å²æœ€é«˜ä»·')) / pl.col('å†å²æœ€é«˜ä»·') * 100)
                .round(2).alias('çªç ´å¹…åº¦'),
                pl.col('æ”¶ç›˜').alias('æ”¶ç›˜ä»·'),
                pl.col('å†å²æœ€é«˜ä»·').alias('å†å²æœ€é«˜'),
            ])

            # æ·»åŠ è®¡ç®—å‡ºçš„åˆ—åˆ°é€‰æ‹©åˆ—è¡¨ï¼Œå¹¶é‡å‘½åæ¶¨è·Œå¹…åˆ—ä»¥åŒ¹é…å‰ç«¯æœŸæœ›
            final_columns = ['ä»£ç ', 'åç§°', 'æ”¶ç›˜ä»·', 'å†å²æœ€é«˜', 'çªç ´å¹…åº¦', 'æˆäº¤é‡', 'æ¶¨è·Œå¹…']
            rename_mapping = {}

            for col in optional_columns:
                if col in available_columns:
                    final_columns.append(col)
                    # ä¸ºå‰ç«¯æ·»åŠ ç™¾åˆ†å·æ ‡è¯†
                    new_col_name = f"{col}(%)"
                    rename_mapping[col] = new_col_name

            result = result.select(final_columns)

            # é‡å‘½åæ¶¨è·Œå¹…åˆ—
            if rename_mapping:
                result = result.rename(rename_mapping)

            result = result.sort('çªç ´å¹…åº¦', descending=True)

            elapsed_time = time.time() - start_time

            if not result.is_empty():
                print(f"âœ… æ‰¾åˆ° {result.height} åª{days}æ—¥æ–°é«˜è‚¡ç¥¨ (è€—æ—¶: {elapsed_time:.3f}ç§’)")
                return result.to_dicts()
            else:
                print(f"â„¹ï¸  æœªæ‰¾åˆ°{days}æ—¥æ–°é«˜è‚¡ç¥¨ (è€—æ—¶: {elapsed_time:.3f}ç§’)")
                return []

        except Exception as e:
            print(f"âŒ åˆ†ææ–°é«˜è‚¡ç¥¨å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return []

    @staticmethod
    def analyze_continuous_limit_up(limit_up_data: pl.DataFrame) -> List[dict]:
        """åˆ†æè¿‘æœŸè¿æ¿é«˜åº¦"""
        if limit_up_data.is_empty():
            print("æ¶¨åœæ¿æ•°æ®ä¸ºç©ºï¼Œæ— æ³•åˆ†æè¿æ¿é«˜åº¦")
            return []
            
        # å¯»æ‰¾åŒ…å«è¿æ¿å¤©æ•°çš„åˆ—
        continuous_days_col = None
        for col in ['è¿æ¿å¤©æ•°', 'è¿ç»­æ¶¨åœå¤©æ•°', 'æ˜¨æ—¥è¿æ¿æ•°', 'æ¶¨åœç»Ÿè®¡']:
            if col in limit_up_data.columns:
                continuous_days_col = col
                break
                
        # å¯»æ‰¾è‚¡ç¥¨åç§°åˆ—å’Œä»£ç åˆ—
        name_col = None
        for col in ['åç§°', 'è‚¡ç¥¨ç®€ç§°']:
            if col in limit_up_data.columns:
                name_col = col
                break
                
        code_col = None
        for col in ['ä»£ç ', 'è‚¡ç¥¨ä»£ç ']:
            if col in limit_up_data.columns:
                code_col = col
                break
                
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°éœ€è¦çš„åˆ—ï¼Œè¿”å›ç©ºç»“æœ
        if continuous_days_col is None or name_col is None or code_col is None:
            print(f"æ•°æ®ç¼ºå°‘è¿æ¿å¤©æ•°ã€åç§°æˆ–ä»£ç åˆ—ï¼Œç°æœ‰åˆ—: {limit_up_data.columns}")
            return []
            
        try:
            # å°è¯•å°†è¿æ¿å¤©æ•°è½¬æ¢ä¸ºæ•°å€¼
            # å¦‚æœè¿æ¿å¤©æ•°æ˜¯ä»¥"Næ¿"ã€"Nè¿æ¿"ç­‰å½¢å¼å­˜å‚¨çš„ï¼Œéœ€è¦æå–æ•°å­—
            if limit_up_data[continuous_days_col].dtype == pl.Utf8:
                # å°è¯•ä»å­—ç¬¦ä¸²ä¸­æå–æ•°å­—
                try:
                    # å°è¯•ç›´æ¥è½¬æ¢ä¸ºæ•°å­—
                    limit_up_data = limit_up_data.with_columns([
                        pl.col(continuous_days_col).cast(pl.Int64).alias('è¿æ¿æ•°')
                    ])
                except:
                    # å¦‚æœå¤±è´¥ï¼Œå°è¯•ä»å­—ç¬¦ä¸²ä¸­æå–æ•°å­—
                    def extract_number(s):
                        import re
                        if s is None:
                            return 1  # é»˜è®¤ä¸º1æ¿
                        match = re.search(r'(\d+)', str(s))
                        return int(match.group(1)) if match else 1
                    
                    # ä½¿ç”¨polarsçš„è‡ªå®šä¹‰å‡½æ•°
                    limit_up_data = limit_up_data.with_columns([
                        pl.col(continuous_days_col).map_elements(extract_number).alias('è¿æ¿æ•°')
                    ])
            else:
                # å¦‚æœå·²ç»æ˜¯æ•°å€¼ç±»å‹ï¼Œç›´æ¥ä½¿ç”¨
                limit_up_data = limit_up_data.with_columns([
                    pl.col(continuous_days_col).alias('è¿æ¿æ•°')
                ])
                
            # æŒ‰è¿æ¿æ•°æ’åºï¼Œå–å‰20åªè‚¡ç¥¨
            result = (
                limit_up_data
                .sort('è¿æ¿æ•°', descending=True)
                .head(20)
                .select([code_col, name_col, 'è¿æ¿æ•°'])
                .to_dicts()
            )
            
            return result
            
        except Exception as e:
            print(f"åˆ†æè¿æ¿é«˜åº¦æ—¶å‡ºé”™: {str(e)}")
            import traceback
            traceback.print_exc()
            return []

    @staticmethod
    def get_beijing_microcap_analysis(date_str: str) -> dict:
        """è·å–åŒ—è¯50å’Œå¾®ç›˜è‚¡åˆ†ææ•°æ®"""
        try:
            from utils.data_fetcher import DataFetcher
            data_fetcher = DataFetcher()

            # è·å–åŒ—è¯50æ•°æ® (ä»£ç : 899050)
            beijing_df = data_fetcher.index_metadata_manager.get_index_data(
                '899050',
                start_date=date_str,
                end_date=date_str
            )

            # è·å–å¾®ç›˜è‚¡æ•°æ® (ä»£ç : 800007)
            microcap_df = data_fetcher.index_metadata_manager.get_index_data(
                '800007',
                start_date=date_str,
                end_date=date_str
            )

            # æå–æ¶¨è·Œå¹…æ•°æ®
            beijing_change = None
            microcap_change = None

            if beijing_df is not None and not beijing_df.is_empty():
                beijing_change = float(beijing_df['æ¶¨è·Œå¹…'][0])

            if microcap_df is not None and not microcap_df.is_empty():
                microcap_change = float(microcap_df['æ¶¨è·Œå¹…'][0])

            return {
                'beijing_50': {
                    'change_pct': beijing_change,
                    'status': MarketAnalyzer._get_sentiment_status(beijing_change) if beijing_change is not None else 'æ— æ•°æ®'
                },
                'microcap': {
                    'change_pct': microcap_change,
                    'status': MarketAnalyzer._get_sentiment_status(microcap_change, is_microcap=True) if microcap_change is not None else 'æ— æ•°æ®'
                }
            }

        except Exception as e:
            print(f"è·å–åŒ—è¯50å’Œå¾®ç›˜è‚¡æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            return {
                'beijing_50': {'change_pct': None, 'status': 'æ•°æ®è·å–å¤±è´¥'},
                'microcap': {'change_pct': None, 'status': 'æ•°æ®è·å–å¤±è´¥'}
            }

    @staticmethod
    def _get_sentiment_status(change_pct: float, is_microcap: bool = False) -> str:
        """æ ¹æ®æ¶¨è·Œå¹…è·å–æƒ…ç»ªçŠ¶æ€"""
        if is_microcap:
            # å¾®ç›˜è‚¡çš„é˜ˆå€¼ç¨æœ‰ä¸åŒ
            if change_pct >= 2:
                return "ğŸ”¥ æƒ…ç»ªç«çƒ­"
            elif change_pct >= 1:
                return "ğŸ“ˆ æƒ…ç»ªç§¯æ"
            elif change_pct >= -1:
                return "ğŸ˜ æƒ…ç»ªå¹³ç¨³"
            elif change_pct >= -3:
                return "ğŸ“‰ æƒ…ç»ªè°¨æ…"
            else:
                return "â„ï¸ æƒ…ç»ªä½è¿·"
        else:
            # åŒ—è¯50çš„é˜ˆå€¼
            if change_pct >= 2:
                return "ğŸ”¥ æƒ…ç»ªç«çƒ­"
            elif change_pct >= 1:
                return "ğŸ“ˆ æƒ…ç»ªç§¯æ"
            elif change_pct >= -1:
                return "ğŸ˜ æƒ…ç»ªå¹³ç¨³"
            elif change_pct >= -2:
                return "ğŸ“‰ æƒ…ç»ªè°¨æ…"
            else:
                return "â„ï¸ æƒ…ç»ªä½è¿·"

    @staticmethod
    def get_trading_strategy(beijing_data: dict) -> dict:
        """æ ¹æ®åŒ—è¯50å’Œå¾®ç›˜è‚¡æ•°æ®ç”Ÿæˆäº¤æ˜“ç­–ç•¥å»ºè®®"""
        try:
            beijing_change = beijing_data.get('beijing_50', {}).get('change_pct')
            microcap_change = beijing_data.get('microcap', {}).get('change_pct')

            if beijing_change is None or microcap_change is None:
                return {
                    'strategy': "æš‚æ— æ•°æ®",
                    'emoji': "âš ï¸",
                    'risk_level': "æœªçŸ¥",
                    'description': "æ•°æ®ä¸è¶³ï¼Œæ— æ³•ç”Ÿæˆç­–ç•¥å»ºè®®"
                }

            # ç­–ç•¥é€»è¾‘ï¼ˆåŸºäºapp.pyä¸­çš„é€»è¾‘ï¼‰
            if -1 < beijing_change <= 1 or -1 < microcap_change <= 1:
                return {
                    'strategy': "çŸ­çº¿æƒ…ç»ªæ— ç¢ï¼Œå¯ä»¥ç»§ç»­å‚ä¸ã€‚",
                    'emoji': "ğŸ˜",
                    'risk_level': "ä¸­æ€§",
                    'description': "å¸‚åœºæƒ…ç»ªå¹³ç¨³ï¼Œå¯ç»´æŒç°æœ‰ä»“ä½"
                }
            elif 1 <= beijing_change < 2 or 1 <= microcap_change < 2:
                return {
                    'strategy': "çŸ­çº¿æƒ…ç»ªç§¯æï¼Œå¯é€‚å½“ä¸Šä»“ä½ã€‚",
                    'emoji': "ğŸ˜Š",
                    'risk_level': "ç§¯æ",
                    'description': "å¸‚åœºæƒ…ç»ªè½¬å¥½ï¼Œå»ºè®®é€‚åº¦å¢åŠ ä»“ä½"
                }
            elif beijing_change >= 2 or microcap_change >= 2:
                return {
                    'strategy': "çŸ­çº¿æƒ…ç»ªé«˜æ˜‚ï¼Œå¯ä»¥é‡ä»“å‚ä¸ã€‚",
                    'emoji': "ğŸš€",
                    'risk_level': "æ¿€è¿›",
                    'description': "å¸‚åœºæƒ…ç»ªç«çƒ­ï¼Œå¯è€ƒè™‘é‡ä»“æ“ä½œ"
                }
            elif -2 < beijing_change <= -1 or -3 < microcap_change <= -1:
                return {
                    'strategy': "çŸ­çº¿è°¨æ…ï¼Œå¯ä»¥è½»ä»“æŠ¢åå¼¹ã€‚",
                    'emoji': "ğŸ˜°",
                    'risk_level': "è°¨æ…",
                    'description': "å¸‚åœºæƒ…ç»ªè½¬å¼±ï¼Œå»ºè®®è½»ä»“æ“ä½œ"
                }
            elif beijing_change <= -2 or microcap_change <= -3:
                return {
                    'strategy': "çŸ­çº¿æƒ…ç»ªç“¦è§£ï¼ŒAæµªä¸‹è·Œå¼€å§‹ã€‚",
                    'emoji': "ğŸ˜±",
                    'risk_level': "ä¿å®ˆ",
                    'description': "å¸‚åœºæƒ…ç»ªæ¶åŒ–ï¼Œå»ºè®®è§‚æœ›æˆ–å‡ä»“"
                }
            else:
                return {
                    'strategy': "æƒ…ç»ªåŒºé—´ä¸æ˜ï¼Œå»ºè®®è°¨æ…ã€‚",
                    'emoji': "ğŸ¤”",
                    'risk_level': "è§‚æœ›",
                    'description': "å¸‚åœºä¿¡å·ä¸æ˜ç¡®ï¼Œå»ºè®®è°¨æ…è§‚æœ›"
                }

        except Exception as e:
            print(f"ç”Ÿæˆäº¤æ˜“ç­–ç•¥æ—¶å‡ºé”™: {str(e)}")
            return {
                'strategy': "ç­–ç•¥ç”Ÿæˆå¤±è´¥",
                'emoji': "âŒ",
                'risk_level': "æœªçŸ¥",
                'description': f"ç­–ç•¥ç”Ÿæˆå‡ºé”™: {str(e)}"
            }

    @staticmethod
    def get_multi_index_kline_data(selected_indices: List[str], date_str: str, days_range: int) -> dict:
        """è·å–å¤šæŒ‡æ•°Kçº¿æ•°æ®"""
        try:
            from utils.data_fetcher import DataFetcher
            from utils.visualizers.index_visualizer import IndexVisualizer
            from datetime import datetime, timedelta
            import os

            data_fetcher = DataFetcher()

            # æŒ‡æ•°ä»£ç æ˜ å°„
            index_options = {
                'ä¸Šè¯æŒ‡æ•°': 'sh000001',
                'æ·±è¯æˆæŒ‡': 'sz399001',
                'åˆ›ä¸šæ¿æŒ‡': 'sz399006',
                'ä¸Šè¯50': 'sh000016',
                'æ²ªæ·±300': 'sh000300',
                'ä¸­è¯500': 'sh000905',
                'ä¸­è¯2000': 'sz932000',
                'ç§‘åˆ›50': 'sh000688',
                'ä¸­è¯1000': 'sh000852'
            }

            # è®¡ç®—å¼€å§‹æ—¥æœŸ
            selected_date = datetime.strptime(date_str, '%Y%m%d').date()
            start_date = selected_date - timedelta(days=days_range)
            start_date_str = start_date.strftime('%Y%m%d')

            index_data_dict = {}

            for index_name in selected_indices:
                if index_name not in index_options:
                    continue

                index_code = index_options[index_name]

                try:
                    # æ£€æŸ¥æ˜¯å¦æœ‰æŒ‡æ•°æ—¥Kå…ƒæ•°æ®
                    if os.path.exists("data_cache/indices/index_daily_metadata.parquet"):
                        # ä»å…ƒæ•°æ®ä¸­è·å–æŒ‡æ•°æ•°æ®
                        clean_code = index_code.replace('sh', '').replace('sz', '')

                        df = data_fetcher.index_metadata_manager.get_index_data(
                            clean_code,
                            start_date=start_date_str,
                            end_date=date_str
                        )

                        if df is not None and not df.is_empty():
                            print(f"ä»å…ƒæ•°æ®ä¸­è·å–åˆ° {index_name} æ•°æ®ï¼Œå…± {df.height} è¡Œ")
                            index_data_dict[index_name] = df
                            continue

                    # å¦‚æœæ²¡æœ‰å…ƒæ•°æ®ï¼Œå°è¯•ä½¿ç”¨akshareè·å–
                    try:
                        import akshare as ak

                        # å°è¯•ä¸åŒçš„ä»£ç æ ¼å¼
                        code_variations = [
                            index_code,
                            index_code.replace('sh', '').replace('sz', ''),
                        ]

                        for code in code_variations:
                            try:
                                print(f"å°è¯•ä½¿ç”¨ä»£ç  {code} è·å– {index_name} æ•°æ®")
                                df = ak.stock_zh_index_daily(symbol=code)
                                if not df.empty:
                                    df = pl.from_pandas(df)

                                    # ç¡®ä¿æ—¥æœŸåˆ—æ ¼å¼æ­£ç¡®
                                    if df['date'].dtype == pl.Utf8:
                                        df = df.with_columns([
                                            pl.col('date').str.strptime(pl.Date, '%Y-%m-%d').alias('date')
                                        ])

                                    # é‡å‘½ååˆ—ä»¥åŒ¹é…é¢„æœŸæ ¼å¼
                                    df = df.rename({
                                        'date': 'æ—¥æœŸ',
                                        'open': 'å¼€ç›˜',
                                        'close': 'æ”¶ç›˜',
                                        'high': 'æœ€é«˜',
                                        'low': 'æœ€ä½',
                                        'volume': 'æˆäº¤é‡'
                                    })

                                    # ç­›é€‰æ—¥æœŸèŒƒå›´
                                    df = df.filter(
                                        (pl.col('æ—¥æœŸ') >= pl.lit(start_date)) &
                                        (pl.col('æ—¥æœŸ') <= pl.lit(selected_date))
                                    )

                                    if not df.is_empty():
                                        print(f"ä½¿ç”¨ä»£ç  {code} æˆåŠŸè·å–åˆ° {index_name} æ•°æ®ï¼Œå…± {df.height} è¡Œ")
                                        index_data_dict[index_name] = df
                                        break
                            except Exception as e:
                                print(f"ä½¿ç”¨ä»£ç  {code} è·å– {index_name} æ•°æ®å¤±è´¥: {str(e)}")

                    except ImportError:
                        print("akshareæœªå®‰è£…ï¼Œæ— æ³•è·å–åœ¨çº¿æ•°æ®")

                except Exception as e:
                    print(f"è·å– {index_name} æ•°æ®æ—¶å‡ºé”™: {str(e)}")

            # ç”ŸæˆKçº¿å›¾HTMLå’ŒEChartsé…ç½®
            if index_data_dict:
                chart_html = IndexVisualizer.plot_multi_index_kline(index_data_dict)
                chart_options = IndexVisualizer.get_multi_index_kline_options(index_data_dict)
                return {
                    'chart_html': chart_html,
                    'chart_options': chart_options,
                    'data_summary': {name: df.height for name, df in index_data_dict.items()},
                    'success_count': len(index_data_dict),
                    'total_requested': len(selected_indices)
                }
            else:
                return {
                    'chart_html': "<div>æ— æ³•è·å–æŒ‡æ•°æ•°æ®</div>",
                    'data_summary': {},
                    'success_count': 0,
                    'total_requested': len(selected_indices)
                }

        except Exception as e:
            print(f"è·å–å¤šæŒ‡æ•°Kçº¿æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            import traceback
            traceback.print_exc()
            return {
                'chart_html': f"<div>æ•°æ®è·å–å¤±è´¥: {str(e)}</div>",
                'data_summary': {},
                'success_count': 0,
                'total_requested': len(selected_indices) if selected_indices else 0
            }

    @staticmethod
    def get_available_indices() -> List[dict]:
        """è·å–å¯ç”¨çš„æŒ‡æ•°åˆ—è¡¨"""
        try:
            from utils.data_fetcher import DataFetcher
            import os

            # é»˜è®¤æŒ‡æ•°é€‰é¡¹
            default_indices = [
                {'name': 'ä¸Šè¯æŒ‡æ•°', 'code': 'sh000001', 'available': False},
                {'name': 'æ·±è¯æˆæŒ‡', 'code': 'sz399001', 'available': False},
                {'name': 'åˆ›ä¸šæ¿æŒ‡', 'code': 'sz399006', 'available': False},
                {'name': 'ä¸Šè¯50', 'code': 'sh000016', 'available': False},
                {'name': 'æ²ªæ·±300', 'code': 'sh000300', 'available': False},
                {'name': 'ä¸­è¯500', 'code': 'sh000905', 'available': False},
                {'name': 'ä¸­è¯2000', 'code': 'sz932000', 'available': False},
                {'name': 'ç§‘åˆ›50', 'code': 'sh000688', 'available': False},
                {'name': 'ä¸­è¯1000', 'code': 'sh000852', 'available': False}
            ]

            # æ£€æŸ¥æ˜¯å¦æœ‰æŒ‡æ•°å…ƒæ•°æ®
            if os.path.exists("data_cache/indices/index_daily_metadata.parquet"):
                try:
                    data_fetcher = DataFetcher()
                    index_metadata = data_fetcher.index_metadata_manager.load_metadata()

                    if index_metadata is not None and not index_metadata.is_empty():
                        available_codes = index_metadata['ä»£ç '].unique().to_list()

                        # æ›´æ–°å¯ç”¨çŠ¶æ€
                        for index_info in default_indices:
                            clean_code = index_info['code'].replace('sh', '').replace('sz', '')
                            if clean_code in available_codes or index_info['code'] in available_codes:
                                index_info['available'] = True

                        # æ·»åŠ å…ƒæ•°æ®ä¸­æœ‰ä½†é»˜è®¤åˆ—è¡¨ä¸­æ²¡æœ‰çš„æŒ‡æ•°
                        if 'åç§°' in index_metadata.columns:
                            unique_indices = index_metadata.select(['ä»£ç ', 'åç§°']).unique()

                            for row in unique_indices.iter_rows():
                                code, name = row
                                clean_code = code.replace('sh', '').replace('sz', '')

                                # æ£€æŸ¥æ˜¯å¦å·²åœ¨é»˜è®¤åˆ—è¡¨ä¸­
                                found = False
                                for existing in default_indices:
                                    existing_clean = existing['code'].replace('sh', '').replace('sz', '')
                                    if clean_code == existing_clean:
                                        found = True
                                        break

                                if not found:
                                    # æ·»åŠ æ–°æŒ‡æ•°
                                    full_code = f"sh{clean_code}" if len(clean_code) == 6 else f"sz{clean_code}"
                                    default_indices.append({
                                        'name': name,
                                        'code': full_code,
                                        'available': True
                                    })

                except Exception as e:
                    print(f"æ£€æŸ¥æŒ‡æ•°å…ƒæ•°æ®æ—¶å‡ºé”™: {str(e)}")

            return default_indices

        except Exception as e:
            print(f"è·å–å¯ç”¨æŒ‡æ•°åˆ—è¡¨æ—¶å‡ºé”™: {str(e)}")
            return []

    @staticmethod
    def analyze_heima_stocks(market_states_data: pl.DataFrame, date=None, exclude_st=True, include_non_main_board=False) -> List[dict]:
        """é»‘é©¬åˆ†æ - åˆ†ææ¶¨åœè‚¡ç¥¨"""
        try:
            if date is None:
                selected_date = datetime.now().date()
            elif isinstance(date, str):
                selected_date = datetime.strptime(date, '%Y-%m-%d').date()
            else:
                selected_date = date

            print(f"ğŸ”§ DEBUG: é»‘é©¬åˆ†ææ—¥æœŸ: {selected_date}")
            print(f"ğŸ”§ DEBUG: å¸‚åœºæ•°æ®è¡Œæ•°: {market_states_data.height}")
            print(f"ğŸ”§ DEBUG: è¿‡æ»¤å‚æ•° - exclude_st: {exclude_st}, include_non_main_board: {include_non_main_board}")

            # ç­›é€‰å½“å¤©çš„æ¶¨åœä¸ªè‚¡
            zt_df = market_states_data.filter(
                (pl.col('æ¶¨åœ') == True) &
                (pl.col('æ—¥æœŸ') == selected_date)
            )

            print(f"ğŸ”§ DEBUG: ç­›é€‰åæ¶¨åœè‚¡ç¥¨æ•°: {zt_df.height}")

            if zt_df.is_empty():
                # å¦‚æœå½“å¤©æ²¡æœ‰æ¶¨åœè‚¡ç¥¨ï¼Œå°è¯•æœ€è¿‘å‡ å¤©çš„æ•°æ®
                print("ğŸ”§ DEBUG: å½“å¤©æ— æ¶¨åœè‚¡ç¥¨ï¼Œå°è¯•æœ€è¿‘3å¤©")
                recent_dates = market_states_data['æ—¥æœŸ'].unique().sort(descending=True).head(3)
                for recent_date in recent_dates:
                    zt_df = market_states_data.filter(
                        (pl.col('æ¶¨åœ') == True) &
                        (pl.col('æ—¥æœŸ') == recent_date)
                    )
                    if not zt_df.is_empty():
                        print(f"ğŸ”§ DEBUG: æ‰¾åˆ° {recent_date} çš„æ¶¨åœè‚¡ç¥¨: {zt_df.height}åª")
                        selected_date = recent_date
                        break

            if zt_df.is_empty():
                return []

            # åº”ç”¨è¿‡æ»¤æ¡ä»¶
            original_count = zt_df.height

            # è¿‡æ»¤STè‚¡ç¥¨
            if exclude_st:
                zt_df = zt_df.filter(~pl.col('åç§°').str.contains('ST'))
                print(f"ğŸ”§ DEBUG: å»æ‰STè‚¡ç¥¨å: {zt_df.height}åª (åŸ{original_count}åª)")

            # è¿‡æ»¤éä¸»æ¿è‚¡ç¥¨ï¼ˆæ ¹æ®æ¶¨è·Œå¹…é™åˆ¶åˆ¤æ–­ï¼‰
            if not include_non_main_board:
                # ä¸»æ¿è‚¡ç¥¨é€šå¸¸æ¶¨è·Œå¹…é™åˆ¶ä¸º10%ï¼ˆ0.10ï¼‰
                zt_df = zt_df.filter(pl.col('æ¶¨è·Œå¹…é™åˆ¶') == 0.10)
                print(f"ğŸ”§ DEBUG: åªä¿ç•™ä¸»æ¿è‚¡ç¥¨å: {zt_df.height}åª")

            if zt_df.is_empty():
                print("ğŸ”§ DEBUG: åº”ç”¨è¿‡æ»¤æ¡ä»¶åæ— è‚¡ç¥¨")
                return []

            # æ£€æŸ¥å¯ç”¨åˆ—
            available_cols = zt_df.columns
            select_cols = ['ä»£ç ', 'åç§°']

            # æ·»åŠ å¯ç”¨çš„åˆ—
            optional_cols = ['æ”¶ç›˜', 'æ¶¨è·Œå¹…', 'æˆäº¤é¢', 'æ¢æ‰‹ç‡', 'è¿æ¿å¤©æ•°', '5æ—¥æ¶¨è·Œå¹…', '10æ—¥æ¶¨è·Œå¹…']
            for col in optional_cols:
                if col in available_cols:
                    select_cols.append(col)

            # æŒ‰è¿æ¿å¤©æ•°æ’åºï¼ˆè¿æ¿æ•°æœ€å¤šçš„åœ¨å‰é¢ï¼‰
            if 'è¿æ¿æ•°' in zt_df.columns:
                # å…ˆæŒ‰è¿æ¿æ•°æ’åºï¼ˆé™åºï¼‰ï¼Œå†æŒ‰æˆäº¤é¢æ’åºï¼ˆé™åºï¼‰
                if 'æˆäº¤é¢' in select_cols:
                    zt_df = zt_df.sort(['è¿æ¿æ•°', 'æˆäº¤é¢'], descending=[True, True])
                else:
                    zt_df = zt_df.sort('è¿æ¿æ•°', descending=True)
            elif 'æˆäº¤é¢' in select_cols:
                # å¦‚æœæ²¡æœ‰è¿æ¿æ•°ï¼ŒæŒ‰æˆäº¤é¢æ’åº
                zt_df = zt_df.sort('æˆäº¤é¢', descending=True)

            # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
            result = zt_df.select(select_cols).to_dicts()

            print(f"ğŸ”§ DEBUG: è¿”å›é»‘é©¬è‚¡ç¥¨æ•°: {len(result)}")
            print(f"ğŸ”§ DEBUG: æ’åºæ–¹å¼: è¿æ¿æ•°é™åº -> æˆäº¤é¢é™åº")
            return result

        except Exception as e:
            print(f"é»‘é©¬åˆ†æå¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return []

    @staticmethod
    def analyze_baima_stocks(market_states_data: pl.DataFrame, intervals=None, min_market_cap: float = 100, exclude_st=True, include_non_main_board=False, include_main_board=True, include_kcb_cyb=True, include_bjs=False) -> dict:
        """å¢å¼ºçš„ç™½é©¬åˆ†æ - æ”¯æŒå¤šæ—¶é—´åŒºé—´å¯¹æ¯”ï¼ŒåŒ…å«è¡Œä¸šå’Œæ¦‚å¿µä¿¡æ¯"""
        try:
            print(f"ğŸ”§ DEBUG: å¼€å§‹å¢å¼ºç™½é©¬åˆ†æ")
            print(f"  - æ•°æ®è¡Œæ•°: {market_states_data.height}")
            print(f"  - æ—¶é—´åŒºé—´æ•°: {len(intervals) if intervals else 0}")

            # ä½¿ç”¨ä¼ å…¥çš„å¸‚åœºçŠ¶æ€æ•°æ®ï¼Œå®ƒå·²ç»åŒ…å«äº†è‚¡ç¥¨çš„åŸºæœ¬ä¿¡æ¯
            # market_states_data åŒ…å«äº†æ‰€æœ‰éœ€è¦çš„è‚¡ç¥¨æ•°æ®
            print(f"  - å¸‚åœºæ•°æ®åˆ—: {market_states_data.columns[:10]}...")

            # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
            required_cols = ['ä»£ç ', 'åç§°', 'æ—¥æœŸ', 'æ”¶ç›˜']
            missing_cols = [col for col in required_cols if col not in market_states_data.columns]
            if missing_cols:
                return {'error': f'ç¼ºå°‘å¿…è¦çš„åˆ—: {missing_cols}'}

            # å°è¯•åŠ è½½å’Œåˆå¹¶è¡Œä¸šã€æ¦‚å¿µæ•°æ®
            enhanced_data = market_states_data
            try:
                import os
                import pandas as pd

                # æ£€æŸ¥å®é™…å­˜åœ¨çš„æ–‡ä»¶
                ths_file = 'data_cache/sectors/åŒèŠ±é¡ºæ¿å—æˆåˆ†è‚¡.xlsx'
                dc_file = 'data_cache/sectors/ä¸œè´¢æ¿å—æˆåˆ†è‚¡.xlsx'

                if os.path.exists(ths_file):
                    print("ğŸ”§ DEBUG: åŠ è½½åŒèŠ±é¡ºè¡Œä¸šå’Œæ¦‚å¿µæ•°æ®...")

                    # è¯»å–åŒèŠ±é¡ºæ•°æ®ï¼ˆåŒ…å«è¡Œä¸šå’Œæ¦‚å¿µï¼‰
                    ths_df = pd.read_excel(ths_file)
                    
                    # æ ‡å‡†åŒ–åˆ—å
                    ths_df = ths_df.rename(columns={
                        'è‚¡ç¥¨ä»£ç ': 'ä»£ç ',
                        'è‚¡ç¥¨åç§°': 'åç§°',
                        'æ¿å—åç§°': 'æ¿å—åç§°'
                    })
                    
                    # ç¡®ä¿ä»£ç ä¸º6ä½å­—ç¬¦ä¸²
                    ths_df['ä»£ç '] = ths_df['ä»£ç '].astype(str).str.zfill(6)
                    ths_pl = pl.from_pandas(ths_df)

                    # åˆ†åˆ«å¤„ç†è¡Œä¸šå’Œæ¦‚å¿µæ•°æ®
                    industry_data = ths_pl.filter(pl.col("æ¿å—ç±»å‹") == "è¡Œä¸š")
                    concept_data = ths_pl.filter(pl.col("æ¿å—ç±»å‹") == "æ¦‚å¿µ")

                    # å¤„ç†è¡Œä¸šæ•°æ® - æ¯ä¸ªè‚¡ç¥¨åªä¿ç•™ä¸€ä¸ªä¸»è¦è¡Œä¸š
                    industries_grouped = None
                    if industry_data.height > 0:
                        industries_grouped = (
                            industry_data
                            .group_by("ä»£ç ")
                            .agg([
                                pl.col("æ¿å—åç§°").first().alias("è¡Œä¸š"),
                            ])
                        )
                        print(f"ğŸ”§ DEBUG: å¤„ç†äº† {industries_grouped.height} åªè‚¡ç¥¨çš„è¡Œä¸šä¿¡æ¯")

                    # å¤„ç†æ¦‚å¿µæ•°æ® - åˆå¹¶å¤šä¸ªæ¦‚å¿µ
                    concepts_grouped = None
                    if concept_data.height > 0:
                        concepts_grouped = (
                            concept_data
                            .group_by("ä»£ç ")
                            .agg([
                                pl.col("æ¿å—åç§°").str.concat(",").alias("æ¦‚å¿µ"),
                            ])
                        )
                        print(f"ğŸ”§ DEBUG: å¤„ç†äº† {concepts_grouped.height} åªè‚¡ç¥¨çš„æ¦‚å¿µä¿¡æ¯")

                    # åˆå¹¶è¡Œä¸šå’Œæ¦‚å¿µä¿¡æ¯
                    sector_info = None
                    if industries_grouped is not None and concepts_grouped is not None:
                        sector_info = (
                            industries_grouped
                            .join(concepts_grouped, on="ä»£ç ", how="outer")
                            .select(["ä»£ç ", "è¡Œä¸š", "æ¦‚å¿µ"])
                        )
                    elif industries_grouped is not None:
                        sector_info = industries_grouped.select(["ä»£ç ", "è¡Œä¸š"])
                    elif concepts_grouped is not None:
                        sector_info = concepts_grouped.select(["ä»£ç ", "æ¦‚å¿µ"])

                    # ä¸å¸‚åœºæ•°æ®åˆå¹¶
                    if sector_info is not None:
                        enhanced_data = market_states_data.join(sector_info, on="ä»£ç ", how="left")
                        print(f"ğŸ”§ DEBUG: æˆåŠŸåˆå¹¶è¡Œä¸šæ¦‚å¿µæ•°æ®ï¼Œæ–°åˆ—æ•°: {len(enhanced_data.columns)}")
                        
                        # éªŒè¯åˆå¹¶ç»“æœ
                        if "è¡Œä¸š" in enhanced_data.columns:
                            non_null_industry_count = enhanced_data.filter(pl.col("è¡Œä¸š").is_not_null()).height
                            print(f"ğŸ”§ DEBUG: æœ‰è¡Œä¸šä¿¡æ¯çš„è‚¡ç¥¨æ•°é‡: {non_null_industry_count}")
                    else:
                        print("ğŸ”§ DEBUG: æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„è¡Œä¸šæ¦‚å¿µæ•°æ®")

                else:
                    print("ğŸ”§ DEBUG: åŒèŠ±é¡ºæ¿å—æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨åŸå§‹æ•°æ®")

            except Exception as e:
                print(f"âš ï¸ åŠ è½½è¡Œä¸šæ¦‚å¿µæ•°æ®å¤±è´¥: {str(e)}ï¼Œä½¿ç”¨åŸå§‹æ•°æ®")
                enhanced_data = market_states_data

            # å¦‚æœæ²¡æœ‰ä¼ å…¥æ—¶é—´åŒºé—´ï¼Œä½¿ç”¨é»˜è®¤æ—¶é—´åŒºé—´
            if intervals is None or len(intervals) == 0:
                from datetime import datetime, timedelta
                end_date = datetime.now().date()
                intervals = [
                    {
                        'start_date': (end_date - timedelta(days=30)).strftime('%Y-%m-%d'),
                        'end_date': end_date.strftime('%Y-%m-%d'),
                        'name': 'æœ€è¿‘30å¤©'
                    },
                    {
                        'start_date': (end_date - timedelta(days=90)).strftime('%Y-%m-%d'),
                        'end_date': end_date.strftime('%Y-%m-%d'),
                        'name': 'æœ€è¿‘90å¤©'
                    },
                    {
                        'start_date': f'{end_date.year}-01-01',
                        'end_date': end_date.strftime('%Y-%m-%d'),
                        'name': 'æœ¬å¹´åº¦'
                    }
                ]

            print(f"ğŸ”§ DEBUG: ä½¿ç”¨çš„æ—¶é—´åŒºé—´: {len(intervals)}ä¸ª")

            # å¼€å§‹ç­›é€‰è‚¡ç¥¨ - ä½¿ç”¨å¢å¼ºçš„æ•°æ®
            filtered_stocks = enhanced_data

            # æ„å»ºç­›é€‰æ¡ä»¶
            filter_conditions = []

            # STè‚¡ç¥¨ç­›é€‰
            if exclude_st:
                filter_conditions.append(~pl.col('åç§°').str.contains("ST"))

            # æ¿å—ç­›é€‰ï¼ˆåŸºäºè‚¡ç¥¨ä»£ç ï¼‰
            board_conditions = []

            # ä¸»æ¿è‚¡ç¥¨ç­›é€‰ï¼ˆæ²ªæ·±ä¸»æ¿ï¼š000ã€001ã€002ã€600ã€601ã€603å¼€å¤´ï¼‰
            if include_main_board:
                main_board_condition = (
                    pl.col("ä»£ç ").str.starts_with("000") |
                    pl.col("ä»£ç ").str.starts_with("001") |
                    pl.col("ä»£ç ").str.starts_with("002") |
                    pl.col("ä»£ç ").str.starts_with("600") |
                    pl.col("ä»£ç ").str.starts_with("601") |
                    pl.col("ä»£ç ").str.starts_with("603")
                )
                board_conditions.append(main_board_condition)

            # ç§‘åˆ›æ¿/åˆ›ä¸šæ¿è‚¡ç¥¨ç­›é€‰ï¼ˆç§‘åˆ›æ¿ï¼š688å¼€å¤´ï¼Œåˆ›ä¸šæ¿ï¼š300ã€301å¼€å¤´ï¼‰
            if include_kcb_cyb:
                kcb_cyb_condition = (
                    pl.col("ä»£ç ").str.starts_with("688") |
                    pl.col("ä»£ç ").str.starts_with("300") |
                    pl.col("ä»£ç ").str.starts_with("301")
                )
                board_conditions.append(kcb_cyb_condition)

            # åŒ—äº¤æ‰€è‚¡ç¥¨ç­›é€‰ï¼ˆ8ã€4å¼€å¤´ï¼‰
            if include_bjs:
                bjs_condition = (
                    pl.col("ä»£ç ").str.starts_with("8") |
                    pl.col("ä»£ç ").str.starts_with("4")
                )
                board_conditions.append(bjs_condition)

            # ç»„åˆæ¿å—æ¡ä»¶
            if board_conditions:
                board_condition = board_conditions[0]
                for condition in board_conditions[1:]:
                    board_condition = board_condition | condition
                filter_conditions.append(board_condition)

            # å¸‚å€¼ç­›é€‰ï¼ˆå¦‚æœæœ‰å¸‚å€¼åˆ—ï¼‰
            if 'å¸‚å€¼' in filtered_stocks.columns:
                filter_conditions.append(pl.col('å¸‚å€¼') >= min_market_cap * 100000000)  # è½¬æ¢ä¸ºå…ƒ

            # åº”ç”¨ç­›é€‰æ¡ä»¶
            if filter_conditions:
                combined_condition = filter_conditions[0]
                for condition in filter_conditions[1:]:
                    combined_condition = combined_condition & condition
                filtered_stocks = filtered_stocks.filter(combined_condition)

            print(f"ğŸ”§ DEBUG: è¿‡æ»¤åè‚¡ç¥¨æ•°: {filtered_stocks.height}")

            # é™ä½å¸‚å€¼è¦æ±‚ï¼Œå¦‚æœæ²¡æœ‰è‚¡ç¥¨
            if filtered_stocks.is_empty() and min_market_cap > 10:
                print(f"ğŸ”§ DEBUG: æ²¡æœ‰è‚¡ç¥¨æ»¡è¶³{min_market_cap}äº¿å¸‚å€¼è¦æ±‚ï¼Œé™ä½åˆ°10äº¿")
                # é‡æ–°ç­›é€‰ï¼Œé™ä½å¸‚å€¼è¦æ±‚
                filter_conditions_relaxed = [cond for cond in filter_conditions if 'å¸‚å€¼' not in str(cond)]
                if 'å¸‚å€¼' in enhanced_data.columns:
                    filter_conditions_relaxed.append(pl.col('å¸‚å€¼') >= 10 * 100000000)  # 10äº¿

                if filter_conditions_relaxed:
                    combined_condition = filter_conditions_relaxed[0]
                    for condition in filter_conditions_relaxed[1:]:
                        combined_condition = combined_condition & condition
                    filtered_stocks = enhanced_data.filter(combined_condition)
                    print(f"ğŸ”§ DEBUG: é™ä½å¸‚å€¼è¦æ±‚åè‚¡ç¥¨æ•°: {filtered_stocks.height}")

            if filtered_stocks.is_empty():
                return {
                    'intervals': [
                        {
                            'name': interval.get('name', f'åŒºé—´{i+1}'),
                            'start_date': interval['start_date'],
                            'end_date': interval['end_date'],
                            'column_name': f"{interval.get('name', f'åŒºé—´{i+1}')}æ¶¨è·Œå¹…"
                        }
                        for i, interval in enumerate(intervals)
                    ],
                    'stocks': [],
                    'total_count': 0,
                    'change_columns': [],
                    'min_market_cap': min_market_cap
                }

            # æŸ¥æ‰¾æ¯åªè‚¡ç¥¨çš„é¦–ä¸ªäº¤æ˜“æ—¥
            first_trading_days = filtered_stocks.group_by("ä»£ç ").agg([
                pl.col("æ—¥æœŸ").min().alias("é¦–ä¸ªäº¤æ˜“æ—¥")
            ])

            # å°†é¦–ä¸ªäº¤æ˜“æ—¥ä¿¡æ¯æ·»åŠ åˆ°filtered_stocksä¸­
            filtered_stocks_with_first_day = filtered_stocks.join(first_trading_days, on="ä»£ç ")

            # æ ‡è®°æ–°è‚¡çš„é¦–æ—¥æ•°æ®
            filtered_stocks_with_first_day = filtered_stocks_with_first_day.with_columns([
                (pl.col("æ—¥æœŸ") == pl.col("é¦–ä¸ªäº¤æ˜“æ—¥")).alias("æ˜¯é¦–æ—¥äº¤æ˜“")
            ])

            # ä¸ºæ¯ä¸ªåŒºé—´è®¡ç®—æ¶¨è·Œå¹…
            interval_results = []
            change_columns = []

            for i, interval in enumerate(intervals):
                # è§£ææ—¶é—´åŒºé—´
                if isinstance(interval, dict):
                    start_date_str = interval['start_date']
                    end_date_str = interval['end_date']
                    interval_name = interval.get('name', f'åŒºé—´{i+1}')
                else:
                    # å…¼å®¹æ—§æ ¼å¼ (start_date, end_date) tuple
                    start_date_str = interval[0].strftime('%Y-%m-%d') if hasattr(interval[0], 'strftime') else str(interval[0])
                    end_date_str = interval[1].strftime('%Y-%m-%d') if hasattr(interval[1], 'strftime') else str(interval[1])
                    interval_name = f'åŒºé—´{i+1}'

                # è½¬æ¢ä¸ºæ—¥æœŸå¯¹è±¡
                from datetime import datetime
                start_date = datetime.strptime(start_date_str, '%Y-%m-%d').date()
                end_date = datetime.strptime(end_date_str, '%Y-%m-%d').date()

                print(f"ğŸ”§ DEBUG: å¤„ç†åŒºé—´{i+1}: {start_date} åˆ° {end_date}")

                # è¿‡æ»¤æ—¥æœŸèŒƒå›´å†…çš„æ•°æ®
                interval_data = filtered_stocks_with_first_day.filter(
                    (pl.col("æ—¥æœŸ") >= start_date) &
                    (pl.col("æ—¥æœŸ") <= end_date)
                )

                if interval_data.is_empty():
                    print(f"âš ï¸ åŒºé—´{i+1}æ— æ•°æ®")
                    continue

                # è®¡ç®—æ¯ä¸ªè‚¡ç¥¨çš„æ¶¨è·Œå¹…å’Œæœ€é«˜æ¶¨è·Œå¹…ï¼ˆæ’é™¤é¦–æ—¥äº¤æ˜“æ•°æ®ï¼‰
                # æ„å»ºèšåˆåˆ—è¡¨
                agg_columns = [
                    # è·å–æœŸé—´é¦–ä¸ªäº¤æ˜“æ—¥çš„æ”¶ç›˜ä»·
                    pl.col("æ”¶ç›˜").first().alias("æœŸåˆæ”¶ç›˜ä»·"),
                    # è·å–æœŸé—´æœ€åä¸€ä¸ªäº¤æ˜“æ—¥çš„æ”¶ç›˜ä»·
                    pl.col("æ”¶ç›˜").last().alias("æœŸæœ«æ”¶ç›˜ä»·"),
                    # è·å–åŒºé—´å†…æœ€ä½ä»·å’Œæœ€é«˜ä»·
                    pl.col("æœ€ä½").min().alias("åŒºé—´æœ€ä½ä»·"),
                    pl.col("æœ€é«˜").max().alias("åŒºé—´æœ€é«˜ä»·"),
                    pl.col("åç§°").last().alias("åç§°"),
                ]

                # æ·»åŠ è¡Œä¸šä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if "è¡Œä¸š" in interval_data.columns:
                    agg_columns.append(pl.col("è¡Œä¸š").last().alias("è¡Œä¸š"))

                # æ·»åŠ æ¦‚å¿µä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if "æ¦‚å¿µ" in interval_data.columns:
                    agg_columns.append(pl.col("æ¦‚å¿µ").last().alias("æ¦‚å¿µ"))

                # æ·»åŠ å¸‚å€¼ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if "å¸‚å€¼" in interval_data.columns:
                    agg_columns.append(pl.col("å¸‚å€¼").last().alias("å¸‚å€¼"))

                stock_changes = (
                    interval_data
                    .filter(~pl.col("æ˜¯é¦–æ—¥äº¤æ˜“"))
                    .sort(["ä»£ç ", "æ—¥æœŸ"])  # ç¡®ä¿æŒ‰æ—¶é—´æ’åº
                    .group_by("ä»£ç ")
                    .agg(agg_columns)
                    .with_columns([
                        # è®¡ç®—åŒºé—´æ¶¨è·Œå¹…ï¼ˆæœŸåˆåˆ°æœŸæœ«ï¼‰
                        ((pl.col("æœŸæœ«æ”¶ç›˜ä»·") - pl.col("æœŸåˆæ”¶ç›˜ä»·")) / pl.col("æœŸåˆæ”¶ç›˜ä»·") * 100)
                        .alias(f"{interval_name}æ¶¨è·Œå¹…"),
                        # è®¡ç®—åŒºé—´å†…æœ€é«˜æ¶¨è·Œå¹…ï¼ˆæœŸåˆä»·æ ¼åˆ°åŒºé—´æœ€é«˜ä»·ï¼‰
                        ((pl.col("åŒºé—´æœ€é«˜ä»·") - pl.col("æœŸåˆæ”¶ç›˜ä»·")) / pl.col("æœŸåˆæ”¶ç›˜ä»·") * 100)
                        .alias(f"{interval_name}æœ€é«˜æ¶¨è·Œå¹…")
                    ])
                )

                change_col_name = f"{interval_name}æ¶¨è·Œå¹…"
                max_change_col_name = f"{interval_name}æœ€é«˜æ¶¨è·Œå¹…"
                change_columns.append(change_col_name)
                change_columns.append(max_change_col_name)

                # åªä¿ç•™éœ€è¦çš„åˆ—ï¼Œé¿å…é‡å¤
                if i == 0:
                    # ç¬¬ä¸€ä¸ªåŒºé—´ä¿ç•™æ‰€æœ‰åŸºç¡€ä¿¡æ¯å’Œæ¶¨è·Œå¹…
                    select_columns = ["ä»£ç ", "åç§°"]

                    # æ·»åŠ è¡Œä¸šä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                    if "è¡Œä¸š" in stock_changes.columns:
                        select_columns.append("è¡Œä¸š")

                    # æ·»åŠ æ¦‚å¿µä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                    if "æ¦‚å¿µ" in stock_changes.columns:
                        select_columns.append("æ¦‚å¿µ")

                    # æ·»åŠ å¸‚å€¼ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                    if "å¸‚å€¼" in stock_changes.columns:
                        select_columns.append("å¸‚å€¼")

                    # æ·»åŠ æ¶¨è·Œå¹…åˆ—å’Œæœ€é«˜æ¶¨è·Œå¹…åˆ—
                    select_columns.append(change_col_name)
                    select_columns.append(max_change_col_name)

                    stock_changes = stock_changes.select(select_columns)
                else:
                    # åç»­åŒºé—´åªä¿ç•™ä»£ç ã€æ¶¨è·Œå¹…å’Œæœ€é«˜æ¶¨è·Œå¹…
                    stock_changes = stock_changes.select([
                        "ä»£ç ", change_col_name, max_change_col_name
                    ])

                interval_results.append(stock_changes)

            # åˆå¹¶æ‰€æœ‰åŒºé—´ç»“æœ
            if interval_results:
                # ä»ç¬¬ä¸€ä¸ªåŒºé—´å¼€å§‹
                result_df = interval_results[0]

                # é€ä¸ªåˆå¹¶å…¶ä»–åŒºé—´
                for i in range(1, len(interval_results)):
                    result_df = result_df.join(
                        interval_results[i],
                        on="ä»£ç ",
                        how="outer"
                    )

                # å¤„ç†å¯èƒ½çš„nullå€¼
                for col in change_columns:
                    if col in result_df.columns:
                        result_df = result_df.with_columns([
                            pl.col(col).fill_null(0)
                        ])

                # æŒ‰ç¬¬ä¸€ä¸ªåŒºé—´çš„æ¶¨è·Œå¹…æ’åº
                if change_columns:
                    first_change_col = change_columns[0]
                    result_df = result_df.sort(first_change_col, descending=True)

                # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼è¿”å›ï¼Œç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
                try:
                    # å…ˆå¤„ç†å¯èƒ½çš„æ•°æ®ç±»å‹é—®é¢˜
                    for col in result_df.columns:
                        if col in ['è¡Œä¸š', 'æ¦‚å¿µ']:
                            # ç¡®ä¿å­—ç¬¦ä¸²ç±»å‹çš„åˆ—æ­£ç¡®å¤„ç†
                            result_df = result_df.with_columns([
                                pl.col(col).cast(pl.Utf8).fill_null("")
                            ])

                    result_data = result_df.to_dicts()

                    # éªŒè¯æ•°æ®å®Œæ•´æ€§
                    if result_data:
                        sample_stock = result_data[0]
                        print(f"ğŸ”§ DEBUG: ç¤ºä¾‹è‚¡ç¥¨æ•°æ®å­—æ®µ: {list(sample_stock.keys())}")
                        if 'è¡Œä¸š' in sample_stock:
                            print(f"ğŸ”§ DEBUG: ç¤ºä¾‹è¡Œä¸šæ•°æ®: {sample_stock['è¡Œä¸š']}")

                except Exception as e:
                    print(f"âš ï¸ æ•°æ®è½¬æ¢è­¦å‘Š: {str(e)}")
                    # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œå°è¯•ç®€åŒ–å¤„ç†
                    result_data = []
                    for row in result_df.iter_rows(named=True):
                        stock_dict = {}
                        for key, value in row.items():
                            # å¤„ç†ç‰¹æ®Šæ•°æ®ç±»å‹
                            if value is None:
                                stock_dict[key] = None
                            elif isinstance(value, (int, float, str)):
                                stock_dict[key] = value
                            else:
                                stock_dict[key] = str(value)
                        result_data.append(stock_dict)

                print(f"âœ… ç™½é©¬åˆ†æå®Œæˆ: {len(result_data)} åªè‚¡ç¥¨, {len(change_columns)} ä¸ªåŒºé—´")

                return {
                    'intervals': [
                        {
                            'name': interval.get('name', f'åŒºé—´{i+1}'),
                            'start_date': interval['start_date'],
                            'end_date': interval['end_date'],
                            'column_name': f"{interval.get('name', f'åŒºé—´{i+1}')}æ¶¨è·Œå¹…"
                        }
                        for i, interval in enumerate(intervals)
                    ],
                    'stocks': result_data,
                    'total_count': len(result_data),
                    'change_columns': change_columns,
                    'min_market_cap': min_market_cap
                }
            else:
                return {
                    'intervals': [],
                    'stocks': [],
                    'total_count': 0,
                    'change_columns': [],
                    'min_market_cap': min_market_cap
                }

        except Exception as e:
            print(f"âŒ å¢å¼ºç™½é©¬åˆ†æå¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return {'error': str(e)}

    @staticmethod
    def _calculate_change_distribution(market_df: pl.DataFrame, change_col: str) -> dict:
        """è®¡ç®—æ¶¨è·Œå¹…åˆ†å¸ƒ"""
        try:
            # å®šä¹‰æ¶¨è·Œå¹…åŒºé—´ï¼ˆä½¿ç”¨æ•°å€¼æ ‡ç­¾ï¼‰
            ranges = [
                ('â‰¤-9.5%', -20, -9.5),
                ('-9.5%~-5%', -9.5, -5),
                ('-5%~-3%', -5, -3),
                ('-3%~-1%', -3, -1),
                ('-1%~0%', -1, 0),
                ('0%~1%', 0, 1),
                ('1%~3%', 1, 3),
                ('3%~5%', 3, 5),
                ('5%~9.5%', 5, 9.5),
                ('â‰¥9.5%', 9.5, 20)
            ]

            distribution = []
            total_count = market_df.height

            for label, min_val, max_val in ranges:
                if min_val == -20:  # è·ŒåœåŒºé—´ï¼ŒåŒ…å«ä¸‹è¾¹ç•Œ
                    count = market_df.filter(
                        (pl.col(change_col) >= min_val) & (pl.col(change_col) < max_val)
                    ).height
                elif max_val == 20:  # æ¶¨åœåŒºé—´ï¼ŒåŒ…å«ä¸Šè¾¹ç•Œ
                    count = market_df.filter(
                        (pl.col(change_col) > min_val) & (pl.col(change_col) <= max_val)
                    ).height
                else:  # å…¶ä»–åŒºé—´ï¼Œä¸åŒ…å«è¾¹ç•Œ
                    count = market_df.filter(
                        (pl.col(change_col) > min_val) & (pl.col(change_col) <= max_val)
                    ).height

                percentage = round((count / total_count * 100), 2) if total_count > 0 else 0

                distribution.append({
                    'label': label,
                    'count': count,
                    'percentage': percentage,
                    'range': f"{min_val}% ~ {max_val}%"
                })

            return {
                'ranges': distribution,
                'total_count': total_count
            }

        except Exception as e:
            print(f"è®¡ç®—æ¶¨è·Œå¹…åˆ†å¸ƒå¤±è´¥: {str(e)}")
            return {
                'ranges': [],
                'total_count': 0
            }

    @staticmethod
    def get_money_effect_analysis(date_str, analysis_type='all', market_states=None,
                                exclude_st=True, include_non_main_board=False):
        """
        è·å–èµšé’±æ•ˆåº”åˆ†ææ•°æ®
        åˆ†ä¸ºä¸¤ä¸ªéƒ¨åˆ†ï¼šå…¨éƒ¨è‚¡ç¥¨èµšé’±æ•ˆåº”ï¼ˆå‰300ï¼‰å’Œè¿‘æœŸå¼ºåŠ¿è‚¡ï¼ˆæ›¾3æ¿ä»¥ä¸Šï¼‰

        Args:
            date_str: åˆ†ææ—¥æœŸ (YYYYMMDDæ ¼å¼)
            analysis_type: åˆ†æç±»å‹ 'all'=å…¨éƒ¨è‚¡ç¥¨å‰300, 'strong'=è¿‘æœŸå¼ºåŠ¿è‚¡(æ›¾3æ¿ä»¥ä¸Š)
            market_states: é¢„åŠ è½½çš„å¸‚åœºçŠ¶æ€æ•°æ®ï¼Œé¿å…é‡å¤åŠ è½½
            exclude_st: æ˜¯å¦æ’é™¤STå’Œé€€å¸‚è‚¡ç¥¨ï¼Œé»˜è®¤True
            include_non_main_board: æ˜¯å¦åŒ…å«éä¸»æ¿è‚¡ç¥¨ï¼Œé»˜è®¤False

        Returns:
            dict: åŒ…å«è‚¡ç¥¨åˆ—è¡¨å’Œç»Ÿè®¡æ•°æ®
        """
        try:
            print(f"ğŸ” å¼€å§‹èµšé’±æ•ˆåº”åˆ†æ: date={date_str}, type={analysis_type}")

            # ä½¿ç”¨ä¼ å…¥çš„å¸‚åœºçŠ¶æ€æ•°æ®ï¼Œé¿å…é‡å¤åŠ è½½
            if market_states is None or market_states.is_empty():
                return {
                    'stocks': [],
                    'stats': {},
                    'message': 'æ— æ³•è·å–å¸‚åœºæ•°æ®'
                }

            # è½¬æ¢æ—¥æœŸæ ¼å¼
            target_date = pd.to_datetime(date_str, format='%Y%m%d').date()

            if analysis_type == 'all':
                # å…¨éƒ¨è‚¡ç¥¨èµšé’±æ•ˆåº”åˆ†æï¼ˆå‰300ï¼‰
                return MarketAnalyzer._analyze_all_stocks_money_effect(
                    target_date, market_states, exclude_st, include_non_main_board)
            elif analysis_type == 'strong':
                # è¿‘æœŸå¼ºåŠ¿è‚¡åˆ†æï¼ˆæ›¾3æ¿ä»¥ä¸Šï¼‰
                return MarketAnalyzer._analyze_strong_stocks_money_effect(
                    target_date, market_states, exclude_st, include_non_main_board)
            else:
                return {
                    'stocks': [],
                    'stats': {},
                    'message': f'ä¸æ”¯æŒçš„åˆ†æç±»å‹: {analysis_type}'
                }



        except Exception as e:
            print(f"âŒ èµšé’±æ•ˆåº”åˆ†æå¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return {
                'stocks': [],
                'stats': {},
                'message': str(e)
            }

    @staticmethod
    def _analyze_all_stocks_money_effect(target_date, market_states, exclude_st=True, include_non_main_board=False):
        """
        åˆ†æå…¨éƒ¨è‚¡ç¥¨çš„èµšé’±æ•ˆåº”
        è®¡ç®—å½“æ—¥æœ€ä½ç‚¹åˆ°æ”¶ç›˜ä»·çš„æ¶¨è·Œå¹…ï¼ŒæŒ‰æ¶¨å¹…æ’åºå–å‰300

        Args:
            target_date: ç›®æ ‡æ—¥æœŸ
            market_states: å¸‚åœºçŠ¶æ€æ•°æ®
            exclude_st: æ˜¯å¦æ’é™¤STå’Œé€€å¸‚è‚¡ç¥¨
            include_non_main_board: æ˜¯å¦åŒ…å«éä¸»æ¿è‚¡ç¥¨
        """
        try:
            print(f"ğŸ“Š åˆ†æå…¨éƒ¨è‚¡ç¥¨èµšé’±æ•ˆåº”: {target_date}")

            # è·å–ç›®æ ‡æ—¥æœŸçš„æ‰€æœ‰è‚¡ç¥¨æ•°æ®
            target_data = market_states.filter(pl.col('æ—¥æœŸ') == target_date)

            if target_data.is_empty():
                return {
                    'stocks': [],
                    'stats': {},
                    'message': f'æ—¥æœŸ {target_date} æ— æ•°æ®'
                }

            # åº”ç”¨è‚¡ç¥¨ç­›é€‰
            if exclude_st:
                # æ’é™¤STå’Œé€€å¸‚è‚¡ç¥¨
                target_data = target_data.filter(
                    ~pl.col('åç§°').str.contains("ST", literal=False) &
                    ~pl.col('åç§°').str.contains("é€€", literal=False)
                )

            if not include_non_main_board:
                # åªåŒ…å«ä¸»æ¿è‚¡ç¥¨ï¼ˆ000ã€001ã€002ã€600ã€601ã€603ã€605å¼€å¤´ï¼‰
                target_data = target_data.filter(
                    pl.col('ä»£ç ').str.starts_with("00") |
                    pl.col('ä»£ç ').str.starts_with("60")
                )

            print(f"ğŸ“ˆ ç›®æ ‡æ—¥æœŸè‚¡ç¥¨æ•°é‡: {len(target_data)}")

            # è®¡ç®—èµšé’±æ•ˆåº”æŒ‡æ ‡
            money_effect_stocks = []

            for row in target_data.to_dicts():
                # è®¡ç®—æœ€ä½åˆ°æ”¶ç›˜çš„æ¶¨è·Œå¹…ï¼ˆèµšé’±æ•ˆåº”ï¼‰
                low_price = row.get('æœ€ä½', 0)
                close_price = row.get('æ”¶ç›˜', 0)
                low_to_close_change = ((close_price - low_price) / low_price * 100) if low_price > 0 else 0

                # è®¡ç®—æœ€é«˜åˆ°æ”¶ç›˜çš„æ¶¨è·Œå¹…ï¼ˆäºé’±æ•ˆåº”ï¼‰
                high_price = row.get('æœ€é«˜', 0)
                high_to_close_change = ((close_price - high_price) / high_price * 100) if high_price > 0 else 0

                # å®‰å…¨çš„å››èˆäº”å…¥ï¼Œå¤„ç†Noneå€¼
                def safe_round(value, digits=2):
                    return round(value, digits) if value is not None else 0.0

                money_effect_stocks.append({
                    'åç§°': row.get('åç§°', ''),
                    'ä»£ç ': row.get('ä»£ç ', ''),
                    'è¿æ¿å¤©æ•°': row.get('è¿æ¿æ•°', 0),
                    'æœ€ä½åˆ°æ”¶ç›˜æ¶¨å¹…': round(low_to_close_change, 2),
                    'æœ€é«˜åˆ°æ”¶ç›˜æ¶¨å¹…': round(high_to_close_change, 2),
                    'å½“æ—¥æ¶¨è·Œå¹…': safe_round(row.get('æ¶¨è·Œå¹…')),
                    '5æ—¥æ¶¨è·Œå¹…': safe_round(row.get('5æ—¥æ¶¨è·Œå¹…')),
                    '10æ—¥æ¶¨è·Œå¹…': safe_round(row.get('10æ—¥æ¶¨è·Œå¹…')),
                    '20æ—¥æ¶¨è·Œå¹…': safe_round(row.get('20æ—¥æ¶¨è·Œå¹…')),
                    'æ”¶ç›˜ä»·': safe_round(row.get('æ”¶ç›˜')),
                    'æˆäº¤é¢': safe_round(row.get('æˆäº¤é¢'))
                })

            # æŒ‰æœ€ä½åˆ°æ”¶ç›˜æ¶¨å¹…æ’åºï¼Œå–å‰300
            money_effect_stocks.sort(key=lambda x: x['æœ€ä½åˆ°æ”¶ç›˜æ¶¨å¹…'], reverse=True)
       

            # è®¡ç®—ç»Ÿè®¡æ•°æ®
            stats = MarketAnalyzer._calculate_money_effect_stats(money_effect_stocks)

            print(f"âœ… å…¨éƒ¨è‚¡ç¥¨èµšé’±æ•ˆåº”åˆ†æå®Œæˆï¼Œå‰300åªè‚¡ç¥¨")

            return {
                'stocks': money_effect_stocks,
                'stats': stats,
                'message': f'å…¨éƒ¨è‚¡ç¥¨èµšé’±æ•ˆåº”åˆ†æå®Œæˆï¼Œæ˜¾ç¤ºå‰300åªè‚¡ç¥¨'
            }

        except Exception as e:
            print(f"âŒ å…¨éƒ¨è‚¡ç¥¨èµšé’±æ•ˆåº”åˆ†æå¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return {
                'stocks': [],
                'stats': {},
                'message': str(e)
            }

    @staticmethod
    def _analyze_strong_stocks_money_effect(target_date, market_states, exclude_st=True, include_non_main_board=False):
        """
        åˆ†æè¿‘æœŸå¼ºåŠ¿è‚¡çš„èµšé’±æ•ˆåº”ï¼ˆæ›¾3æ¿ä»¥ä¸Šï¼‰
        æ˜¾ç¤ºè¿‘åå¤©å†…æ›¾ç»è¾¾åˆ°3æ¿ä»¥ä¸Šçš„è‚¡ç¥¨

        Args:
            target_date: ç›®æ ‡æ—¥æœŸ
            market_states: å¸‚åœºçŠ¶æ€æ•°æ®
            exclude_st: æ˜¯å¦æ’é™¤STå’Œé€€å¸‚è‚¡ç¥¨
            include_non_main_board: æ˜¯å¦åŒ…å«éä¸»æ¿è‚¡ç¥¨
        """
        try:
            print(f"ğŸ“Š åˆ†æè¿‘æœŸå¼ºåŠ¿è‚¡èµšé’±æ•ˆåº”ï¼ˆæ›¾3æ¿ä»¥ä¸Šï¼‰: {target_date}")

            # è·å–è¿‘åå¤©çš„æ—¥æœŸèŒƒå›´
            end_date = target_date
            start_date = end_date - timedelta(days=10)

            print(f"ğŸ“… åˆ†ææ—¥æœŸèŒƒå›´: {start_date} åˆ° {end_date}")

            # ç­›é€‰æ—¥æœŸèŒƒå›´å†…çš„æ•°æ®
            date_filtered = market_states.filter(
                (pl.col('æ—¥æœŸ') >= start_date) &
                (pl.col('æ—¥æœŸ') <= end_date)
            )

            if date_filtered.is_empty():
                return {
                    'stocks': [],
                    'stats': {},
                    'message': f'æŒ‡å®šæ—¥æœŸèŒƒå›´å†…æ— æ•°æ®'
                }

            print(f"ğŸ“Š æ—¥æœŸèŒƒå›´å†…æ•°æ®: {len(date_filtered)} æ¡è®°å½•")

            # åº”ç”¨è‚¡ç¥¨ç­›é€‰
            filtered_data = date_filtered
            if exclude_st:
                # æ’é™¤STå’Œé€€å¸‚è‚¡ç¥¨
                filtered_data = filtered_data.filter(
                    ~pl.col('åç§°').str.contains("ST", literal=False) &
                    ~pl.col('åç§°').str.contains("é€€", literal=False)
                )

            if not include_non_main_board:
                # åªåŒ…å«ä¸»æ¿è‚¡ç¥¨ï¼ˆ000ã€001ã€002ã€600ã€601ã€603ã€605å¼€å¤´ï¼‰
                filtered_data = filtered_data.filter(
                    pl.col('ä»£ç ').str.starts_with("00") |
                    pl.col('ä»£ç ').str.starts_with("60")
                )

            # æ‰¾å‡ºæ›¾ç»3æ¿ä»¥ä¸Šçš„è‚¡ç¥¨
            strong_stocks_data = filtered_data.filter(pl.col('è¿æ¿æ•°') >= 3)

            if strong_stocks_data.is_empty():
                return {
                    'stocks': [],
                    'stats': {},
                    'message': f'è¿‘åå¤©å†…æ— 3è¿æ¿ä»¥ä¸Šè‚¡ç¥¨'
                }

            print(f"ğŸ¯ æ‰¾åˆ° {len(strong_stocks_data)} æ¡å¼ºåŠ¿è‚¡è®°å½•")

            # è·å–è¿™äº›è‚¡ç¥¨åœ¨ç›®æ ‡æ—¥æœŸçš„æ•°æ®
            strong_stock_names = strong_stocks_data['åç§°'].unique().to_list()
            target_data = market_states.filter(
                (pl.col('æ—¥æœŸ') == target_date) &
                (pl.col('åç§°').is_in(strong_stock_names))
            )

            if target_data.is_empty():
                return {
                    'stocks': [],
                    'stats': {},
                    'message': f'ç›®æ ‡æ—¥æœŸæ— å¼ºåŠ¿è‚¡æ•°æ®'
                }

            print(f"ğŸ“ˆ ç›®æ ‡æ—¥æœŸå¼ºåŠ¿è‚¡æ•°é‡: {len(target_data)}")

            # è®¡ç®—èµšé’±æ•ˆåº”æŒ‡æ ‡
            money_effect_stocks = []

            for row in target_data.to_dicts():
                # è®¡ç®—æœ€ä½åˆ°æ”¶ç›˜çš„æ¶¨è·Œå¹…ï¼ˆèµšé’±æ•ˆåº”ï¼‰
                low_price = row.get('æœ€ä½', 0)
                close_price = row.get('æ”¶ç›˜', 0)
                low_to_close_change = ((close_price - low_price) / low_price * 100) if low_price > 0 else 0

                # è®¡ç®—æœ€é«˜åˆ°æ”¶ç›˜çš„æ¶¨è·Œå¹…ï¼ˆäºé’±æ•ˆåº”ï¼‰
                high_price = row.get('æœ€é«˜', 0)
                high_to_close_change = ((close_price - high_price) / high_price * 100) if high_price > 0 else 0

                # è·å–è¯¥è‚¡ç¥¨çš„å†å²æœ€é«˜è¿æ¿æ•°
                stock_name = row.get('åç§°', '')
                max_board_days = strong_stocks_data.filter(
                    pl.col('åç§°') == stock_name
                )['è¿æ¿æ•°'].max()

                # å®‰å…¨çš„å››èˆäº”å…¥ï¼Œå¤„ç†Noneå€¼
                def safe_round(value, digits=2):
                    return round(value, digits) if value is not None else 0.0

                money_effect_stocks.append({
                    'åç§°': stock_name,
                    'ä»£ç ': row.get('ä»£ç ', ''),
                    'è¿æ¿å¤©æ•°': row.get('è¿æ¿æ•°', 0),  # å½“å‰è¿æ¿æ•°
                    'å†å²æœ€é«˜è¿æ¿': max_board_days,  # å†å²æœ€é«˜è¿æ¿æ•°
                    'æœ€ä½åˆ°æ”¶ç›˜æ¶¨å¹…': round(low_to_close_change, 2),
                    'æœ€é«˜åˆ°æ”¶ç›˜æ¶¨å¹…': round(high_to_close_change, 2),
                    'å½“æ—¥æ¶¨è·Œå¹…': safe_round(row.get('æ¶¨è·Œå¹…')),
                    '5æ—¥æ¶¨è·Œå¹…': safe_round(row.get('5æ—¥æ¶¨è·Œå¹…')),
                    '10æ—¥æ¶¨è·Œå¹…': safe_round(row.get('10æ—¥æ¶¨è·Œå¹…')),
                    '20æ—¥æ¶¨è·Œå¹…': safe_round(row.get('20æ—¥æ¶¨è·Œå¹…')),
                    'æ”¶ç›˜ä»·': safe_round(row.get('æ”¶ç›˜')),
                    'æˆäº¤é¢': safe_round(row.get('æˆäº¤é¢'))
                })

            # æŒ‰æœ€ä½åˆ°æ”¶ç›˜æ¶¨å¹…æ’åº
            money_effect_stocks.sort(key=lambda x: x['æœ€ä½åˆ°æ”¶ç›˜æ¶¨å¹…'], reverse=True)

            # è®¡ç®—ç»Ÿè®¡æ•°æ®
            stats = MarketAnalyzer._calculate_money_effect_stats(money_effect_stocks)

            print(f"âœ… è¿‘æœŸå¼ºåŠ¿è‚¡èµšé’±æ•ˆåº”åˆ†æå®Œæˆï¼Œæ‰¾åˆ° {len(money_effect_stocks)} åªè‚¡ç¥¨")

            return {
                'stocks': money_effect_stocks,
                'stats': stats,
                'message': f'è¿‘æœŸå¼ºåŠ¿è‚¡èµšé’±æ•ˆåº”åˆ†æå®Œæˆï¼Œæ‰¾åˆ° {len(money_effect_stocks)} åªæ›¾3æ¿ä»¥ä¸Šè‚¡ç¥¨'
            }

        except Exception as e:
            print(f"âŒ è¿‘æœŸå¼ºåŠ¿è‚¡èµšé’±æ•ˆåº”åˆ†æå¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return {
                'stocks': [],
                'stats': {},
                'message': str(e)
            }

    @staticmethod
    def _calculate_money_effect_stats(stocks_data):
        """
        è®¡ç®—èµšé’±æ•ˆåº”ç»Ÿè®¡æ•°æ®

        Args:
            stocks_data: è‚¡ç¥¨æ•°æ®åˆ—è¡¨

        Returns:
            dict: ç»Ÿè®¡æ•°æ®
        """
        try:
            if not stocks_data:
                return {
                    'totalStocks': 0,
                    'avgLowToClose': 0,
                    'avgHighToClose': 0,
                    'avg5DayChange': 0,
                    'avg10DayChange': 0
                }

            total_stocks = len(stocks_data)

            # è®¡ç®—å¹³å‡å€¼
            avg_low_to_close = sum(stock['æœ€ä½åˆ°æ”¶ç›˜æ¶¨å¹…'] for stock in stocks_data) / total_stocks
            avg_high_to_close = sum(stock['æœ€é«˜åˆ°æ”¶ç›˜æ¶¨å¹…'] for stock in stocks_data) / total_stocks
            avg_5day = sum(stock['5æ—¥æ¶¨è·Œå¹…'] for stock in stocks_data) / total_stocks
            avg_10day = sum(stock['10æ—¥æ¶¨è·Œå¹…'] for stock in stocks_data) / total_stocks

            return {
                'totalStocks': total_stocks,
                'avgLowToClose': round(avg_low_to_close, 2),
                'avgHighToClose': round(avg_high_to_close, 2),
                'avg5DayChange': round(avg_5day, 2),
                'avg10DayChange': round(avg_10day, 2)
            }

        except Exception as e:
            print(f"è®¡ç®—ç»Ÿè®¡æ•°æ®å¤±è´¥: {str(e)}")
            return {
                'totalStocks': 0,
                'avgLowToClose': 0,
                'avgHighToClose': 0,
                'avg5DayChange': 0,
                'avg10DayChange': 0
            }

    @staticmethod
    def get_index_data(index_name: str, date_str: str, days_range: int = 180):
        """è·å–å•ä¸ªæŒ‡æ•°çš„æ•°æ®"""
        try:
            print(f"ğŸ”§ è·å–æŒ‡æ•°æ•°æ®: {index_name}, æ—¥æœŸ: {date_str}, å¤©æ•°: {days_range}")

            from utils.data_fetcher import DataFetcher
            data_fetcher = DataFetcher()

            # æŒ‡æ•°ä»£ç æ˜ å°„
            index_code_map = {
                'ä¸Šè¯æŒ‡æ•°': '000001',
                'æ·±è¯æˆæŒ‡': '399001',
                'åˆ›ä¸šæ¿æŒ‡': '399006',
                'ä¸­è¯2000': '932000',
                'ç§‘åˆ›50': '000688',
                'åŒ—è¯50': '899050',
                'ä¸­è¯500': '000905',
                'æ²ªæ·±300': '000300'
            }

            index_code = index_code_map.get(index_name)
            if not index_code:
                print(f"âŒ æœªçŸ¥çš„æŒ‡æ•°åç§°: {index_name}")
                return None

            # è®¡ç®—å¼€å§‹æ—¥æœŸ
            from datetime import datetime, timedelta
            end_date = datetime.strptime(date_str, '%Y%m%d').date()
            start_date = end_date - timedelta(days=days_range)
            start_date_str = start_date.strftime('%Y%m%d')

            print(f"ğŸ“Š æŸ¥è¯¢æŒ‡æ•° {index_name}({index_code}) ä» {start_date_str} åˆ° {date_str}")

            # ä»æŒ‡æ•°å…ƒæ•°æ®ä¸­è·å–æ•°æ®
            df = data_fetcher.index_metadata_manager.get_index_data(
                index_code,
                start_date=start_date_str,
                end_date=date_str
            )

            if df is not None and not df.is_empty():
                print(f"âœ… è·å–åˆ° {index_name} æ•°æ®ï¼Œå…± {df.height} è¡Œ")
                return df
            else:
                print(f"âŒ æœªè·å–åˆ° {index_name} æ•°æ®")
                return None

        except Exception as e:
            print(f"âŒ è·å–æŒ‡æ•° {index_name} æ•°æ®å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None