#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®è·å–å™¨ - æ¸…ç†ç‰ˆæœ¬ï¼Œåªä¿ç•™çº¯æ•°æ®è·å–åŠŸèƒ½
è¿ç§»åçš„æ¶æ„ï¼šåªè´Ÿè´£ä»å„ç§æ•°æ®æºè·å–åŸå§‹æ•°æ®
"""

import akshare as ak
import polars as pl
from datetime import datetime, timedelta, date, time as dt_time
from .data_cache import DataCache
from typing import Dict, Optional, Union, List, Tuple
from pathlib import Path
import os
import pandas as pd
import time
import threading

# å¯¼å…¥metadataç®¡ç†å™¨
from .metadata.stock_data_manager import StockMetadataManager
from .metadata.index_data_manager import IndexMetadataManager
from .metadata.market_data_manager import MarketMetadataManager
from .metadata.sector_data_manager import SectorDataManager


class LocalFileDataFetcher:
    """ä»æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿè·å–æ•°æ®"""
    def __init__(self, data_dir: str = "E:/jupyter/å¤§A/all_stock_candle/stock/daily"):
        super().__init__()
        self.data_dir = data_dir
        print(f"åˆå§‹åŒ–æœ¬åœ°æ–‡ä»¶æ•°æ®è·å–å™¨ï¼Œæ•°æ®ç›®å½•: {data_dir}")
        
        # ç¡®ä¿stock_metadata_managerå’Œindex_metadata_managerå·²æ­£ç¡®åˆå§‹åŒ–
        self.stock_metadata_manager = StockMetadataManager()
        self.index_metadata_manager = IndexMetadataManager()
        
        # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
        if not os.path.exists(data_dir):
            raise FileNotFoundError(f"æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
            
        # è·å–å¯ç”¨çš„è‚¡ç¥¨ä»£ç åˆ—è¡¨
        self.available_stocks = self._get_available_stocks()
        print(f"æ‰¾åˆ° {len(self.available_stocks)} åªè‚¡ç¥¨çš„æœ¬åœ°æ•°æ®")
    
    def _is_bond_code(self, stock_code: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºå€ºåˆ¸ä»£ç """
        # å®šä¹‰éœ€è¦å¿½ç•¥çš„å€ºåˆ¸ä»£ç åˆ—è¡¨
        ignore_codes = [
            'sh600001', 'sh600002', 'sh600003', 'sh600065', 'sh600087', 'sh600092',
            'sh600102', 'sh600181', 'sh600205', 'sh600253', 'sh600263', 'sh600286',
            'sh600296', 'sh600357', 'sh600472', 'sh600553', 'sh600591', 'sh600607',
            'sh600625', 'sh600627', 'sh600631', 'sh600632', 'sh600646', 'sh600659',
            'sh600669', 'sh600670', 'sh600672', 'sh600700', 'sh600709', 'sh600752',
            'sh600762', 'sh600772', 'sh600786', 'sh600788', 'sh600799', 'sh600813',
            'sh600832', 'sh600840'
        ]
        
        # å¦‚æœåœ¨å¿½ç•¥åˆ—è¡¨ä¸­ï¼Œåˆ™æ˜¯å€ºåˆ¸
        if stock_code in ignore_codes:
            return True
            
        # é€šç”¨çš„å€ºåˆ¸ä»£ç è¯†åˆ«è§„åˆ™
        bond_prefixes = ['sh110', 'sh113', 'sh120', 'sh122', 'sh123', 'sh124', 'sh127', 'sh128', 'sh132', 
                         'sz110', 'sz111', 'sz112', 'sz113', 'sz118', 'sz120', 'sz123', 'sz127', 'sz128']
        
        # æ£€æŸ¥æ˜¯å¦åŒ¹é…å€ºåˆ¸å‰ç¼€
        for prefix in bond_prefixes:
            if stock_code.startswith(prefix):
                return True
                
        return False

    def _get_available_stocks(self) -> List[str]:
        """è·å–å¯ç”¨çš„è‚¡ç¥¨ä»£ç åˆ—è¡¨"""
        stock_files = glob.glob(os.path.join(self.data_dir, "*.csv"))
        stock_codes = [os.path.basename(f).replace(".csv", "") for f in stock_files]
        
        # è¿‡æ»¤æ‰å€ºåˆ¸ä»£ç 
        filtered_codes = []
        bond_codes = []
        
        for code in stock_codes:
            if self._is_bond_code(code):
                bond_codes.append(code)
            else:
                filtered_codes.append(code)
        
        # è®°å½•è¿‡æ»¤æƒ…å†µ
        if bond_codes:
            print(f"å·²è¿‡æ»¤ {len(bond_codes)} ä¸ªå€ºåˆ¸ä»£ç ï¼Œä¾‹å¦‚: {bond_codes[:5]}")
        
        return filtered_codes
    
    def _read_stock_data(self, stock_code: str) -> pl.DataFrame:
        """è¯»å–å•åªè‚¡ç¥¨çš„æ•°æ®"""
        # å¦‚æœæ˜¯å€ºåˆ¸ä»£ç ï¼Œç›´æ¥è¿”å›ç©ºDataFrameï¼Œä¸æ‰“å°é”™è¯¯ä¿¡æ¯
        if self._is_bond_code(stock_code):
            return pl.DataFrame()
            
        file_path = os.path.join(self.data_dir, f"{stock_code}.csv")
        if not os.path.exists(file_path):
            print(f"è‚¡ç¥¨ {stock_code} çš„æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return pl.DataFrame()
            
        try:
            # è¯»å–CSVæ–‡ä»¶
            df = pl.read_csv(file_path)
            
            # å¦‚æœæ–‡ä»¶ä¸ºç©ºæˆ–åªæœ‰æ ‡é¢˜è¡Œï¼Œè¿”å›ç©ºDataFrame
            if df.is_empty() or df.height <= 1:
                return pl.DataFrame()
            
            # ç¡®ä¿æ—¥æœŸåˆ—æ ¼å¼æ­£ç¡®
            if 'æ—¥æœŸ' in df.columns:
                df = df.with_columns([
                    pl.col('æ—¥æœŸ').str.strptime(pl.Date, '%Y-%m-%d').alias('date')
                ])
                # åˆ é™¤åŸå§‹æ—¥æœŸåˆ—
                df = df.drop('æ—¥æœŸ')
            
            # é‡å‘½ååˆ—ä»¥åŒ¹é…æœŸæœ›çš„æ ¼å¼
            column_mapping = {
                'ä»£ç ': 'code',
                'å¼€ç›˜': 'open',
                'æ”¶ç›˜': 'close',
                'æœ€é«˜': 'high',
                'æœ€ä½': 'low',
                'æˆäº¤é‡': 'volume',
                'æˆäº¤é¢': 'amount',
                'æŒ¯å¹…': 'amplitude',
                'æ¶¨è·Œå¹…': 'change_pct',
                'æ¶¨è·Œé¢': 'change_amount',
                'æ¢æ‰‹ç‡': 'turnover'
            }
            
            # é‡å‘½ååˆ—
            for old_col, new_col in column_mapping.items():
                if old_col in df.columns:
                    df = df.rename({old_col: new_col})
            
            return df
            
        except Exception as e:
            # å¦‚æœæ˜¯"empty CSV"é”™è¯¯ï¼Œé™é»˜å¤„ç†
            if "empty CSV" in str(e):
                return pl.DataFrame()
            print(f"è¯»å–è‚¡ç¥¨ {stock_code} æ•°æ®å¤±è´¥: {str(e)}")
            return pl.DataFrame()
    
    def get_index_data(self, start_date: str, end_date: str = None) -> dict:
        """è·å–ä¸»è¦æŒ‡æ•°æ•°æ®"""
        if end_date is None:
            end_date = datetime.now().strftime('%Y%m%d')
        
        indices = {
            'ä¸Šè¯æŒ‡æ•°': 'sh000001',
            'æ·±è¯æˆæŒ‡': 'sz399001',
            'åˆ›ä¸šæ¿æŒ‡': 'sz399006'
        }
        
        result = {}
        for name, code in indices.items():
            # æ£€æŸ¥ç¼“å­˜
            if not self.cache.needs_update(f"index_{code}", end_date):
                cached_data = self.cache.load_data(f"index_{code}", end_date)
                if cached_data is not None:
                    result[name] = cached_data
                    continue
            
            # å°è¯•ä»æœ¬åœ°æ–‡ä»¶è·å–æ•°æ®
            if code in self.available_stocks:
                df = self._read_stock_data(code)
                if not df.is_empty():
                    # è½¬æ¢æ—¥æœŸæ ¼å¼
                    start_date_obj = datetime.strptime(start_date, '%Y%m%d').date()
                    end_date_obj = datetime.strptime(end_date, '%Y%m%d').date()
                    
                    # ç­›é€‰æ—¥æœŸèŒƒå›´
                    df = df.filter(
                        (pl.col('date') >= pl.lit(start_date_obj)) & 
                        (pl.col('date') <= pl.lit(end_date_obj))
                    )
                    
                    # ä¿å­˜åˆ°ç¼“å­˜
                    self.cache.save_data(f"index_{code}", end_date, df)
                    result[name] = df
                    continue
            
            # å¦‚æœæœ¬åœ°æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•ä½¿ç”¨ akshare è·å–æ•°æ®
            try:
                ak_code = code.replace('sh', 'sh').replace('sz', 'sz')
                df = ak.index_zh_a_hist(symbol=ak_code)
                df = pl.from_pandas(df)
                
                # ä¿å­˜åˆ°ç¼“å­˜
                self.cache.save_data(f"index_{code}", end_date, df)
                result[name] = df
            except Exception as e:
                print(f"è·å–æŒ‡æ•° {code} æ•°æ®å¤±è´¥: {str(e)}")
                result[name] = pl.DataFrame()
        
        return result
    
    def get_market_sentiment(self, date: str = None) -> dict:
        """è·å–å¸‚åœºæƒ…ç»ªæŒ‡æ ‡"""
        if date is None:
            date = datetime.now().strftime('%Y%m%d')
            
        # æ£€æŸ¥ç¼“å­˜
        if not self.cache.needs_update("sentiment", date):
            cached_data = self.cache.load_dict_data("sentiment", date, 
                ['limit_up', 'limit_down', 'market_overview', 'strong_stocks', 
                 'previous_limit_up', 'break_limit_up', 'big_deal'])
            if cached_data is not None:
                return cached_data
        
        try:
            # è·å–æ–°æ•°æ®
            limit_up = ak.stock_zt_pool_em(date=date)
            limit_down = ak.stock_zt_pool_dtgc_em(date=date)
            market_data = ak.stock_zh_a_spot_em()
            strong_stocks = ak.stock_zt_pool_strong_em(date=date)
            previous_limit_up = ak.stock_zt_pool_previous_em(date=date)
            break_limit_up = ak.stock_zt_pool_zbgc_em(date=date)
            big_deal = ak.stock_fund_flow_big_deal()
            
            # è½¬æ¢ä¸ºpandas DataFrameï¼Œå¹¶æ£€æŸ¥æ˜¯å¦ä¸ºç©º
            limit_up_df = pd.DataFrame(limit_up) if not isinstance(limit_up, pd.DataFrame) else limit_up
            limit_down_df = pd.DataFrame(limit_down) if not isinstance(limit_down, pd.DataFrame) else limit_down
            market_data_df = pd.DataFrame(market_data) if not isinstance(market_data, pd.DataFrame) else market_data
            strong_stocks_df = pd.DataFrame(strong_stocks) if not isinstance(strong_stocks, pd.DataFrame) else strong_stocks
            previous_limit_up_df = pd.DataFrame(previous_limit_up) if not isinstance(previous_limit_up, pd.DataFrame) else previous_limit_up
            break_limit_up_df = pd.DataFrame(break_limit_up) if not isinstance(break_limit_up, pd.DataFrame) else break_limit_up
            big_deal_df = pd.DataFrame(big_deal) if not isinstance(big_deal, pd.DataFrame) else big_deal
            
            # è½¬æ¢ä¸ºpolars DataFrameï¼Œå¹¶ç¡®ä¿éç©º
            result = {}
            
            # è½¬æ¢limit_up
            if not limit_up_df.empty:
                result['limit_up'] = pl.from_pandas(limit_up_df)
            else:
                result['limit_up'] = pl.DataFrame()
                
            # è½¬æ¢limit_down
            if not limit_down_df.empty:
                result['limit_down'] = pl.from_pandas(limit_down_df)
            else:
                result['limit_down'] = pl.DataFrame()
                
            # è½¬æ¢market_overview
            if not market_data_df.empty:
                # ç¡®ä¿ market_overview ä¸­æœ‰ 'amount' æˆ– 'æˆäº¤é¢' åˆ—
                market_overview = pl.from_pandas(market_data_df)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æˆäº¤é¢åˆ—
                has_amount_col = False
                for col in ['æˆäº¤é¢', 'amount', 'trade_amount', 'æˆäº¤é‡‘é¢']:
                    if col in market_overview.columns:
                        has_amount_col = True
                        break
                
                # å¦‚æœæ²¡æœ‰æˆäº¤é¢åˆ—ï¼Œæ·»åŠ ä¸€ä¸ªé»˜è®¤å€¼ä¸º0çš„åˆ—
                if not has_amount_col:
                    market_overview = market_overview.with_columns([
                        pl.lit(0).alias('æˆäº¤é¢')
                    ])
                    print("è­¦å‘Š: market_overview ä¸­æ²¡æœ‰æˆäº¤é¢åˆ—ï¼Œå·²æ·»åŠ é»˜è®¤å€¼ä¸º0çš„åˆ—")
                
                # æ£€æŸ¥å¹¶å¤„ç†æ—¥æœŸåˆ—
                date_cols = []
                for col in market_overview.columns:
                    if col.lower() in ['date', 'æ—¥æœŸ', 'trade_date', 'äº¤æ˜“æ—¥æœŸ']:
                        date_cols.append(col)
                
                # å¦‚æœæœ‰æ—¥æœŸåˆ—ï¼Œç¡®ä¿å®ƒä»¬æ˜¯å­—ç¬¦ä¸²ç±»å‹
                for date_col in date_cols:
                    col_type = market_overview[date_col].dtype
                    if col_type in [pl.Date, pl.Datetime]:
                        print(f"å°†market_overviewä¸­çš„{date_col}åˆ—ä»æ—¥æœŸç±»å‹è½¬æ¢ä¸ºå­—ç¬¦ä¸²ç±»å‹")
                        market_overview = market_overview.with_columns([
                            pl.col(date_col).dt.strftime('%Y-%m-%d').alias(date_col)
                        ])
                
                # æ£€æŸ¥å¹¶å¤„ç†ä»£ç åˆ—
                code_cols = []
                for col in market_overview.columns:
                    if col.lower() in ['code', 'ä»£ç ', 'stock_code', 'è‚¡ç¥¨ä»£ç ']:
                        code_cols.append(col)
                
                # å¦‚æœæœ‰ä»£ç åˆ—ï¼Œç¡®ä¿å®ƒä»¬æ˜¯å­—ç¬¦ä¸²ç±»å‹
                for code_col in code_cols:
                    col_type = market_overview[code_col].dtype
                    if col_type != pl.Utf8:
                        print(f"å°†market_overviewä¸­çš„{code_col}åˆ—è½¬æ¢ä¸ºå­—ç¬¦ä¸²ç±»å‹")
                        market_overview = market_overview.with_columns([
                            pl.col(code_col).cast(pl.Utf8).alias(code_col)
                        ])
                
                result['market_overview'] = market_overview
            else:
                # åˆ›å»ºä¸€ä¸ªå¸¦æœ‰é»˜è®¤åˆ—çš„ç©º DataFrame
                result['market_overview'] = pl.DataFrame({
                    'ä»£ç ': [],
                    'åç§°': [],
                    'æ¶¨è·Œå¹…': [],
                    'æˆäº¤é¢': []
                })
                
            # è½¬æ¢strong_stocks
            if not strong_stocks_df.empty:
                result['strong_stocks'] = pl.from_pandas(strong_stocks_df)
            else:
                result['strong_stocks'] = pl.DataFrame()
                
            # è½¬æ¢previous_limit_up
            if not previous_limit_up_df.empty:
                result['previous_limit_up'] = pl.from_pandas(previous_limit_up_df)
            else:
                result['previous_limit_up'] = pl.DataFrame()
                
            # è½¬æ¢break_limit_up
            if not break_limit_up_df.empty:
                result['break_limit_up'] = pl.from_pandas(break_limit_up_df)
            else:
                result['break_limit_up'] = pl.DataFrame()
                
            # è½¬æ¢big_deal
            if not big_deal_df.empty:
                result['big_deal'] = pl.from_pandas(big_deal_df)
            else:
                result['big_deal'] = pl.DataFrame()
            
            # ä¿å­˜åˆ°ç¼“å­˜
            self.cache.save_dict_data("sentiment", date, result)
            return result
            
        except Exception as e:
            print(f"è·å–å¸‚åœºæƒ…ç»ªæ•°æ®å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            # è¿”å›ç©ºæ•°æ®æ¡†
            return {
                'limit_up': pl.DataFrame(),
                'limit_down': pl.DataFrame(),
                'market_overview': pl.DataFrame({
                    'ä»£ç ': [],
                    'åç§°': [],
                    'æ¶¨è·Œå¹…': [],
                    'æˆäº¤é¢': []
                }),
                'strong_stocks': pl.DataFrame(),
                'previous_limit_up': pl.DataFrame(),
                'break_limit_up': pl.DataFrame(),
                'big_deal': pl.DataFrame()
            }
    
    def fetch_stock_details(self, date: str = None) -> Dict[str, pl.DataFrame]:
        """è·å–ä¸ªè‚¡è¯¦ç»†æ•°æ®"""
        try:
            # è·å–ä¸ªè‚¡å†å²æ•°æ®
            stock_details = {}
            
            # è·å–æ˜¨æ—¥æ¶¨åœè‚¡ç¥¨åˆ—è¡¨
            sentiment_data = self.get_market_sentiment(date)
            previous_limit_up = sentiment_data.get('previous_limit_up', pl.DataFrame())
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºç©ºDataFrame
            if previous_limit_up is None or not isinstance(previous_limit_up, pl.DataFrame) or previous_limit_up.is_empty():
                print("æœªè·å–åˆ°æ˜¨æ—¥æ¶¨åœè‚¡ç¥¨åˆ—è¡¨")
                return {}
            
            # ç¡®å®šä»£ç åˆ—å
            code_col = None
            for col in ['ä»£ç ', 'è‚¡ç¥¨ä»£ç ', 'code', 'symbol']:
                if col in previous_limit_up.columns:
                    code_col = col
                    break
            
            if code_col is None:
                print("æ— æ³•ç¡®å®šè‚¡ç¥¨ä»£ç åˆ—")
                return {}
                
            stock_codes = previous_limit_up[code_col].to_list()
            print(f"å¼€å§‹è·å– {len(stock_codes)} åªè‚¡ç¥¨çš„å†å²æ•°æ®")
            
            for code in stock_codes:
                try:
                    print(f"æ­£åœ¨è·å–è‚¡ç¥¨ {code} çš„å†å²æ•°æ®...")
                    
                    # æ£€æŸ¥ç¼“å­˜
                    cache_key = f"stock_detail_{code}"
                    if not self.cache.needs_update(cache_key, date):
                        cached_data = self.cache.load_data(cache_key, date)
                        if cached_data is not None and isinstance(cached_data, pl.DataFrame) and not cached_data.is_empty():
                            print(f"ä»ç¼“å­˜åŠ è½½è‚¡ç¥¨ {code} çš„å†å²æ•°æ®")
                            stock_details[code] = cached_data
                            continue
                    
                    # è·å–æœ€è¿‘30ä¸ªäº¤æ˜“æ—¥çš„æ•°æ®
                    start_date = (datetime.now() - timedelta(days=60)).strftime("%Y%m%d")
                    end_date = datetime.now().strftime("%Y%m%d")
                    
                    print(f"è·å–è‚¡ç¥¨ {code} ä» {start_date} åˆ° {end_date} çš„å†å²æ•°æ®")
                    df = ak.stock_zh_a_hist(symbol=code, period="daily", 
                                          start_date=start_date,
                                          end_date=end_date,
                                          adjust="qfq")
                    
                    # æ£€æŸ¥æ˜¯å¦ä¸ºç©º
                    df_pd = pd.DataFrame(df) if not isinstance(df, pd.DataFrame) else df
                    if df_pd.empty:
                        print(f"è‚¡ç¥¨{code}è¿”å›çš„æ•°æ®ä¸ºç©º")
                        continue
                        
                    # è½¬æ¢ä¸ºpolars DataFrameå¹¶ç¡®ä¿åˆ—åæ­£ç¡®
                    df = pl.from_pandas(df_pd)
                    
                    # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
                    required_columns = ['æ—¥æœŸ', 'å¼€ç›˜', 'æ”¶ç›˜', 'æœ€é«˜', 'æœ€ä½', 'æˆäº¤é‡', 'æˆäº¤é¢', 'æŒ¯å¹…', 'æ¶¨è·Œå¹…', 'æ¶¨è·Œé¢', 'æ¢æ‰‹ç‡']
                    missing_columns = [col for col in required_columns if col not in df.columns]
                    if missing_columns:
                        print(f"è‚¡ç¥¨{code}æ•°æ®ç¼ºå°‘å¿…è¦çš„åˆ—: {missing_columns}")
                        print(f"å®é™…åˆ—å: {df.columns}")
                        continue
                    
                    # é‡å‘½ååˆ—
                    column_mapping = {
                        'æ—¥æœŸ': 'date',
                        'å¼€ç›˜': 'open',
                        'æ”¶ç›˜': 'close',
                        'æœ€é«˜': 'high',
                        'æœ€ä½': 'low',
                        'æˆäº¤é‡': 'volume',
                        'æˆäº¤é¢': 'amount',
                        'æŒ¯å¹…': 'amplitude',
                        'æ¶¨è·Œå¹…': 'change_pct',
                        'æ¶¨è·Œé¢': 'change_amount',
                        'æ¢æ‰‹ç‡': 'turnover'
                    }
                    
                    df = df.rename(column_mapping)
                    
                    # ç¡®ä¿æ—¥æœŸåˆ—æ ¼å¼æ­£ç¡®
                    if df['date'].dtype == pl.Utf8:
                        try:
                            print(f"è‚¡ç¥¨ {code} å°†æ—¥æœŸåˆ—ä»å­—ç¬¦ä¸²è½¬æ¢ä¸ºæ—¥æœŸç±»å‹")
                            df = df.with_columns([
                                pl.col('date').str.strptime(pl.Date, '%Y-%m-%d').alias('date')
                            ])
                        except Exception as e:
                            print(f"è‚¡ç¥¨{code}æ—¥æœŸæ ¼å¼è½¬æ¢å¤±è´¥: {str(e)}")
                            print(f"æ—¥æœŸç¤ºä¾‹: {df['date'].head(5)}")
                            continue
                    
                    # æŒ‰æ—¥æœŸæ’åº
                    df = df.sort('date')
                    
                    # ä¿å­˜åˆ°ç¼“å­˜
                    self.cache.save_data(cache_key, date, df)
                    stock_details[code] = df
                    print(f"æˆåŠŸè·å–å¹¶å¤„ç†è‚¡ç¥¨ {code} çš„å†å²æ•°æ®")
                    
                except Exception as e:
                    print(f"è·å–è‚¡ç¥¨{code}æ•°æ®å¤±è´¥: {str(e)}")
                    import traceback
                    traceback.print_exc()
                    continue
            
            if not stock_details:
                print("æœªèƒ½æˆåŠŸè·å–ä»»ä½•è‚¡ç¥¨çš„å†å²æ•°æ®")
            else:
                print(f"æˆåŠŸè·å–äº†{len(stock_details)}åªè‚¡ç¥¨çš„å†å²æ•°æ®")
                
            return stock_details
            
        except Exception as e:
            print(f"è·å–ä¸ªè‚¡è¯¦ç»†æ•°æ®å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return {}
    
    def get_sector_data(self) -> dict:
        """è·å–è¡Œä¸šæ¿å—æ•°æ®"""
        # è¿™ä¸ªæ–¹æ³•éœ€è¦è¡Œä¸šæ¿å—çš„æ˜ å°„å…³ç³»ï¼Œç®€åŒ–å¤„ç†ï¼Œç›´æ¥ä½¿ç”¨ akshare
        return DataFetcher().get_sector_data()

class DataFetcher:
    """æ•°æ®è·å–å™¨ - æ•´åˆæ‰€æœ‰æ•°æ®è·å–å’Œç®¡ç†åŠŸèƒ½"""
    def __init__(self):
        """åˆå§‹åŒ–æ•°æ®è·å–å™¨"""
        self.cache = DataCache()
        self.stock_metadata_manager = StockMetadataManager()
        self.index_metadata_manager = IndexMetadataManager()
        self.market_metadata_manager = MarketMetadataManager()
        self.sector_data_manager = SectorDataManager()

    def check_and_update_metadata(self, progress_callback=None):
        """æ£€æŸ¥å¹¶æ›´æ–°æ‰€æœ‰å…ƒæ•°æ®"""
        print("ğŸ”„ å¼€å§‹æ£€æŸ¥å¹¶æ›´æ–°æ‰€æœ‰å…ƒæ•°æ®...")

        if progress_callback:
            progress_callback(0, 100, "å¼€å§‹æ£€æŸ¥å…ƒæ•°æ®æ›´æ–°éœ€æ±‚...")

        # 1. æ£€æŸ¥å¹¶æ›´æ–°è‚¡ç¥¨å…ƒæ•°æ®
        stock_metadata_updated = True
        if not self.stock_metadata_manager.is_latest_trading_day():
            print("ğŸ“Š æ£€æµ‹åˆ°è‚¡ç¥¨å…ƒæ•°æ®éœ€è¦æ›´æ–°...")
            if progress_callback:
                progress_callback(10, 100, "æ­£åœ¨æ›´æ–°è‚¡ç¥¨å…ƒæ•°æ®...")
            stock_metadata_updated = self.stock_metadata_manager.update_metadata(progress_callback=progress_callback)
            print("âœ… è‚¡ç¥¨å…ƒæ•°æ®æ›´æ–°å®Œæˆ" if stock_metadata_updated else "âŒ è‚¡ç¥¨å…ƒæ•°æ®æ›´æ–°å¤±è´¥")
        else:
            print("âœ… è‚¡ç¥¨å…ƒæ•°æ®å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€æ›´æ–°")
            if progress_callback:
                progress_callback(20, 100, "è‚¡ç¥¨å…ƒæ•°æ®æ£€æŸ¥å®Œæˆ")

        # 2. æ£€æŸ¥å¹¶æ›´æ–°æŒ‡æ•°å…ƒæ•°æ®
        index_metadata_updated = True
        if not self.index_metadata_manager.is_latest_trading_day():
            print("ğŸ“Š æ£€æµ‹åˆ°æŒ‡æ•°å…ƒæ•°æ®éœ€è¦æ›´æ–°...")
            if progress_callback:
                progress_callback(30, 100, "æ­£åœ¨æ›´æ–°æŒ‡æ•°å…ƒæ•°æ®...")
            index_metadata_updated = self.index_metadata_manager.update_metadata(
                progress_callback=lambda current, total, message:
                    progress_callback(30 + int(current / 3), 100, message)
                    if progress_callback else None
            )
            print("âœ… æŒ‡æ•°å…ƒæ•°æ®æ›´æ–°å®Œæˆ" if index_metadata_updated else "âŒ æŒ‡æ•°å…ƒæ•°æ®æ›´æ–°å¤±è´¥")
        else:
            print("âœ… æŒ‡æ•°å…ƒæ•°æ®å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€æ›´æ–°")
            if progress_callback:
                progress_callback(50, 100, "æŒ‡æ•°å…ƒæ•°æ®æ£€æŸ¥å®Œæˆ")

        # 3. æ£€æŸ¥å¹¶æ›´æ–°å¸‚åœºçŠ¶æ€æ•°æ®
        market_states_updated = True
        if not self.market_metadata_manager.is_latest_trading_day():
            print("ğŸ“Š æ£€æµ‹åˆ°å¸‚åœºçŠ¶æ€æ•°æ®éœ€è¦æ›´æ–°...")
            if progress_callback:
                progress_callback(60, 100, "æ­£åœ¨æ›´æ–°å¸‚åœºçŠ¶æ€æ•°æ®...")
            try:
                market_states_updated = self.market_metadata_manager.update_market_states_incremental()
                print("âœ… å¸‚åœºçŠ¶æ€æ•°æ®æ›´æ–°å®Œæˆ" if market_states_updated else "âŒ å¸‚åœºçŠ¶æ€æ•°æ®æ›´æ–°å¤±è´¥")
            except Exception as e:
                print(f"âŒ æ›´æ–°å¸‚åœºçŠ¶æ€æ•°æ®æ—¶å‡ºé”™: {str(e)}")
                import traceback
                traceback.print_exc()
                market_states_updated = False
        else:
            print("âœ… å¸‚åœºçŠ¶æ€æ•°æ®å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€æ›´æ–°")
            if progress_callback:
                progress_callback(70, 100, "å¸‚åœºçŠ¶æ€æ•°æ®æ£€æŸ¥å®Œæˆ")

        # 4. æ£€æŸ¥å¹¶æ›´æ–°æ¿å—æ•°æ®ï¼ˆåŒ…å«è¡Œä¸šå’Œæ¦‚å¿µæ¿å—ï¼‰
        sector_updated = True
        # æ£€æŸ¥æ¿å—æ•°æ®æ˜¯å¦éœ€è¦æ›´æ–°
        try:
            # ä½¿ç”¨SectorDataManagerçš„is_latest_trading_dayæ–¹æ³•
            if not self.sector_data_manager.is_latest_trading_day():
                print("ğŸ“Š æ£€æµ‹åˆ°æ¿å—æ•°æ®éœ€è¦æ›´æ–°...")
                if progress_callback:
                    progress_callback(80, 100, "æ­£åœ¨æ›´æ–°æ¿å—æ•°æ®...")
                try:
                    sector_updated = self.sector_data_manager.update_sector_data()
                    print("âœ… æ¿å—æ•°æ®æ›´æ–°å®Œæˆ" if sector_updated else "âŒ æ¿å—æ•°æ®æ›´æ–°å¤±è´¥")
                except Exception as e:
                    print(f"âŒ æ›´æ–°æ¿å—æ•°æ®æ—¶å‡ºé”™: {str(e)}")
                    import traceback
                    traceback.print_exc()
                    sector_updated = False
            else:
                print("âœ… æ¿å—æ•°æ®å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€æ›´æ–°")
                if progress_callback:
                    progress_callback(85, 100, "æ¿å—æ•°æ®æ£€æŸ¥å®Œæˆ")
        except Exception as e:
            print(f"âŒ æ£€æŸ¥æ¿å—æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            sector_updated = False

        # 5. æ£€æŸ¥å¹¶æ›´æ–°å¸‚åœºå…ƒæ•°æ®
        market_metadata_updated = True
        if not self.market_metadata_manager.is_latest_trading_day():
            print("ğŸ“Š æ£€æµ‹åˆ°å¸‚åœºå…ƒæ•°æ®éœ€è¦æ›´æ–°...")
            if progress_callback:
                progress_callback(90, 100, "æ­£åœ¨æ›´æ–°å¸‚åœºå…ƒæ•°æ®...")
            market_metadata_updated = self.market_metadata_manager.update_metadata(
                progress_callback=lambda current, total, message:
                    progress_callback(90 + int(current / 10), 100, message)
                    if progress_callback else None
            )
            print("âœ… å¸‚åœºå…ƒæ•°æ®æ›´æ–°å®Œæˆ" if market_metadata_updated else "âŒ å¸‚åœºå…ƒæ•°æ®æ›´æ–°å¤±è´¥")
        else:
            print("âœ… å¸‚åœºå…ƒæ•°æ®å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€æ›´æ–°")

        # å®Œæˆæ‰€æœ‰æ›´æ–°
        if progress_callback:
            progress_callback(100, 100, "æ‰€æœ‰æ•°æ®æ›´æ–°æ£€æŸ¥å®Œæˆ")

        print("ğŸ‰ æ‰€æœ‰å…ƒæ•°æ®æ›´æ–°æ£€æŸ¥å®Œæˆ")

        # è¿”å›æ‰€æœ‰æ›´æ–°æ˜¯å¦æˆåŠŸ
        all_success = (stock_metadata_updated and index_metadata_updated and
                      market_states_updated and sector_updated and market_metadata_updated)

        return all_success

    def get_market_sentiment(self, date: str = None) -> dict:
        """è·å–å¸‚åœºæƒ…ç»ªæŒ‡æ ‡"""
        if date is None:
            date = datetime.now().strftime('%Y%m%d')
            
        # æ£€æŸ¥ç¼“å­˜
        if not self.cache.needs_update("sentiment", date):
            cached_data = self.cache.load_dict_data("sentiment", date, 
                ['limit_up', 'limit_down', 'market_overview', 'strong_stocks', 
                 'previous_limit_up', 'break_limit_up', 'big_deal'])
            if cached_data is not None:
                return cached_data
        
        try:
            # è·å–æ–°æ•°æ®
            limit_up = ak.stock_zt_pool_em(date=date)
            limit_down = ak.stock_zt_pool_dtgc_em(date=date)
            market_data = ak.stock_zh_a_spot_em()
            strong_stocks = ak.stock_zt_pool_strong_em(date=date)
            previous_limit_up = ak.stock_zt_pool_previous_em(date=date)
            break_limit_up = ak.stock_zt_pool_zbgc_em(date=date)
            big_deal = ak.stock_fund_flow_big_deal()
            
            # è½¬æ¢ä¸ºpandas DataFrameï¼Œå¹¶æ£€æŸ¥æ˜¯å¦ä¸ºç©º
            limit_up_df = pd.DataFrame(limit_up) if not isinstance(limit_up, pd.DataFrame) else limit_up
            limit_down_df = pd.DataFrame(limit_down) if not isinstance(limit_down, pd.DataFrame) else limit_down
            market_data_df = pd.DataFrame(market_data) if not isinstance(market_data, pd.DataFrame) else market_data
            strong_stocks_df = pd.DataFrame(strong_stocks) if not isinstance(strong_stocks, pd.DataFrame) else strong_stocks
            previous_limit_up_df = pd.DataFrame(previous_limit_up) if not isinstance(previous_limit_up, pd.DataFrame) else previous_limit_up
            break_limit_up_df = pd.DataFrame(break_limit_up) if not isinstance(break_limit_up, pd.DataFrame) else break_limit_up
            big_deal_df = pd.DataFrame(big_deal) if not isinstance(big_deal, pd.DataFrame) else big_deal
            
            # è½¬æ¢ä¸ºpolars DataFrameï¼Œå¹¶ç¡®ä¿éç©º
            result = {}
            
            # è½¬æ¢limit_up
            if not limit_up_df.empty:
                result['limit_up'] = pl.from_pandas(limit_up_df)
            else:
                result['limit_up'] = pl.DataFrame()
                
            # è½¬æ¢limit_down
            if not limit_down_df.empty:
                result['limit_down'] = pl.from_pandas(limit_down_df)
            else:
                result['limit_down'] = pl.DataFrame()
                
            # è½¬æ¢market_overview
            if not market_data_df.empty:
                # ç¡®ä¿ market_overview ä¸­æœ‰ 'amount' æˆ– 'æˆäº¤é¢' åˆ—
                market_overview = pl.from_pandas(market_data_df)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æˆäº¤é¢åˆ—
                has_amount_col = False
                for col in ['æˆäº¤é¢', 'amount', 'trade_amount', 'æˆäº¤é‡‘é¢']:
                    if col in market_overview.columns:
                        has_amount_col = True
                        break
                
                # å¦‚æœæ²¡æœ‰æˆäº¤é¢åˆ—ï¼Œæ·»åŠ ä¸€ä¸ªé»˜è®¤å€¼ä¸º0çš„åˆ—
                if not has_amount_col:
                    market_overview = market_overview.with_columns([
                        pl.lit(0).alias('æˆäº¤é¢')
                    ])
                    print("è­¦å‘Š: market_overview ä¸­æ²¡æœ‰æˆäº¤é¢åˆ—ï¼Œå·²æ·»åŠ é»˜è®¤å€¼ä¸º0çš„åˆ—")
                
                result['market_overview'] = market_overview
            else:
                # åˆ›å»ºä¸€ä¸ªå¸¦æœ‰é»˜è®¤åˆ—çš„ç©º DataFrame
                result['market_overview'] = pl.DataFrame({
                    'ä»£ç ': [],
                    'åç§°': [],
                    'æ¶¨è·Œå¹…': [],
                    'æˆäº¤é¢': []
                })
                
            # è½¬æ¢strong_stocks
            if not strong_stocks_df.empty:
                result['strong_stocks'] = pl.from_pandas(strong_stocks_df)
            else:
                result['strong_stocks'] = pl.DataFrame()
                
            # è½¬æ¢previous_limit_up
            if not previous_limit_up_df.empty:
                result['previous_limit_up'] = pl.from_pandas(previous_limit_up_df)
            else:
                result['previous_limit_up'] = pl.DataFrame()
                
            # è½¬æ¢break_limit_up
            if not break_limit_up_df.empty:
                result['break_limit_up'] = pl.from_pandas(break_limit_up_df)
            else:
                result['break_limit_up'] = pl.DataFrame()
                
            # è½¬æ¢big_deal
            if not big_deal_df.empty:
                result['big_deal'] = pl.from_pandas(big_deal_df)
            else:
                result['big_deal'] = pl.DataFrame()
            
            # ä¿å­˜åˆ°ç¼“å­˜
            self.cache.save_dict_data("sentiment", date, result)
            return result
            
        except Exception as e:
            print(f"è·å–å¸‚åœºæƒ…ç»ªæ•°æ®å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            # è¿”å›ç©ºæ•°æ®æ¡†
            return {
                'limit_up': pl.DataFrame(),
                'limit_down': pl.DataFrame(),
                'market_overview': pl.DataFrame({
                    'ä»£ç ': [],
                    'åç§°': [],
                    'æ¶¨è·Œå¹…': [],
                    'æˆäº¤é¢': []
                }),
                'strong_stocks': pl.DataFrame(),
                'previous_limit_up': pl.DataFrame(),
                'break_limit_up': pl.DataFrame(),
                'big_deal': pl.DataFrame()
            }
    
    # ========== æ¿å—æ•°æ®ç®¡ç†æ–¹æ³• ==========


    def get_combined_sectors_summary(self, date_str: str = None, include_sectors: bool = True, include_concepts: bool = True, days_back: int = 30) -> Dict:
        """è·å–åˆå¹¶æ¿å—æ•°æ®æ‘˜è¦ï¼ˆè¡Œä¸š+æ¦‚å¿µï¼‰

        Args:
            date_str: æŒ‡å®šæ—¥æœŸï¼ˆæ ¼å¼ï¼šYYYY-MM-DDï¼‰ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨æœ€æ–°æ•°æ®
            include_sectors: æ˜¯å¦åŒ…å«è¡Œä¸šæ¿å—
            include_concepts: æ˜¯å¦åŒ…å«æ¦‚å¿µæ¿å—
            days_back: å½“date_strä¸ºNoneæ—¶ï¼ŒåŠ è½½æœ€è¿‘å¤šå°‘å¤©çš„æ•°æ®
        """
        try:
            from datetime import datetime

            # ä½¿ç”¨ç»Ÿä¸€æ•°æ®åŠ è½½æ–¹æ³•
            if date_str:
                unified_data = self.sector_data_manager.load_sector_data(
                    days_back=60,  # åŠ è½½æ›´å¤šå¤©æ•°ä»¥ç¡®ä¿åŒ…å«ç›®æ ‡æ—¥æœŸ
                    include_sectors=include_sectors,
                    include_concepts=include_concepts,
                    target_date=date_str  # ä¿®æ­£ï¼šä¼ é€’target_date
                )
                target_date = datetime.strptime(date_str, '%Y-%m-%d').date()
            else:
                # æœ€æ–°æ•°æ®æ¨¡å¼ï¼šä½¿ç”¨æŒ‡å®šçš„days_back
                unified_data = self.sector_data_manager.load_sector_data(
                    days_back=days_back,
                    include_sectors=include_sectors,
                    include_concepts=include_concepts
                )
                # ä½¿ç”¨æœ€æ–°æ—¥æœŸ
                if not unified_data.is_empty():
                    target_date = unified_data['æ—¥æœŸ'].max()
                else:
                    target_date = datetime.now().date()

            if unified_data.is_empty():
                return {
                    'top_sectors': [],
                    'fund_flow': [],
                    'performance': [],
                    'trend_analysis': [],
                    'summary': {
                        'total_sectors': 0,
                        'up_sectors': 0,
                        'down_sectors': 0,
                        'avg_change': 0.0
                    }
                }

            # ç­›é€‰æŒ‡å®šæ—¥æœŸçš„æ•°æ®
            target_data = unified_data.filter(pl.col('æ—¥æœŸ') == target_date)

            if target_data.is_empty():
                # å¦‚æœæŒ‡å®šæ—¥æœŸæ²¡æœ‰æ•°æ®ï¼Œå°è¯•æ‰¾æœ€æ¥è¿‘çš„æ—¥æœŸ
                available_dates = unified_data['æ—¥æœŸ'].unique().sort()
                closest_date = None

                for date in available_dates:
                    if date <= target_date:
                        closest_date = date
                    else:
                        break

                if closest_date:
                    print(f"âš ï¸ æŒ‡å®šæ—¥æœŸ {date_str} æ— æ•°æ®ï¼Œä½¿ç”¨æœ€æ¥è¿‘çš„æ—¥æœŸ {closest_date}")
                    target_data = unified_data.filter(pl.col('æ—¥æœŸ') == closest_date)
                else:
                    return {
                        'top_sectors': [],
                        'fund_flow': [],
                        'performance': [],
                        'trend_analysis': [],
                        'summary': {
                            'total_sectors': 0,
                            'up_sectors': 0,
                            'down_sectors': 0,
                            'avg_change': 0.0
                        }
                    }

            # æ¿å—æ•°æ®å·²ç»åŒ…å«5æ—¥å’Œ10æ—¥æ¶¨è·Œå¹…ä»¥åŠæˆäº¤é¢é‡æ¯”ï¼Œç›´æ¥ä½¿ç”¨
            target_data_with_periods = target_data

            # æˆäº¤é¢é‡æ¯”ä¹Ÿå·²ç»åœ¨æ•°æ®ä¸­ï¼Œæ— éœ€é‡æ–°è®¡ç®—
            target_data_with_volume_ratio = target_data_with_periods

            # å¤„ç†æ•°æ®æ ¼å¼åŒ–ï¼ˆç§»é™¤è‚¡ç¥¨æ•°é‡è®¡ç®—ä»¥æå‡æ€§èƒ½ï¼‰
            combined_top_sectors = []
            for row in target_data_with_volume_ratio.to_dicts():
                # å…ˆä¿ç•™åŸå§‹æ•°æ®ï¼Œå¤„ç†æ—¥æœŸåºåˆ—åŒ–
                formatted_row = {}
                for key, value in row.items():
                    if hasattr(value, 'strftime'):  # å¤„ç†æ—¥æœŸå¯¹è±¡
                        formatted_row[key] = value.strftime('%Y-%m-%d')
                    else:
                        formatted_row[key] = value

                # ä¿ç•™åŸå§‹æ•°æ®ï¼Œè®©å‰ç«¯å¤„ç†æ ¼å¼åŒ–
                formatted_row['æˆäº¤é¢é‡æ¯”'] = row.get('æˆäº¤é¢é‡æ¯”')  # æ·»åŠ æˆäº¤é¢é‡æ¯”å­—æ®µ
                formatted_row['æˆäº¤é¢'] = row.get('æˆäº¤é¢') or 0
                formatted_row['æˆäº¤é‡'] = row.get('æˆäº¤é‡') or 0
                formatted_row['æ¶¨è·Œå¹…'] = row.get('æ¶¨è·Œå¹…') or 0
                formatted_row['5æ—¥æ¶¨è·Œå¹…'] = row.get('5æ—¥æ¶¨è·Œå¹…') or 0
                formatted_row['10æ—¥æ¶¨è·Œå¹…'] = row.get('10æ—¥æ¶¨è·Œå¹…') or 0
                formatted_row['æ¢æ‰‹ç‡'] = row.get('æ¢æ‰‹ç‡') or 0
                formatted_row['æŒ¯å¹…'] = row.get('æŒ¯å¹…') or 0
                formatted_row['æœ€æ–°ä»·'] = row.get('æ”¶ç›˜') or 0

                # ç§»é™¤è‚¡ç¥¨æ•°é‡è®¡ç®—ä»¥æå‡æ€§èƒ½
                # formatted_row['è‚¡ç¥¨æ•°é‡'] = 0  # ä¸å†è®¡ç®—è‚¡ç¥¨æ•°é‡

                combined_top_sectors.append(formatted_row)

            # æŒ‰æ¶¨è·Œå¹…æ’åºï¼ˆå¤„ç†Noneå€¼ï¼‰
            def safe_float(value):
                if value is None:
                    return 0.0
                try:
                    return float(value)
                except (ValueError, TypeError):
                    return 0.0

            combined_top_sectors.sort(key=lambda x: safe_float(x.get('æ¶¨è·Œå¹…', 0)), reverse=True)

            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯ï¼ˆä½¿ç”¨åŸå§‹æ•°å€¼è€Œä¸æ˜¯æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²ï¼‰
            total_sectors = len(combined_top_sectors)
            up_sectors = len([s for s in combined_top_sectors if safe_float(s.get('æ¶¨è·Œå¹…_åŸå§‹', 0)) > 0])
            down_sectors = len([s for s in combined_top_sectors if safe_float(s.get('æ¶¨è·Œå¹…_åŸå§‹', 0)) < 0])
            avg_change = sum(safe_float(s.get('æ¶¨è·Œå¹…_åŸå§‹', 0)) for s in combined_top_sectors) / total_sectors if total_sectors > 0 else 0

            return {
                'top_sectors': combined_top_sectors,
                'fund_flow': [],  # æš‚æ—¶ä¸ºç©ºï¼Œå¯ä»¥åç»­æ‰©å±•
                'performance': [],  # æš‚æ—¶ä¸ºç©ºï¼Œå¯ä»¥åç»­æ‰©å±•
                'trend_analysis': [],  # æš‚æ—¶ä¸ºç©ºï¼Œå¯ä»¥åç»­æ‰©å±•
                'summary': {
                    'total_sectors': total_sectors,
                    'up_sectors': up_sectors,
                    'down_sectors': down_sectors,
                    'avg_change': round(avg_change, 2)
                }
            }

        except Exception as e:
            print(f"âŒ è·å–æŒ‡å®šæ—¥æœŸæ¿å—æ‘˜è¦å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return {
                'top_sectors': [],
                'fund_flow': [],
                'performance': [],
                'trend_analysis': [],
                'summary': {
                    'total_sectors': 0,
                    'up_sectors': 0,
                    'down_sectors': 0,
                    'avg_change': 0.0
                }
            }

    def get_sectors_custom_period(self, start_date: str, end_date: str, include_sectors: bool = True, include_concepts: bool = True) -> List[Dict]:
        """è·å–æ¿å—è‡ªå®šä¹‰åŒºé—´æ¶¨è·Œå¹…"""
        try:
            # åŠ è½½ç»Ÿä¸€æ¿å—æ•°æ®
            unified_data = self.sector_data_manager.load_sector_data(
                include_sectors=include_sectors,
                include_concepts=include_concepts
            )

            if unified_data.is_empty():
                return []

            # è½¬æ¢æ—¥æœŸæ ¼å¼
            start_dt = datetime.strptime(start_date, '%Y-%m-%d').date()
            end_dt = datetime.strptime(end_date, '%Y-%m-%d').date()

            # ç­›é€‰æ—¥æœŸèŒƒå›´å†…çš„æ•°æ®
            period_data = unified_data.filter(
                (pl.col('æ—¥æœŸ') >= start_dt) & (pl.col('æ—¥æœŸ') <= end_dt)
            )

            if period_data.is_empty():
                return []

            # æŒ‰æ¿å—åç§°åˆ†ç»„è®¡ç®—åŒºé—´æ¶¨è·Œå¹…
            result = []

            for sector_name in period_data['æ¿å—åç§°'].unique():
                sector_data = period_data.filter(pl.col('æ¿å—åç§°') == sector_name).sort('æ—¥æœŸ')

                if sector_data.height < 2:
                    continue

                # è·å–èµ·å§‹å’Œç»“æŸä»·æ ¼
                start_price = sector_data.select(pl.col('æ”¶ç›˜')).to_series()[0]
                end_price = sector_data.select(pl.col('æ”¶ç›˜')).to_series()[-1]

                if start_price and end_price and start_price != 0:
                    # è®¡ç®—åŒºé—´æ¶¨è·Œå¹…
                    period_change = ((end_price - start_price) / start_price * 100)

                    # è·å–æ¿å—ç±»å‹
                    sector_type = sector_data.select(pl.col('æ¿å—ç±»å‹')).to_series()[0]

                    # è·å–èµ·å§‹å’Œç»“æŸæ—¥æœŸ
                    start_date = sector_data.select(pl.col('æ—¥æœŸ')).to_series()[0]
                    end_date = sector_data.select(pl.col('æ—¥æœŸ')).to_series()[-1]

                    result.append({
                        'æ¿å—åç§°': sector_name,
                        'æ¿å—ç±»å‹': sector_type,
                        'åŒºé—´æ¶¨è·Œå¹…': round(period_change, 2),
                        'èµ·å§‹ä»·æ ¼': round(start_price, 2),
                        'ç»“æŸä»·æ ¼': round(end_price, 2),
                        'èµ·å§‹æ—¥æœŸ': start_date.strftime('%Y-%m-%d') if hasattr(start_date, 'strftime') else str(start_date),
                        'ç»“æŸæ—¥æœŸ': end_date.strftime('%Y-%m-%d') if hasattr(end_date, 'strftime') else str(end_date)
                    })

            # æŒ‰åŒºé—´æ¶¨è·Œå¹…é™åºæ’åº
            result.sort(key=lambda x: x['åŒºé—´æ¶¨è·Œå¹…'], reverse=True)

            return result

        except Exception as e:
            print(f"âŒ è·å–è‡ªå®šä¹‰åŒºé—´æ¿å—æ•°æ®å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return []

    def get_sector_kline_data(self, sector_name: str, days_back: int = 30, target_date: str = None) -> pl.DataFrame:
        """
        è·å–å•ä¸ªæ¿å—çš„Kçº¿æ•°æ®ï¼Œç”¨äºå‰ç«¯åŸç”ŸEChartsæ¸²æŸ“
        
        Args:
            sector_name: æ¿å—åç§°
            days_back: è·å–æœ€è¿‘å¤šå°‘å¤©çš„æ•°æ®
            target_date: ç›®æ ‡æ—¥æœŸï¼ˆå¯é€‰ï¼‰ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™ä½¿ç”¨æœ€æ–°æ—¥æœŸ
            
        Returns:
            pl.DataFrame: æ¿å—Kçº¿æ•°æ®
        """
        try:
            # è°ƒç”¨SectorDataManagerè·å–Kçº¿æ•°æ®
            return self.sector_data_manager.get_sector_kline_data(sector_name, days_back, target_date)
        except Exception as e:
            print(f"âŒ DataFetcherè·å–æ¿å—Kçº¿æ•°æ®å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return pl.DataFrame()

def create_data_fetcher(use_local_file: bool = False, local_file_path: str = "E:/jupyter/å¤§A/all_stock_candle/stock/daily") -> Union[DataFetcher, LocalFileDataFetcher]:
    """åˆ›å»ºæ•°æ®è·å–å™¨"""
    if use_local_file:
        try:
            print(f"å°è¯•ä½¿ç”¨æœ¬åœ°æ–‡ä»¶æ•°æ®è·å–å™¨ï¼Œè·¯å¾„: {local_file_path}")
            return LocalFileDataFetcher(local_file_path)
        except Exception as e:
            print(f"åˆå§‹åŒ–æœ¬åœ°æ–‡ä»¶æ•°æ®è·å–å™¨å¤±è´¥: {str(e)}")
            print("å°†ä½¿ç”¨é»˜è®¤æ•°æ®è·å–å™¨")
    
    # è¿”å›é»˜è®¤æ•°æ®è·å–å™¨
    print("ä½¿ç”¨AKShareæ•°æ®è·å–å™¨")
    return DataFetcher()
