#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¿å—æ•°æ®ç®¡ç†å™¨

SectorDataManagerï¼Œä¸“é—¨è´Ÿè´£æ¿å—æ•°æ®ç®¡ç†
åŒ…å«æ¿å—æˆåˆ†è‚¡ç®¡ç†åŠŸèƒ½ï¼Œæ”¯æŒåŒèŠ±é¡ºæ•°æ®æºã€ä¸œè´¢æ•°æ®æº
"""

import polars as pl
import pandas as pd
import akshare as ak
import requests
import json
import time
import random
import re
from datetime import datetime, timedelta, time as dt_time, date
from pathlib import Path
from typing import Optional, List, Dict, Tuple
import warnings

# å±è”½pandasè­¦å‘Š
warnings.filterwarnings('ignore', category=pd.errors.PerformanceWarning)

# æ£€æŸ¥é—®è´¢åº“æ˜¯å¦å¯ç”¨
try:
    import pywencai
    PYWENCAI_AVAILABLE = True
except ImportError:
    PYWENCAI_AVAILABLE = False
    print("âš ï¸ pywencaiæœªå®‰è£…ï¼Œæˆåˆ†è‚¡åŠŸèƒ½å°†å—é™")

# å¯¼å…¥æ•°æ®å¤„ç†å™¨
from .data_processor import DataProcessor


class ThsDataProvider:
    """åŒèŠ±é¡ºæ•°æ®æä¾›å™¨ - ä¸“é—¨å¤„ç†åŒèŠ±é¡ºæ•°æ®æº"""

    def __init__(self):
        self.base_url = "https://d.10jqka.com.cn"
        self.headers = {
            'Referer': 'http://q.10jqka.com.cn/',
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
                          '(KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
            'Accept': 'application/javascript, */*;q=0.1',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive'
        }
        
        # é”™è¯¯æ—¥å¿—é…ç½®
        self.data_dir = Path("data_cache")
        self.sector_dir = self.data_dir / "sectors"
        self.sector_dir.mkdir(parents=True, exist_ok=True)
        self.error_log_file = self.sector_dir / "ths_update_errors.log"

    def test_connection(self) -> bool:
        """æµ‹è¯•åŒèŠ±é¡ºè¿æ¥"""
        if not PYWENCAI_AVAILABLE:
            print("âŒ pywencaiæœªå®‰è£…ï¼Œæ— æ³•æµ‹è¯•åŒèŠ±é¡ºè¿æ¥")
            return False

        try:
            # æµ‹è¯•é—®è´¢åº“
            test_result = pywencai.get(query="ä¸Šè¯æŒ‡æ•°", query_type="zhishu")
            if len(test_result) > 0:
                print("âœ… åŒèŠ±é¡ºé—®è´¢åº“è¿æ¥æˆåŠŸ")
                return True
            else:
                print("âŒ åŒèŠ±é¡ºé—®è´¢åº“è¿”å›ç©ºæ•°æ®")
                return False
        except Exception as e:
            print(f"âŒ åŒèŠ±é¡ºè¿æ¥å¤±è´¥: {e}")
            return False

    def get_sector_data_with_retry(self, sector_name: str, sector_type: str, 
                                   start_date: str, end_date: str,
                                   max_retries: int = 3) -> Optional[pd.DataFrame]:
        """è·å–å•ä¸ªæ¿å—å†å²æ•°æ®ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
        
        Args:
            sector_name: æ¿å—åç§°
            sector_type: æ¿å—ç±»å‹ï¼ˆ"è¡Œä¸š" æˆ– "æ¦‚å¿µ"ï¼‰
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            
        Returns:
            æ¿å—å†å²æ•°æ®DataFrameï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        for attempt in range(max_retries):
            try:
                print(f"ğŸ“Š è·å–{sector_type}æ¿å—æ•°æ®: {sector_name} (å°è¯• {attempt + 1}/{max_retries})")
                
                if sector_type == "è¡Œä¸š":
                    data = ak.stock_board_industry_index_ths(
                        symbol=sector_name, 
                        start_date=start_date, 
                        end_date=end_date
                    )
                else:  # æ¦‚å¿µ
                    data = ak.stock_board_concept_index_ths(
                        symbol=sector_name, 
                        start_date=start_date, 
                        end_date=end_date
                    )
                
                if data is not None and not data.empty:
                    # æ•°æ®è´¨é‡æ£€æŸ¥
                    required_columns = ['æ—¥æœŸ', 'å¼€ç›˜ä»·', 'æ”¶ç›˜ä»·', 'æœ€é«˜ä»·', 'æœ€ä½ä»·']
                    missing_columns = [col for col in required_columns if col not in data.columns]
                    
                    if missing_columns:
                        print(f"âš ï¸ æ•°æ®ç¼ºå°‘å¿…è¦åˆ—: {missing_columns}")
                        continue
                    
                    # æ ‡å‡†åŒ–åˆ—å
                    data = data.rename(columns={
                        'å¼€ç›˜ä»·': 'å¼€ç›˜',
                        'æœ€é«˜ä»·': 'æœ€é«˜',
                        'æœ€ä½ä»·': 'æœ€ä½',
                        'æ”¶ç›˜ä»·': 'æ”¶ç›˜'
                    })
                    
                    # æ·»åŠ æ¿å—ä¿¡æ¯
                    data['æ¿å—åç§°'] = sector_name
                    data['æ¿å—ç±»å‹'] = sector_type
                    data['æ•°æ®æº'] = 'åŒèŠ±é¡º'
                    
                    # æ•°æ®éªŒè¯
                    data_years = pd.to_datetime(data['æ—¥æœŸ']).dt.year.unique()
                    coverage_years = len(data_years)
                    
                    print(f"âœ… æˆåŠŸè·å– {len(data)} æ¡è®°å½•ï¼Œè¦†ç›– {coverage_years} å¹´æ•°æ®")
                    return data
                else:
                    print(f"âš ï¸ è·å–æ•°æ®å¤±è´¥æˆ–ä¸ºç©º (å°è¯• {attempt + 1})")
                    
            except Exception as e:
                error_msg = f"è·å–{sector_name}æ•°æ®å¤±è´¥ (å°è¯• {attempt + 1}): {e}"
                print(f"âŒ {error_msg}")
                
                # å†…è”é”™è¯¯æ—¥å¿—è®°å½•
                try:
                    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    with open(self.error_log_file, 'a', encoding='utf-8') as f:
                        f.write(f"[{timestamp}] {error_msg}\n")
                except Exception as log_e:
                    print(f"âš ï¸ è®°å½•é”™è¯¯æ—¥å¿—å¤±è´¥: {log_e}")
                
                if attempt < max_retries - 1:
                    # æŒ‡æ•°é€€é¿å»¶è¿Ÿ
                    delay = (attempt + 1) * 2 + random.uniform(1, 3)
                    print(f"â³ ç­‰å¾… {delay:.1f} ç§’åé‡è¯•...")
                    time.sleep(delay)
        
        print(f"âŒ å¤šæ¬¡å°è¯•åä»æ— æ³•è·å– {sector_name} çš„æ•°æ®")
        return None

    def get_sector_constituents(self, code: str, name: str, sector_type: str = "æ¦‚å¿µ", max_retries: int = 3) -> Optional[pd.DataFrame]:
        """ä½¿ç”¨é—®è´¢åº“è·å–åŒèŠ±é¡ºæ¿å—æˆåˆ†è‚¡æ•°æ®ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰"""
        
        for attempt in range(max_retries):
            try:
                if attempt == 0:
                    print(f"ğŸ“Š ä½¿ç”¨é—®è´¢åº“è·å–{sector_type}æ¿å—æˆåˆ†è‚¡: {name}")
                else:
                    print(f"ğŸ“Š é‡è¯•è·å–{sector_type}æ¿å—æˆåˆ†è‚¡: {name} (å°è¯• {attempt + 1}/{max_retries})")

                # æ„å»ºé—®è´¢æŸ¥è¯¢è¯­å¥
                if sector_type == "æ¦‚å¿µ":
                    if attempt > 1:
                        query = f"{name}"
                    else:
                        query = f"æ‰€å±æ¦‚å¿µåŒ…å«{name}"
                else:
                    query = f"æ‰€å±åŒèŠ±é¡ºè¡Œä¸šåŒ…å«{name}"

                # ä½¿ç”¨é—®è´¢åº“æŸ¥è¯¢
                stocks_df = pywencai.get(
                    query=query,
                    query_type="stock",
                    loop=True
                )

                if stocks_df is not None and not stocks_df.empty:
                    # ä¼˜åŒ–çš„å‘é‡åŒ–æ•°æ®å¤„ç†
                    current_date = datetime.now().strftime('%Y-%m-%d')
                    
                    # é¢„å®šä¹‰å¯èƒ½çš„åˆ—åæ˜ å°„ï¼ˆé—®è´¢è¿”å›çš„åˆ—åå¯èƒ½ä¸åŒï¼‰
                    code_columns = ['è‚¡ç¥¨ä»£ç ', 'code', 'ä»£ç ', 'symbol']
                    name_columns = ['è‚¡ç¥¨ç®€ç§°', 'name', 'åç§°', 'è‚¡ç¥¨åç§°']
                    
                    # æ‰¾åˆ°å®é™…å­˜åœ¨çš„åˆ—å
                    code_col = next((col for col in code_columns if col in stocks_df.columns), None)
                    name_col = next((col for col in name_columns if col in stocks_df.columns), None)
                    
                    if not code_col or not name_col:
                        print(f"    âŒ æœªæ‰¾åˆ°å¿…è¦çš„åˆ—: ä»£ç åˆ—={code_col}, åç§°åˆ—={name_col}")
                        print(f"    ğŸ” å¯ç”¨åˆ—å: {list(stocks_df.columns)}")
                        return None
                    
                    # è¿‡æ»¤æœ‰æ•ˆæ•°æ®
                    valid_mask = stocks_df[code_col].notna() & stocks_df[name_col].notna()
                    valid_df = stocks_df[valid_mask].copy()
                    
                    if valid_df.empty:
                        print(f"    âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„è‚¡ç¥¨æ•°æ®")
                        return None
                    
                    # å‘é‡åŒ–å¤„ç†è‚¡ç¥¨ä»£ç æ ¼å¼ï¼šæå–å‰6ä½æ•°å­—ï¼ˆå¤„ç†002569.szæ ¼å¼ï¼‰
                    valid_df['è‚¡ç¥¨ä»£ç '] = valid_df[code_col].astype(str).str.extract(r'(\d{6})')[0]
                    valid_df['è‚¡ç¥¨åç§°'] = valid_df[name_col].astype(str)
                    
                    # è¿‡æ»¤æ‰æ— æ³•è§£æçš„è‚¡ç¥¨ä»£ç 
                    code_valid_mask = valid_df['è‚¡ç¥¨ä»£ç '].notna() & (valid_df['è‚¡ç¥¨ä»£ç '].str.len() == 6)
                    valid_df = valid_df[code_valid_mask]
                    
                    if valid_df.empty:
                        print(f"    âš ï¸ æ²¡æœ‰æœ‰æ•ˆæ ¼å¼çš„è‚¡ç¥¨ä»£ç ")
                        return None
                    
                    # å‘é‡åŒ–æ·»åŠ å…ƒæ•°æ®
                    valid_df['æ¿å—åç§°'] = name
                    valid_df['æ¿å—ä»£ç '] = code  
                    valid_df['æ¿å—ç±»å‹'] = sector_type
                    valid_df['æ›´æ–°æ—¥æœŸ'] = current_date
                    valid_df['æ•°æ®æº'] = 'åŒèŠ±é¡º'
                    
                    # é€‰æ‹©éœ€è¦çš„åˆ—
                    result_columns = ['è‚¡ç¥¨ä»£ç ', 'è‚¡ç¥¨åç§°', 'æ¿å—åç§°', 'æ¿å—ä»£ç ', 'æ¿å—ç±»å‹', 'æ›´æ–°æ—¥æœŸ', 'æ•°æ®æº']
                    stocks_data = valid_df[result_columns].to_dict('records')

                    if stocks_data:
                        result_df = pd.DataFrame(stocks_data)
                        print(f"âœ… è·å–åˆ° {len(result_df)} åª{sector_type}æˆåˆ†è‚¡")
                        return result_df
                    else:
                        print(f"âš ï¸ æœªèƒ½è§£æ{sector_type}æ¿å— {name} çš„æˆåˆ†è‚¡æ•°æ®")
                        if attempt < max_retries - 1:
                            print(f"â³ ç­‰å¾…é‡è¯•...")
                            time.sleep(random.uniform(1, 3))
                            continue
                        return pd.DataFrame()
                else:
                    print(f"âš ï¸ é—®è´¢æŸ¥è¯¢ {name} æ— ç»“æœ")
                    if attempt < max_retries - 1:
                        print(f"â³ ç­‰å¾…é‡è¯•...")
                        time.sleep(random.uniform(1, 3))
                        continue
                    return pd.DataFrame()

            except Exception as e:
                print(f"âŒ ä½¿ç”¨é—®è´¢åº“è·å–{sector_type}æˆåˆ†è‚¡å¤±è´¥ (å°è¯• {attempt + 1}): {e}")
                if attempt < max_retries - 1:
                    print(f"â³ ç­‰å¾… {random.uniform(1, 3):.1f} ç§’åé‡è¯•...")
                    time.sleep(random.uniform(1, 3))
                    continue
                else:
                    return None
        
        # å¦‚æœæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
        print(f"âŒ å¤šæ¬¡å°è¯•åä»æ— æ³•è·å– {name} çš„æˆåˆ†è‚¡æ•°æ®")
        return None

    def update_sector_data(self, sector_dir: Path, years_back: int = 1, force_update: bool = False) -> bool:
        """å…¨é¢æ›´æ–°åŒèŠ±é¡ºæ¿å—æ•°æ®"""
        try:
            print(f"ğŸš€ å¼€å§‹å…¨é¢æ›´æ–°åŒèŠ±é¡ºæ¿å—æ•°æ® (æœ€è¿‘{years_back}å¹´)")

            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
            from pathlib import Path
            sector_path = Path(sector_dir)
            sectors_ths_file = sector_path / "sectors_ths.parquet"

            # è®¡ç®—æ—¥æœŸèŒƒå›´
            end_date = (datetime.now() + pd.Timedelta(days=1)).strftime('%Y%m%d')
            start_date = (datetime.now() - pd.Timedelta(days=years_back*31)).strftime('%Y%m%d')

            print(f"ğŸ“… æ›´æ–°æ—¥æœŸèŒƒå›´: {start_date} åˆ° {end_date}")

            # æ›´æ–°è¡Œä¸šæ•°æ®
            print("\nğŸ“Š æ›´æ–°åŒèŠ±é¡ºè¡Œä¸šæ¿å—æ•°æ®...")
            industry_success = self._update_industries(start_date, end_date, sector_path)

            # æ›´æ–°æ¦‚å¿µæ•°æ®
            print("\nğŸ“Š æ›´æ–°åŒèŠ±é¡ºæ¦‚å¿µæ¿å—æ•°æ®...")
            concept_success = self._update_concepts(start_date, end_date, sector_path)

            # åˆå¹¶æ•°æ®
            if industry_success or concept_success:
                print("\nğŸ”— åˆå¹¶åŒèŠ±é¡ºæ¿å—æ•°æ®...")

                try:
                    # æ”¶é›†æ‰€æœ‰æ–°æ•°æ®
                    all_new_data = []

                    # è¯»å–æ–°çš„è¡Œä¸šæ•°æ®
                    industry_temp_file = sector_path / "temp_industry_ths.parquet"
                    if industry_success and industry_temp_file.exists():
                        industry_data = pl.read_parquet(industry_temp_file)
                        all_new_data.append(industry_data)
                        print(f"ğŸ“Š æ–°è¡Œä¸šæ•°æ®: {industry_data.height} æ¡è®°å½•")
                        # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                        industry_temp_file.unlink()

                    # è¯»å–æ–°çš„æ¦‚å¿µæ•°æ®
                    concept_temp_file = sector_path / "temp_concept_ths.parquet"
                    if concept_success and concept_temp_file.exists():
                        concept_data = pl.read_parquet(concept_temp_file)
                        all_new_data.append(concept_data)
                        print(f"ğŸ“Š æ–°æ¦‚å¿µæ•°æ®: {concept_data.height} æ¡è®°å½•")
                        # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                        concept_temp_file.unlink()

                    if all_new_data:
                        # åˆå¹¶æ‰€æœ‰æ–°æ•°æ®
                        new_combined_data = pl.concat(all_new_data)
                        print(f"ğŸ“Š æ–°æ•°æ®æ€»è®¡: {new_combined_data.height} æ¡è®°å½•")

                        # ä¿å­˜åŸå§‹æ–°æ•°æ®åˆ°ä¸´æ—¶æ–‡ä»¶ï¼Œç­‰å¾…SectorDataManagerå¤„ç†
                        temp_new_data_file = sector_path / "temp_new_data_ths.parquet"
                        new_combined_data.write_parquet(temp_new_data_file)
                        print(f"ğŸ“Š æ–°æ•°æ®å·²ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶: {temp_new_data_file}")

                        # è¿”å›Trueï¼Œè®©SectorDataManagerç»§ç»­å¤„ç†
                        return True


                    else:
                        print("âš ï¸ æ²¡æœ‰æ–°æ•°æ®éœ€è¦åˆå¹¶")
                        return False

                except Exception as e:
                    print(f"âŒ åˆå¹¶æ•°æ®å¤±è´¥: {e}")
                    import traceback
                    traceback.print_exc()
                    return False
            else:
                print("âŒ è¡Œä¸šå’Œæ¦‚å¿µæ•°æ®æ›´æ–°éƒ½å¤±è´¥")
                return False

        except Exception as e:
            print(f"\nâŒ æ›´æ–°åŒèŠ±é¡ºæ¿å—æ•°æ®å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False

    def _update_industries(self, start_date: str, end_date: str, sector_dir: Path) -> bool:
        """æ›´æ–°åŒèŠ±é¡ºè¡Œä¸šæ¿å—æ•°æ®"""
        print("\nğŸ“Š æ›´æ–°åŒèŠ±é¡ºè¡Œä¸šæ¿å—æ•°æ®...")

        try:
            # ç›´æ¥ä½¿ç”¨AKShareè·å–è¡Œä¸šåˆ—è¡¨
            print("ğŸ“Š è·å–åŒèŠ±é¡ºè¡Œä¸šæŒ‡æ•°åˆ—è¡¨...")
            industries_df = ak.stock_board_industry_name_ths()
            if industries_df is None or industries_df.empty:
                print("âŒ è·å–è¡Œä¸šåˆ—è¡¨å¤±è´¥")
                return False

            print(f"âœ… è·å–åˆ° {len(industries_df)} ä¸ªåŒèŠ±é¡ºè¡Œä¸šæŒ‡æ•°")

            print(f"ğŸ“‹ è·å–åˆ° {len(industries_df)} ä¸ªè¡Œä¸šæ¿å—")

            all_industry_data = []
            success_count = 0

            # æ£€æŸ¥æ˜¯å¦æœ‰æµ‹è¯•é™åˆ¶ï¼ˆé»˜è®¤å…¨é‡å¤„ç†ï¼‰
            test_limit = getattr(self, '_test_industry_limit', None)
            if test_limit is None:
                print(f"ğŸš€ å…¨é‡æ¨¡å¼ï¼šå¤„ç†æ‰€æœ‰ {len(industries_df)} ä¸ªè¡Œä¸š")
                industries_to_process = industries_df
            else:
                print(f"ğŸ§ª æµ‹è¯•æ¨¡å¼ï¼šåªå¤„ç†å‰ {test_limit} ä¸ªè¡Œä¸š")
                industries_to_process = industries_df.head(test_limit)

            for index, row in industries_to_process.iterrows():
                try:
                    # ä½¿ç”¨å®é™…çš„åˆ—åï¼šcode å’Œ name
                    if 'code' not in row or 'name' not in row:
                        print(f"    âŒ ç¬¬{index+1}è¡Œç¼ºå°‘å¿…è¦åˆ—ï¼Œå¯ç”¨åˆ—: {list(row.index)}")
                        continue

                    symbol = row['code']
                    name = row['name']

                    print(f"  ğŸ“Š å¤„ç†è¡Œä¸š: {name} ({symbol}) [{index+1}/{len(industries_df)}]")

                    # ä½¿ç”¨å¸¦é‡è¯•æœºåˆ¶çš„æ–¹æ³•è·å–è¡Œä¸šæŒ‡æ•°æ•°æ®
                    industry_data = self.get_sector_data_with_retry(
                        sector_name=name,
                        sector_type="è¡Œä¸š",
                        start_date=start_date,
                        end_date=end_date
                    )

                    if industry_data is not None and not industry_data.empty:
                        # æ·»åŠ æ¿å—ä»£ç ï¼ˆæ¿å—åç§°å·²åœ¨æ–¹æ³•å†…æ·»åŠ ï¼‰
                        industry_data['æ¿å—ä»£ç '] = symbol

                        all_industry_data.append(industry_data)
                        success_count += 1
                        print(f"    âœ… æˆåŠŸè·å– {len(industry_data)} æ¡æ•°æ®")
                    else:
                        print(f"    âš ï¸ æœªè·å–åˆ°æ•°æ®")

                except Exception as e:
                    # å®‰å…¨çš„å¼‚å¸¸å¤„ç†ï¼Œé¿å…å¼•ç”¨æœªå®šä¹‰çš„å˜é‡
                    row_info = f"ç¬¬{index+1}è¡Œ" if 'name' not in locals() else f"è¡Œä¸š {name}"
                    print(f"    âŒ å¤„ç†{row_info}å¤±è´¥: {e}")
                    continue

            total_industries = len(industries_to_process) if test_limit is not None else len(industries_df)
            print(f"\nğŸ“Š è¡Œä¸šæ•°æ®è·å–å®Œæˆ: {success_count}/{total_industries} æˆåŠŸ")

            # ä¿å­˜è¡Œä¸šæ•°æ®åˆ°ä¸´æ—¶æ–‡ä»¶
            if all_industry_data:
                # åˆå¹¶æ‰€æœ‰è¡Œä¸šæ•°æ®
                combined_data = pd.concat(all_industry_data, ignore_index=True)
                combined_pl = pl.from_pandas(combined_data)

                # åœ¨ä¿å­˜å‰ï¼Œç»Ÿä¸€å…³é”®åˆ—çš„æ•°æ®ç±»å‹ï¼Œé¿å…åç»­æ‹¼æ¥ç±»å‹ä¸ä¸€è‡´
                to_cast_cols = ['æ¿å—ä»£ç ', 'æ¿å—åç§°', 'æ¿å—ç±»å‹', 'æ•°æ®æº']
                for col in to_cast_cols:
                    if col in combined_pl.columns:
                        # å°†åˆ—ç»Ÿä¸€ä¸ºå­—ç¬¦ä¸²ï¼Œå¹¶å°†ç©ºå€¼è½¬ä¸ºç©ºå­—ç¬¦ä¸²ï¼Œé¿å…å‡ºç° Null dtype
                        combined_pl = combined_pl.with_columns([
                            pl.col(col).cast(pl.Utf8).fill_null("").alias(col)
                        ])

                # ä¿å­˜åŸå§‹æ•°æ®åˆ°ä¸´æ—¶æ–‡ä»¶ï¼Œç­‰å¾…SectorDataManageræ·»åŠ æŠ€æœ¯æŒ‡æ ‡
                temp_file = sector_dir / "temp_industry_ths.parquet"
                combined_pl.write_parquet(temp_file)

                print(f"âœ… è¡Œä¸šæ¿å—åŸå§‹æ•°æ®ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶: {combined_pl.height} æ¡è®°å½•")
                return True
            else:
                print("âŒ æ²¡æœ‰è·å–åˆ°ä»»ä½•è¡Œä¸šæ•°æ®")
                return False

        except Exception as e:
            print(f"âŒ æ›´æ–°è¡Œä¸šæ¿å—æ•°æ®å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False

    def _update_concepts(self, start_date: str, end_date: str, sector_dir: Path) -> bool:
        """æ›´æ–°åŒèŠ±é¡ºæ¦‚å¿µæ¿å—æ•°æ®"""
        print("\nğŸ“Š æ›´æ–°åŒèŠ±é¡ºæ¦‚å¿µæ¿å—æ•°æ®...")

        try:
            # ç›´æ¥ä½¿ç”¨AKShareè·å–æ¦‚å¿µåˆ—è¡¨
            print("ğŸ“Š è·å–åŒèŠ±é¡ºæ¦‚å¿µæŒ‡æ•°åˆ—è¡¨...")
            concepts_df = ak.stock_board_concept_name_ths()
            if concepts_df is None or concepts_df.empty:
                print("âŒ è·å–æ¦‚å¿µåˆ—è¡¨å¤±è´¥")
                return False

            print(f"âœ… è·å–åˆ° {len(concepts_df)} ä¸ªåŒèŠ±é¡ºæ¦‚å¿µæŒ‡æ•°")
            print(f"ğŸ“‹ è·å–åˆ° {len(concepts_df)} ä¸ªæ¦‚å¿µæ¿å—")

            all_concept_data = []
            success_count = 0

            # æ£€æŸ¥æ˜¯å¦æœ‰æµ‹è¯•é™åˆ¶ï¼ˆé»˜è®¤å…¨é‡å¤„ç†ï¼‰
            test_limit = getattr(self, '_test_concept_limit', None)
            if test_limit is None:
                print(f"ğŸš€ å…¨é‡æ¨¡å¼ï¼šå¤„ç†æ‰€æœ‰ {len(concepts_df)} ä¸ªæ¦‚å¿µ")
                concepts_to_process = concepts_df
            else:
                print(f"ğŸ§ª æµ‹è¯•æ¨¡å¼ï¼šåªå¤„ç†å‰ {test_limit} ä¸ªæ¦‚å¿µ")
                concepts_to_process = concepts_df.head(test_limit)

            for index, row in concepts_to_process.iterrows():
                try:
                    # ä½¿ç”¨AKShareè¿”å›çš„åˆ—åï¼šcode å’Œ name
                    if 'code' not in row or 'name' not in row:
                        print(f"    âŒ ç¬¬{index+1}è¡Œç¼ºå°‘å¿…è¦åˆ—ï¼Œå¯ç”¨åˆ—: {list(row.index)}")
                        continue

                    symbol = row['code']
                    name = row['name']

                    print(f"  ğŸ“Š å¤„ç†æ¦‚å¿µ: {name} ({symbol}) [{index+1}/{len(concepts_df)}]")

                    # ä½¿ç”¨å¸¦é‡è¯•æœºåˆ¶çš„æ–¹æ³•è·å–æ¦‚å¿µæŒ‡æ•°æ•°æ®
                    concept_data = self.get_sector_data_with_retry(
                        sector_name=name,
                        sector_type="æ¦‚å¿µ",
                        start_date=start_date,
                        end_date=end_date
                    )

                    if concept_data is not None and not concept_data.empty:
                        # æ·»åŠ æ¿å—ä»£ç ï¼ˆæ¿å—åç§°å·²åœ¨æ–¹æ³•å†…æ·»åŠ ï¼‰
                        concept_data['æ¿å—ä»£ç '] = symbol

                        all_concept_data.append(concept_data)
                        success_count += 1
                        print(f"    âœ… æˆåŠŸè·å– {len(concept_data)} æ¡æ•°æ®")

                        # æ¯å¤„ç†50ä¸ªæ¦‚å¿µä¿å­˜ä¸€æ¬¡è¿›åº¦
                        if len(all_concept_data) % 50 == 0:
                            print(f"  ğŸ’¾ ä¿å­˜è¿›åº¦: å·²å¤„ç† {len(all_concept_data)} ä¸ªæ¦‚å¿µ")
                    else:
                        print(f"    âš ï¸ æœªè·å–åˆ°æ•°æ®")

                except Exception as e:
                    # å®‰å…¨çš„å¼‚å¸¸å¤„ç†ï¼Œé¿å…å¼•ç”¨æœªå®šä¹‰çš„å˜é‡
                    row_info = f"ç¬¬{index+1}è¡Œ" if 'name' not in locals() else f"æ¦‚å¿µ {name}"
                    print(f"    âŒ å¤„ç†{row_info}å¤±è´¥: {e}")
                    continue

            total_concepts = len(concepts_to_process) if test_limit is not None else len(concepts_df)
            print(f"\nğŸ“Š æ¦‚å¿µæ•°æ®è·å–å®Œæˆ: {success_count}/{total_concepts} æˆåŠŸ")

            # ä¿å­˜æ¦‚å¿µæ•°æ®åˆ°ä¸´æ—¶æ–‡ä»¶
            if all_concept_data:
                # å¦‚æœæ²¡æœ‰data_processorï¼Œä½¿ç”¨ç®€å•ä¿å­˜
                combined_data = pd.concat(all_concept_data, ignore_index=True)
                combined_pl = pl.from_pandas(combined_data)

                # åœ¨ä¿å­˜å‰ï¼Œç»Ÿä¸€å…³é”®åˆ—çš„æ•°æ®ç±»å‹ï¼Œé¿å…åç»­æ‹¼æ¥ç±»å‹ä¸ä¸€è‡´
                to_cast_cols = ['æ¿å—ä»£ç ', 'æ¿å—åç§°', 'æ¿å—ç±»å‹', 'æ•°æ®æº']
                for col in to_cast_cols:
                    if col in combined_pl.columns:
                        combined_pl = combined_pl.with_columns([
                            pl.col(col).cast(pl.Utf8).fill_null("").alias(col)
                        ])

                # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶ï¼Œç­‰å¾…åç»­åˆå¹¶
                temp_file = sector_dir / "temp_concept_ths.parquet"
                combined_pl.write_parquet(temp_file)

                print(f"âœ… æ¦‚å¿µæ¿å—åŸå§‹æ•°æ®ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶: {len(combined_data)} æ¡è®°å½•")
                return True
            else:
                print("âŒ æ²¡æœ‰è·å–åˆ°ä»»ä½•æ¦‚å¿µæ•°æ®")
                return False

        except Exception as e:
            print(f"âŒ æ›´æ–°æ¦‚å¿µæ¿å—æ•°æ®å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False

    def update_sector_constituents(self, sector_dir: Path) -> bool:
        """æ›´æ–°åŒèŠ±é¡ºæ‰€æœ‰æˆåˆ†è‚¡æ•°æ®"""
        try:
            print("ğŸš€ å¼€å§‹æ›´æ–°åŒèŠ±é¡ºæˆåˆ†è‚¡æ•°æ®...")

            all_constituents = []
            concept_success = 0
            industry_success = 0

            # ç›´æ¥ä½¿ç”¨AKShareè·å–æ¦‚å¿µæŒ‡æ•°åˆ—è¡¨
            print("ğŸ“Š è·å–åŒèŠ±é¡ºæ¦‚å¿µæŒ‡æ•°åˆ—è¡¨...")
            concepts_df = ak.stock_board_concept_name_ths()
            if concepts_df is not None and not concepts_df.empty:
                print(f"ğŸ“Š æ›´æ–°åŒèŠ±é¡ºæ¦‚å¿µæ¿å—æˆåˆ†è‚¡ ({len(concepts_df)} ä¸ª)...")
                for idx, row in concepts_df.iterrows():
                    code = row.get('code', '')
                    name = row.get('name', '')  # AKShareè¿”å›çš„æ˜¯'name'åˆ—

                    if code and name:
                        print(f"  [{idx+1}/{len(concepts_df)}] {name}({code})")
                        stocks_df = self.get_sector_constituents(code, name, "æ¦‚å¿µ")

                        if stocks_df is not None and not stocks_df.empty:
                            all_constituents.append(stocks_df)
                            concept_success += 1
                            print(f"    âœ… {len(stocks_df)} åªè‚¡ç¥¨")
                        else:
                            print(f"    âŒ è·å–å¤±è´¥")

                        # æ¯åä¸ªæ¿å—ä¼‘æ¯0.5ç§’
                        if (idx + 1) % 10 == 0:
                            print(f"  ğŸ’¤ å·²å¤„ç† {idx + 1} ä¸ªæ¦‚å¿µæ¿å—ï¼Œä¼‘æ¯0.5ç§’...")
                            import time
                            time.sleep(0.5)

            # ç›´æ¥ä½¿ç”¨AKShareè·å–è¡Œä¸šæŒ‡æ•°åˆ—è¡¨
            print("ğŸ“Š è·å–åŒèŠ±é¡ºè¡Œä¸šæŒ‡æ•°åˆ—è¡¨...")
            industries_df = ak.stock_board_industry_name_ths()
            if industries_df is not None and not industries_df.empty:
                print(f"ğŸ“Š æ›´æ–°åŒèŠ±é¡ºè¡Œä¸šæ¿å—æˆåˆ†è‚¡ ({len(industries_df)} ä¸ª)...")
                for idx, row in industries_df.iterrows():
                    # AKShareè¿”å›çš„åˆ—åæ˜¯'code'å’Œ'name'
                    code = row.get('code', '')
                    name = row.get('name', '')

                    if code and name:
                        print(f"  [{idx+1}/{len(industries_df)}] {name}({code})")
                        stocks_df = self.get_sector_constituents(code, name, "è¡Œä¸š")

                        if stocks_df is not None and not stocks_df.empty:
                            all_constituents.append(stocks_df)
                            industry_success += 1
                            print(f"    âœ… {len(stocks_df)} åªè‚¡ç¥¨")
                        else:
                            print(f"    âŒ è·å–å¤±è´¥")

                        # æ¯åä¸ªæ¿å—ä¼‘æ¯0.5ç§’
                        if (idx + 1) % 10 == 0:
                            print(f"  ğŸ’¤ å·²å¤„ç† {idx + 1} ä¸ªè¡Œä¸šæ¿å—ï¼Œä¼‘æ¯0.5ç§’...")
                            import time
                            time.sleep(0.5)

            print(f"âœ… åŒèŠ±é¡ºæˆåˆ†è‚¡æ›´æ–°å®Œæˆ: æ¦‚å¿µ{concept_success}, è¡Œä¸š{industry_success}")

            # ä¿å­˜æˆåˆ†è‚¡æ•°æ®
            if all_constituents:
                print("\nğŸ’¾ ä¿å­˜åŒèŠ±é¡ºæˆåˆ†è‚¡æ•°æ®...")

                try:
                    # åˆå¹¶æ‰€æœ‰æˆåˆ†è‚¡æ•°æ®
                    combined_data = pd.concat(all_constituents, ignore_index=True)

                    # ç¡®ä¿è‚¡ç¥¨ä»£ç æ˜¯6ä½æ ¼å¼ï¼ˆä¸è¶³çš„ç”¨0å¡«å……ï¼‰
                    combined_data['è‚¡ç¥¨ä»£ç '] = combined_data['è‚¡ç¥¨ä»£ç '].astype(str).str.zfill(6)
                    
                    # æŒ‰æ¿å—åç§°å’Œè‚¡ç¥¨ä»£ç å»é‡ï¼Œä¿ç•™ç¬¬ä¸€ä¸ª
                    combined_data = combined_data.drop_duplicates(subset=['æ¿å—åç§°', 'è‚¡ç¥¨ä»£ç '], keep='first')

                    # æ·»åŠ æ•°æ®æºæ ‡è¯†
                    combined_data['æ•°æ®æº'] = 'åŒèŠ±é¡º'
                    combined_data['æ›´æ–°æ—¥æœŸ'] = datetime.now().strftime('%Y-%m-%d')

                    # ä¿å­˜åˆ°Excelæ–‡ä»¶
                    output_file = sector_dir / "åŒèŠ±é¡ºæ¿å—æˆåˆ†è‚¡.xlsx"

                    # åˆ›å»ºExcelå†™å…¥å™¨
                    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
                        # ä¿å­˜æ‰€æœ‰æ•°æ®åˆ°"æ‰€æœ‰æ•°æ®"å·¥ä½œè¡¨
                        combined_data.to_excel(writer, sheet_name='æ‰€æœ‰æ•°æ®', index=False)

                        # æŒ‰æ¿å—ç±»å‹åˆ†åˆ«ä¿å­˜
                        for sector_type in combined_data['æ¿å—ç±»å‹'].unique():
                            type_data = combined_data[combined_data['æ¿å—ç±»å‹'] == sector_type]
                            sheet_name = f"{sector_type}æ¿å—"
                            type_data.to_excel(writer, sheet_name=sheet_name, index=False)

                    print(f"âœ… åŒèŠ±é¡ºæˆåˆ†è‚¡æ•°æ®ä¿å­˜æˆåŠŸ: {len(combined_data)} æ¡è®°å½•")
                    print(f"ğŸ“ ä¿å­˜ä½ç½®: {output_file}")

                    return True

                except Exception as e:
                    print(f"âŒ ä¿å­˜åŒèŠ±é¡ºæˆåˆ†è‚¡æ•°æ®å¤±è´¥: {e}")
                    import traceback
                    traceback.print_exc()
                    return False
            else:
                print("âŒ æ²¡æœ‰è·å–åˆ°ä»»ä½•æˆåˆ†è‚¡æ•°æ®")
                return False

        except Exception as e:
            print(f"âŒ åŒèŠ±é¡ºæˆåˆ†è‚¡æ›´æ–°å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False




class EastmoneyDataProvider:
    """ä¸œæ–¹è´¢å¯Œæ•°æ®æä¾›å™¨ - ä¸“é—¨å¤„ç†ä¸œè´¢æ•°æ®æº"""

    def __init__(self):
        self.source_name = "ä¸œæ–¹è´¢å¯Œ"

    def test_connection(self) -> bool:
        """æµ‹è¯•ä¸œè´¢è¿æ¥"""
        try:
            # æµ‹è¯•è·å–æ¦‚å¿µæ¿å—åç§°
            test_data = ak.stock_board_concept_name_em()
            if test_data is not None and not test_data.empty:
                print("âœ… ä¸œæ–¹è´¢å¯Œè¿æ¥æˆåŠŸ")
                return True
            else:
                print("âŒ ä¸œæ–¹è´¢å¯Œè¿”å›ç©ºæ•°æ®")
                return False
        except Exception as e:
            print(f"âŒ ä¸œæ–¹è´¢å¯Œè¿æ¥å¤±è´¥: {e}")
            return False



    def get_concept_hist_data(self, concept_name: str, start_date: str, end_date: str) -> Optional[pd.DataFrame]:
        """è·å–ä¸œè´¢æ¦‚å¿µæ¿å—å†å²æ•°æ®

        Args:
            concept_name: æ¦‚å¿µæ¿å—åç§°ï¼ˆå¦‚"ç»¿è‰²ç”µåŠ›"ï¼‰ï¼Œä¸æ˜¯ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
        """
        try:
            print(f"ğŸ“Š è·å–ä¸œè´¢æ¦‚å¿µæ¿å—æ•°æ®: {concept_name}")
            data = ak.stock_board_concept_hist_em(
                symbol=concept_name,  # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦ä¼ é€’æ¦‚å¿µåç§°ï¼Œä¸æ˜¯ä»£ç 
                start_date=start_date,
                end_date=end_date,
                period="daily",
                adjust=""  # ä¸å¤æƒï¼Œä¿æŒä¸å…¶ä»–æ•°æ®æºä¸€è‡´
            )
            if data is not None and not data.empty:
                # æ·»åŠ æ¿å—ä¿¡æ¯
                data['æ¿å—åç§°'] = concept_name
                data['æ¿å—ç±»å‹'] = 'æ¦‚å¿µ'
                data['æ•°æ®æº'] = 'ä¸œæ–¹è´¢å¯Œ'
                print(f"âœ… è·å–åˆ° {len(data)} æ¡æ¦‚å¿µæ¿å—æ•°æ®")
                return data
            else:
                print(f"âš ï¸ æ¦‚å¿µæ¿å— {concept_name} æ— æ•°æ®")
                return None
        except Exception as e:
            print(f"âŒ è·å–æ¦‚å¿µæ¿å—æ•°æ®å¤±è´¥: {e}")
            return None

    def get_industry_hist_data(self, symbol: str, start_date: str, end_date: str) -> Optional[pd.DataFrame]:
        """è·å–ä¸œè´¢è¡Œä¸šæ¿å—å†å²æ•°æ®"""
        try:
            print(f"ğŸ“Š è·å–ä¸œè´¢è¡Œä¸šæ¿å—æ•°æ®: {symbol}")
            data = ak.stock_board_industry_hist_em(
                symbol=symbol,
                start_date=start_date,
                end_date=end_date,
                period="æ—¥k",
                adjust="qfq"  # å‰å¤æƒ
            )
            if data is not None and not data.empty:
                # æ·»åŠ æ¿å—ä¿¡æ¯
                data['æ¿å—åç§°'] = symbol
                data['æ¿å—ç±»å‹'] = 'è¡Œä¸š'
                data['æ•°æ®æº'] = 'ä¸œæ–¹è´¢å¯Œ'
                print(f"âœ… è·å–åˆ° {len(data)} æ¡è¡Œä¸šæ¿å—æ•°æ®")
                return data
            else:
                print(f"âš ï¸ è¡Œä¸šæ¿å— {symbol} æ— æ•°æ®")
                return None
        except Exception as e:
            print(f"âŒ è·å–è¡Œä¸šæ¿å—æ•°æ®å¤±è´¥: {e}")
            return None

    def get_concept_constituents(self, symbol: str) -> Optional[pd.DataFrame]:
        """è·å–ä¸œè´¢æ¦‚å¿µæ¿å—æˆåˆ†è‚¡"""
        try:
            print(f"ğŸ“Š è·å–ä¸œè´¢æ¦‚å¿µæ¿å—æˆåˆ†è‚¡: {symbol}")
            data = ak.stock_board_concept_cons_em(symbol=symbol)
            if data is not None and not data.empty:
                # æ ‡å‡†åŒ–æ•°æ®
                current_date = datetime.now().date()

                # ç¡®ä¿æœ‰å¿…è¦çš„åˆ—
                if 'ä»£ç ' in data.columns and 'åç§°' in data.columns:
                    result_data = []
                    for _, row in data.iterrows():
                        result_data.append({
                            'è‚¡ç¥¨ä»£ç ': str(row['ä»£ç ']).zfill(6),
                            'è‚¡ç¥¨åç§°': row['åç§°'],
                            'æ¿å—åç§°': symbol,
                            'æ¿å—ä»£ç ': '',  # ä¸œè´¢æ¥å£ä¸æä¾›æ¿å—ä»£ç 
                            'æ¿å—ç±»å‹': 'æ¦‚å¿µ',
                            'æ›´æ–°æ—¥æœŸ': current_date,
                            'æ•°æ®æº': 'ä¸œæ–¹è´¢å¯Œ'
                        })

                    if result_data:
                        result_df = pd.DataFrame(result_data)
                        print(f"âœ… è·å–åˆ° {len(result_df)} åªæ¦‚å¿µæˆåˆ†è‚¡")
                        return result_df

                print(f"âš ï¸ æ¦‚å¿µæ¿å— {symbol} æˆåˆ†è‚¡æ•°æ®æ ¼å¼å¼‚å¸¸")
                return None
            else:
                print(f"âš ï¸ æ¦‚å¿µæ¿å— {symbol} æ— æˆåˆ†è‚¡æ•°æ®")
                return None
        except Exception as e:
            print(f"âŒ è·å–æ¦‚å¿µæ¿å—æˆåˆ†è‚¡å¤±è´¥: {e}")
            return None

    def get_industry_constituents(self, symbol: str) -> Optional[pd.DataFrame]:
        """è·å–ä¸œè´¢è¡Œä¸šæ¿å—æˆåˆ†è‚¡"""
        try:
            print(f"ğŸ“Š è·å–ä¸œè´¢è¡Œä¸šæ¿å—æˆåˆ†è‚¡: {symbol}")
            data = ak.stock_board_industry_cons_em(symbol=symbol)
            if data is not None and not data.empty:
                # æ ‡å‡†åŒ–æ•°æ®
                current_date = datetime.now().date()

                # ç¡®ä¿æœ‰å¿…è¦çš„åˆ—
                if 'ä»£ç ' in data.columns and 'åç§°' in data.columns:
                    result_data = []
                    for _, row in data.iterrows():
                        result_data.append({
                            'è‚¡ç¥¨ä»£ç ': str(row['ä»£ç ']).zfill(6),
                            'è‚¡ç¥¨åç§°': row['åç§°'],
                            'æ¿å—åç§°': symbol,
                            'æ¿å—ä»£ç ': '',  # ä¸œè´¢æ¥å£ä¸æä¾›æ¿å—ä»£ç 
                            'æ¿å—ç±»å‹': 'è¡Œä¸š',
                            'æ›´æ–°æ—¥æœŸ': current_date,
                            'æ•°æ®æº': 'ä¸œæ–¹è´¢å¯Œ'
                        })

                    if result_data:
                        result_df = pd.DataFrame(result_data)
                        print(f"âœ… è·å–åˆ° {len(result_df)} åªè¡Œä¸šæˆåˆ†è‚¡")
                        return result_df

                print(f"âš ï¸ è¡Œä¸šæ¿å— {symbol} æˆåˆ†è‚¡æ•°æ®æ ¼å¼å¼‚å¸¸")
                return None
            else:
                print(f"âš ï¸ è¡Œä¸šæ¿å— {symbol} æ— æˆåˆ†è‚¡æ•°æ®")
                return None
        except Exception as e:
            print(f"âŒ è·å–è¡Œä¸šæ¿å—æˆåˆ†è‚¡å¤±è´¥: {e}")
            return None

    def update_sector_data(self, start_date: str, end_date: str, sector_dir: Path) -> bool:
        """ä½¿ç”¨ä¸œè´¢æ•°æ®æºæ›´æ–°æ¿å—æ•°æ®"""
        try:
            all_data = []

            # è·å–æ¦‚å¿µæ¿å—
            print("ğŸ“Š è·å–ä¸œè´¢æ¦‚å¿µæ¿å—åç§°...")
            try:
                concepts_df = ak.stock_board_concept_name_em()
                if concepts_df is not None and not concepts_df.empty:
                    print(f"âœ… è·å–åˆ° {len(concepts_df)} ä¸ªä¸œè´¢æ¦‚å¿µæ¿å—")
                    print(f"ğŸ“‹ è·å–åˆ° {len(concepts_df)} ä¸ªæ¦‚å¿µæ¿å—")
                else:
                    print("âš ï¸ ä¸œè´¢æ¦‚å¿µæ¿å—æ•°æ®ä¸ºç©º")
                    concepts_df = None
            except Exception as e:
                print(f"âŒ è·å–ä¸œè´¢æ¦‚å¿µæ¿å—åç§°å¤±è´¥: {e}")
                concepts_df = None

            if concepts_df is not None:

                for index, row in concepts_df.iterrows():
                    try:
                        symbol = row['æ¿å—ä»£ç ']
                        name = row['æ¿å—åç§°']

                        # ä¸œè´¢æ¦‚å¿µæ¿å—APIéœ€è¦ä¼ é€’æ¿å—åç§°ï¼Œä¸æ˜¯ä»£ç 
                        concept_data = self.get_concept_hist_data(name, start_date, end_date)
                        if concept_data is not None:
                            concept_data['æ¿å—åç§°'] = name
                            concept_data['æ¿å—ä»£ç '] = symbol
                            concept_data['æ¿å—ç±»å‹'] = 'æ¦‚å¿µ'
                            concept_data['æ•°æ®æº'] = 'ä¸œæ–¹è´¢å¯Œ'
                            all_data.append(concept_data)
                    except Exception as e:
                        print(f"å¤„ç†æ¦‚å¿µæ¿å— {name} å¤±è´¥: {e}")
                        continue

            # è·å–è¡Œä¸šæ¿å—
            print("ğŸ“Š è·å–ä¸œè´¢è¡Œä¸šæ¿å—åç§°...")
            try:
                industries_df = ak.stock_board_industry_name_em()
                if industries_df is not None and not industries_df.empty:
                    print(f"âœ… è·å–åˆ° {len(industries_df)} ä¸ªä¸œè´¢è¡Œä¸šæ¿å—")
                    print(f"ğŸ“‹ è·å–åˆ° {len(industries_df)} ä¸ªè¡Œä¸šæ¿å—")
                else:
                    print("âš ï¸ ä¸œè´¢è¡Œä¸šæ¿å—æ•°æ®ä¸ºç©º")
                    industries_df = None
            except Exception as e:
                print(f"âŒ è·å–ä¸œè´¢è¡Œä¸šæ¿å—åç§°å¤±è´¥: {e}")
                industries_df = None

            if industries_df is not None:

                for index, row in industries_df.iterrows():
                    try:
                        symbol = row['æ¿å—ä»£ç ']
                        name = row['æ¿å—åç§°']

                        industry_data = self.get_industry_hist_data(symbol, start_date, end_date)
                        if industry_data is not None:
                            industry_data['æ¿å—åç§°'] = name
                            industry_data['æ¿å—ä»£ç '] = symbol
                            industry_data['æ¿å—ç±»å‹'] = 'è¡Œä¸š'
                            industry_data['æ•°æ®æº'] = 'ä¸œæ–¹è´¢å¯Œ'
                            all_data.append(industry_data)
                    except Exception as e:
                        print(f"å¤„ç†è¡Œä¸šæ¿å— {name} å¤±è´¥: {e}")
                        continue

            # ä¿å­˜æ•°æ®
            if all_data:
                # ç®€å•ä¿å­˜
                combined_data = pd.concat(all_data, ignore_index=True)
                combined_pl = pl.from_pandas(combined_data)

                output_file = sector_dir / "sectors_dc.parquet"
                combined_pl.write_parquet(output_file)

                print(f"âœ… ä¸œè´¢æ¿å—æ•°æ®ä¿å­˜æˆåŠŸ: {len(combined_data)} æ¡è®°å½•")
                return True
            else:
                print("âŒ æ²¡æœ‰è·å–åˆ°ä»»ä½•ä¸œè´¢æ•°æ®")
                return False

        except Exception as e:
            print(f"âŒ ä¸œè´¢æ•°æ®æ›´æ–°å¤±è´¥: {e}")
            return False

    def update_all_constituents(self, sector_dir: Path) -> bool:
        """æ›´æ–°ä¸œè´¢æ‰€æœ‰æˆåˆ†è‚¡æ•°æ®"""
        try:
            print("ğŸš€ å¼€å§‹æ›´æ–°ä¸œè´¢æˆåˆ†è‚¡æ•°æ®...")

            all_constituents = []
            concept_success = 0
            industry_success = 0

            # è·å–æ¦‚å¿µæ¿å—åˆ—è¡¨
            print("ğŸ“Š è·å–ä¸œè´¢æ¦‚å¿µæ¿å—åç§°...")
            try:
                concepts_df = ak.stock_board_concept_name_em()
                if concepts_df is not None and not concepts_df.empty:
                    print(f"âœ… è·å–åˆ° {len(concepts_df)} ä¸ªä¸œè´¢æ¦‚å¿µæ¿å—")
                    print(f"ğŸ“Š æ›´æ–°ä¸œè´¢æ¦‚å¿µæ¿å—æˆåˆ†è‚¡ ({len(concepts_df)} ä¸ª)...")
                else:
                    print("âš ï¸ ä¸œè´¢æ¦‚å¿µæ¿å—æ•°æ®ä¸ºç©º")
                    concepts_df = None
            except Exception as e:
                print(f"âŒ è·å–ä¸œè´¢æ¦‚å¿µæ¿å—åç§°å¤±è´¥: {e}")
                concepts_df = None

            if concepts_df is not None:
                for idx, row in concepts_df.iterrows():
                    name = row.get('æ¿å—åç§°', '')

                    if name:
                        print(f"  [{idx+1}/{len(concepts_df)}] {name}")
                        stocks_df = self.get_concept_constituents(name)

                        if stocks_df is not None and not stocks_df.empty:
                            all_constituents.append(stocks_df)
                            concept_success += 1
                            print(f"    âœ… {len(stocks_df)} åªè‚¡ç¥¨")
                        else:
                            print(f"    âŒ è·å–å¤±è´¥")

                        # æ¯åä¸ªæ¿å—ä¼‘æ¯0.5ç§’
                        if (idx + 1) % 10 == 0:
                            print(f"  ğŸ’¤ å·²å¤„ç† {idx + 1} ä¸ªä¸œè´¢æ¦‚å¿µæ¿å—ï¼Œä¼‘æ¯0.5ç§’...")
                            import time
                            time.sleep(0.5)

            # è·å–è¡Œä¸šæ¿å—åˆ—è¡¨
            print("ğŸ“Š è·å–ä¸œè´¢è¡Œä¸šæ¿å—åç§°...")
            try:
                industries_df = ak.stock_board_industry_name_em()
                if industries_df is not None and not industries_df.empty:
                    print(f"âœ… è·å–åˆ° {len(industries_df)} ä¸ªä¸œè´¢è¡Œä¸šæ¿å—")
                    print(f"ğŸ“Š æ›´æ–°ä¸œè´¢è¡Œä¸šæ¿å—æˆåˆ†è‚¡ ({len(industries_df)} ä¸ª)...")
                else:
                    print("âš ï¸ ä¸œè´¢è¡Œä¸šæ¿å—æ•°æ®ä¸ºç©º")
                    industries_df = None
            except Exception as e:
                print(f"âŒ è·å–ä¸œè´¢è¡Œä¸šæ¿å—åç§°å¤±è´¥: {e}")
                industries_df = None

            if industries_df is not None:
                for idx, row in industries_df.iterrows():
                    name = row.get('æ¿å—åç§°', '')

                    if name:
                        print(f"  [{idx+1}/{len(industries_df)}] {name}")
                        stocks_df = self.get_industry_constituents(name)

                        if stocks_df is not None and not stocks_df.empty:
                            all_constituents.append(stocks_df)
                            industry_success += 1
                            print(f"    âœ… {len(stocks_df)} åªè‚¡ç¥¨")
                        else:
                            print(f"    âŒ è·å–å¤±è´¥")

                        # æ¯åä¸ªæ¿å—ä¼‘æ¯0.5ç§’
                        if (idx + 1) % 10 == 0:
                            print(f"  ğŸ’¤ å·²å¤„ç† {idx + 1} ä¸ªä¸œè´¢è¡Œä¸šæ¿å—ï¼Œä¼‘æ¯0.5ç§’...")
                            import time
                            time.sleep(0.5)

            print(f"âœ… ä¸œè´¢æˆåˆ†è‚¡æ›´æ–°å®Œæˆ: æ¦‚å¿µ{concept_success}, è¡Œä¸š{industry_success}")

            # ä¿å­˜æˆåˆ†è‚¡æ•°æ®
            if all_constituents:
                print("\nğŸ’¾ ä¿å­˜ä¸œè´¢æˆåˆ†è‚¡æ•°æ®...")

                try:
                    # åˆå¹¶æ‰€æœ‰æˆåˆ†è‚¡æ•°æ®
                    combined_data = pd.concat(all_constituents, ignore_index=True)

                    # ç¡®ä¿è‚¡ç¥¨ä»£ç æ˜¯6ä½æ ¼å¼ï¼ˆä¸è¶³çš„ç”¨0å¡«å……ï¼‰
                    combined_data['è‚¡ç¥¨ä»£ç '] = combined_data['è‚¡ç¥¨ä»£ç '].astype(str).str.zfill(6)
                    
                    # æŒ‰æ¿å—åç§°å’Œè‚¡ç¥¨ä»£ç å»é‡ï¼Œä¿ç•™ç¬¬ä¸€ä¸ª
                    combined_data = combined_data.drop_duplicates(subset=['æ¿å—åç§°', 'è‚¡ç¥¨ä»£ç '], keep='first')

                    # æ·»åŠ æ•°æ®æºæ ‡è¯†
                    combined_data['æ•°æ®æº'] = 'ä¸œæ–¹è´¢å¯Œ'
                    combined_data['æ›´æ–°æ—¥æœŸ'] = datetime.now().strftime('%Y-%m-%d')

                    # ä¿å­˜åˆ°Excelæ–‡ä»¶
                    output_file = sector_dir / "ä¸œè´¢æ¿å—æˆåˆ†è‚¡.xlsx"

                    # åˆ›å»ºExcelå†™å…¥å™¨
                    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
                        # ä¿å­˜æ‰€æœ‰æ•°æ®åˆ°"æ‰€æœ‰æ•°æ®"å·¥ä½œè¡¨
                        combined_data.to_excel(writer, sheet_name='æ‰€æœ‰æ•°æ®', index=False)

                        # æŒ‰æ¿å—ç±»å‹åˆ†åˆ«ä¿å­˜
                        for sector_type in combined_data['æ¿å—ç±»å‹'].unique():
                            type_data = combined_data[combined_data['æ¿å—ç±»å‹'] == sector_type]
                            sheet_name = f"{sector_type}æ¿å—"
                            type_data.to_excel(writer, sheet_name=sheet_name, index=False)

                    print(f"âœ… ä¸œè´¢æˆåˆ†è‚¡æ•°æ®ä¿å­˜æˆåŠŸ: {len(combined_data)} æ¡è®°å½•")
                    print(f"ğŸ“ ä¿å­˜ä½ç½®: {output_file}")

                    return True

                except Exception as e:
                    print(f"âŒ ä¿å­˜ä¸œè´¢æˆåˆ†è‚¡æ•°æ®å¤±è´¥: {e}")
                    import traceback
                    traceback.print_exc()
                    return False
            else:
                print("âŒ æ²¡æœ‰è·å–åˆ°ä»»ä½•æˆåˆ†è‚¡æ•°æ®")
                return False

        except Exception as e:
            print(f"âŒ ä¸œè´¢æˆåˆ†è‚¡æ›´æ–°å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False


class SectorDataManager:
    """æ¿å—æ•°æ®ç®¡ç†å™¨ - ä¸“æ³¨äºåŠ è½½æœ¬åœ°æ•°æ®ã€åè°ƒæ›´æ–°ã€æä¾›æ•°æ®æ¥å£"""

    def __init__(self, data_dir: str = "data_cache", preferred_source: str = "ths"):
        self.data_dir = Path(data_dir)
        self.sector_dir = self.data_dir / "sectors"
        self.sector_dir.mkdir(parents=True, exist_ok=True)

        # æ–‡ä»¶è·¯å¾„é…ç½®
        self.ths_file = self.sector_dir / "sectors_ths.parquet"
        self.dc_file = self.sector_dir / "sectors_dc.parquet"
        self.ths_constituents_file = self.sector_dir / "åŒèŠ±é¡ºæ¿å—æˆåˆ†è‚¡.xlsx"
        self.dc_constituents_file = self.sector_dir / "ä¸œè´¢æ¿å—æˆåˆ†è‚¡.xlsx"

        # æ•°æ®æä¾›å™¨
        self.ths_provider = ThsDataProvider()
        self.eastmoney_provider = EastmoneyDataProvider()
        self.preferred_source = preferred_source
        
        # æˆåˆ†è‚¡æ•°æ®ç¼“å­˜ - æ€§èƒ½ä¼˜åŒ–
        self._constituents_cache = {}
        self._cache_timestamps = {}
        self._cache_expire_seconds = 300  # ç¼“å­˜5åˆ†é’Ÿ
        
        # ç´¢å¼•ç¼“å­˜ - ä¸ºé¢‘ç¹æŸ¥è¯¢çš„åˆ—å»ºç«‹ç´¢å¼•
        self._index_cache = {}

    def load_sector_data(self, source: str = None, days_back: int = None, include_sectors: bool = True, include_concepts: bool = True, target_date: str = None) -> pl.DataFrame:
        """
        åŠ è½½æ¿å—æ•°æ®

        Args:
            source: æ•°æ®æº ("ths" æˆ– "eastmoney")ï¼Œé»˜è®¤ä½¿ç”¨preferred_source
            days_back: åŠ è½½æœ€è¿‘å¤šå°‘å¤©çš„æ•°æ®
            include_sectors: æ˜¯å¦åŒ…å«è¡Œä¸šæ¿å—
            include_concepts: æ˜¯å¦åŒ…å«æ¦‚å¿µæ¿å—
            target_date: ç›®æ ‡æ—¥æœŸï¼ˆå¯é€‰ï¼‰ï¼Œå¦‚æœæŒ‡å®šåˆ™ä»è¯¥æ—¥æœŸå¼€å§‹å¾€å‰è®¡ç®—

        Returns:
            pl.DataFrame: æ¿å—æ•°æ®
        """
        if source is None:
            source = self.preferred_source

        try:
            # æ ¹æ®æŒ‡å®šçš„æ•°æ®æºåŠ è½½æ•°æ®
            if source == "ths" and self.ths_file.exists():
                print(f"ğŸ“Š åŠ è½½åŒèŠ±é¡ºæ¿å—æ•°æ®: {self.ths_file}")
                df = pl.read_parquet(self.ths_file)
            elif source == "eastmoney" and self.dc_file.exists():
                print(f"ğŸ“Š åŠ è½½ä¸œè´¢æ¿å—æ•°æ®: {self.dc_file}")
                df = pl.read_parquet(self.dc_file)
            else:
                # å°è¯•åŠ è½½ä»»ä½•å¯ç”¨çš„æ•°æ®
                if self.ths_file.exists():
                    print(f"ğŸ“Š åŠ è½½åŒèŠ±é¡ºæ¿å—æ•°æ®: {self.ths_file}")
                    df = pl.read_parquet(self.ths_file)
                elif self.dc_file.exists():
                    print(f"ğŸ“Š åŠ è½½ä¸œè´¢æ¿å—æ•°æ®: {self.dc_file}")
                    df = pl.read_parquet(self.dc_file)
                else:
                    print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°æ¿å—æ•°æ®æ–‡ä»¶")
                    return pl.DataFrame()

            # æŒ‰æ¿å—ç±»å‹ç­›é€‰
            if not include_sectors and not include_concepts:
                return pl.DataFrame()
            elif include_sectors and not include_concepts:
                df = df.filter(pl.col('æ¿å—ç±»å‹') == "è¡Œä¸š")
            elif not include_sectors and include_concepts:
                df = df.filter(pl.col('æ¿å—ç±»å‹') == "æ¦‚å¿µ")
            # å¦‚æœä¸¤è€…éƒ½ä¸ºTrueï¼Œåˆ™ä¸ç­›é€‰

            # ç¡®ä¿æ—¥æœŸåˆ—ä¸ºDateç±»å‹
            if 'æ—¥æœŸ' in df.columns and not df.is_empty():
                if df['æ—¥æœŸ'].dtype == pl.Utf8:
                    df = df.with_columns([
                        pl.col('æ—¥æœŸ').str.strptime(pl.Date, format='%Y-%m-%d', strict=False).alias('æ—¥æœŸ')
                    ])
                elif df['æ—¥æœŸ'].dtype.base_type() == pl.Datetime:
                    df = df.with_columns([
                        pl.col('æ—¥æœŸ').dt.date().alias('æ—¥æœŸ')
                    ])

            # å¦‚æœæŒ‡å®šäº†å¤©æ•°ï¼Œåˆ™ç­›é€‰æœ€è¿‘çš„æ•°æ®
            if days_back is not None and not df.is_empty() and 'æ—¥æœŸ' in df.columns:
                # å¦‚æœæŒ‡å®šäº†target_dateï¼Œåˆ™ä»è¯¥æ—¥æœŸå¼€å§‹å¾€å‰è®¡ç®—
                if target_date:
                    try:
                        if isinstance(target_date, str):
                            end_date = datetime.strptime(target_date, '%Y-%m-%d').date()
                        else:
                            end_date = target_date
                        cutoff_date = end_date - timedelta(days=days_back)
                        df = df.filter((pl.col('æ—¥æœŸ') >= cutoff_date) & (pl.col('æ—¥æœŸ') <= end_date))
                        print(f"ğŸ“… ä½¿ç”¨æŒ‡å®šæ—¥æœŸèŒƒå›´: {cutoff_date} è‡³ {end_date}")
                    except Exception as e:
                        print(f"âš ï¸ è§£ætarget_dateå¤±è´¥ï¼Œä½¿ç”¨å½“å‰æ—¥æœŸ: {e}")
                        cutoff_date = datetime.now().date() - timedelta(days=days_back)
                        df = df.filter(pl.col('æ—¥æœŸ') >= cutoff_date)
                else:
                    cutoff_date = datetime.now().date() - timedelta(days=days_back)
                    df = df.filter(pl.col('æ—¥æœŸ') >= cutoff_date)

            return df.sort(['æ—¥æœŸ', 'æ¿å—ç±»å‹', 'æ¿å—åç§°']) if not df.is_empty() else df

        except Exception as e:
            print(f"âŒ åŠ è½½æ¿å—æ•°æ®å¤±è´¥: {e}")
            return pl.DataFrame()

    def get_sector_kline_data(self, sector_name: str, days_back: int = 30, target_date: str = None) -> pl.DataFrame:
        """
        è·å–å•ä¸ªæ¿å—çš„Kçº¿æ•°æ®ï¼Œç”¨äºå‰ç«¯åŸç”ŸEChartsæ¸²æŸ“
        
        Args:
            sector_name: æ¿å—åç§°
            days_back: è·å–æœ€è¿‘å¤šå°‘å¤©çš„æ•°æ®
            target_date: ç›®æ ‡æ—¥æœŸï¼ˆå¯é€‰ï¼‰ï¼Œå¦‚æœæŒ‡å®šåˆ™ä»è¯¥æ—¥æœŸå¼€å§‹å¾€å‰è®¡ç®—
            
        Returns:
            pl.DataFrame: åŒ…å«æ—¥æœŸã€å¼€ç›˜ã€æ”¶ç›˜ã€æœ€é«˜ã€æœ€ä½ã€æˆäº¤é‡ã€æˆäº¤é¢ç­‰åˆ—çš„æ•°æ®
        """
        try:
            print(f"ğŸ” è·å–æ¿å—Kçº¿æ•°æ®: {sector_name}, å¤©æ•°: {days_back}, ç›®æ ‡æ—¥æœŸ: {target_date}")
            
            # åŠ è½½æ‰€æœ‰æ¿å—æ•°æ®ï¼Œä¼ é€’target_dateå‚æ•°
            all_data = self.load_sector_data(days_back=days_back, target_date=target_date)
            
            if all_data.is_empty():
                print(f"âŒ æœªæ‰¾åˆ°æ¿å—æ•°æ®")
                return pl.DataFrame()
            
            print(f"ğŸ“Š åŠ è½½çš„æ¿å—æ•°æ®èŒƒå›´: {all_data['æ—¥æœŸ'].min()} è‡³ {all_data['æ—¥æœŸ'].max()}")
            
            # ç­›é€‰æŒ‡å®šæ¿å—çš„æ•°æ®
            sector_data = all_data.filter(pl.col('æ¿å—åç§°') == sector_name)
            
            if sector_data.is_empty():
                print(f"âŒ æœªæ‰¾åˆ°æ¿å— '{sector_name}' çš„æ•°æ®")
                return pl.DataFrame()
            
            print(f"âœ… æ‰¾åˆ°æ¿å— '{sector_name}' æ•°æ®: {sector_data.height} æ¡è®°å½•")
            
            # æŒ‰æ—¥æœŸæ’åº
            sector_data = sector_data.sort('æ—¥æœŸ')
            
            # ç¡®ä¿åŒ…å«å¿…è¦çš„åˆ—ï¼Œå¦‚æœç¼ºå°‘åˆ™è¡¥å……
            # åŸºç¡€å¿…éœ€åˆ—ï¼ˆç”¨äºè®¡ç®—ä¸Kçº¿å±•ç¤ºï¼‰
            base_required_columns = ['æ—¥æœŸ', 'å¼€ç›˜', 'æ”¶ç›˜', 'æœ€é«˜', 'æœ€ä½']
            optional_columns = ['æˆäº¤é‡', 'æˆäº¤é¢', 'æ¢æ‰‹ç‡', 'æ€»å¸‚å€¼']

            # å…ˆæ ¡éªŒåŸºç¡€å¿…éœ€åˆ—
            base_missing = [col for col in base_required_columns if col not in sector_data.columns]
            if base_missing:
                print(f"âŒ æ¿å—æ•°æ®ç¼ºå°‘åŸºç¡€å¿…éœ€åˆ—: {base_missing}")
                return pl.DataFrame()

            # è‹¥ç¼ºå°‘æ¶¨è·Œå¹…åˆ™æŒ‰ (æ”¶ç›˜-å¼€ç›˜)/å¼€ç›˜*100 è®¡ç®—è¡¥é½ï¼Œé¿å…å› ç¼ºåˆ—è€Œæ•´ä½“å¤±è´¥
            if 'æ¶¨è·Œå¹…' not in sector_data.columns:
                try:
                    sector_data = sector_data.with_columns([
                        pl.when(pl.col('å¼€ç›˜').is_not_null() & (pl.col('å¼€ç›˜') != 0))
                          .then(((pl.col('æ”¶ç›˜') - pl.col('å¼€ç›˜')) / pl.col('å¼€ç›˜') * 100))
                          .otherwise(pl.lit(0.0))
                          .cast(pl.Float64)
                          .alias('æ¶¨è·Œå¹…')
                    ])
                    print("ğŸ”§ å·²è‡ªåŠ¨è¡¥é½ç¼ºå¤±åˆ—: æ¶¨è·Œå¹…")
                except Exception as _e:
                    print(f"âŒ è®¡ç®—æ¶¨è·Œå¹…å¤±è´¥: {_e}")
                    return pl.DataFrame()
            
            # è¡¥å……å¯é€‰åˆ—ï¼ˆå¦‚æœç¼ºå°‘åˆ™è®¾ä¸º0ï¼‰
            for col in optional_columns:
                if col not in sector_data.columns:
                    sector_data = sector_data.with_columns([
                        pl.lit(0.0).alias(col)
                    ])
            
            # é€‰æ‹©å’Œé‡å‘½ååˆ—ï¼Œç¡®ä¿ä¸å‰ç«¯æœŸæœ›çš„æ ¼å¼ä¸€è‡´
            kline_data = sector_data.select([
                pl.col('æ—¥æœŸ'),
                pl.col('å¼€ç›˜').alias('å¼€ç›˜'),
                pl.col('æ”¶ç›˜').alias('æ”¶ç›˜'), 
                pl.col('æœ€é«˜').alias('æœ€é«˜'),
                pl.col('æœ€ä½').alias('æœ€ä½'),
                pl.col('æˆäº¤é‡').alias('æˆäº¤é‡'),
                pl.col('æˆäº¤é¢').alias('æˆäº¤é¢'),
                pl.col('æ¶¨è·Œå¹…').alias('æ¶¨è·Œå¹…')
            ])
            
            print(f"âœ… æˆåŠŸè·å–æ¿å— '{sector_name}' çš„Kçº¿æ•°æ®: {kline_data.height} æ¡è®°å½•")
            print(f"ğŸ“… æ•°æ®æ—¥æœŸèŒƒå›´: {kline_data['æ—¥æœŸ'].min()} è‡³ {kline_data['æ—¥æœŸ'].max()}")
            
            return kline_data
            
        except Exception as e:
            print(f"âŒ è·å–æ¿å—Kçº¿æ•°æ®å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return pl.DataFrame()

    def is_latest_trading_day(self) -> bool:
        """æ£€æŸ¥æ¿å—æ•°æ®æ˜¯å¦æ˜¯æœ€æ–°äº¤æ˜“æ—¥çš„æ•°æ®

        é€»è¾‘ï¼š
        1. è·å–ç°æœ‰æ•°æ®çš„æœ€æ–°æ—¥æœŸ
        2. è·å–å½“å‰åº”è¯¥æ›´æ–°åˆ°çš„æœ€æ–°äº¤æ˜“æ—¥æœŸ
        3. åˆ¤æ–­å½“å¤©æ˜¯å¦ä¸ºäº¤æ˜“æ—¥ï¼Œæ˜¯å¦å·²è¿‡18:00
        4. è€ƒè™‘å‘¨æœ«å’ŒèŠ‚å‡æ—¥çš„å½±å“
        """
        try:
            # 1. è·å–ç°æœ‰æ•°æ®çš„æœ€æ–°æ—¥æœŸ
            df = self.load_sector_data()
            if df.is_empty():
                print("æ¿å—æ•°æ®ä¸ºç©ºï¼Œéœ€è¦æ›´æ–°")
                return False

            if 'æ—¥æœŸ' not in df.columns:
                print("è­¦å‘Š: æ¿å—æ•°æ®ä¸­ç¼ºå°‘æ—¥æœŸåˆ—")
                return False

            # è§£æç°æœ‰æ•°æ®çš„æœ€æ–°æ—¥æœŸ
            latest_date_raw = df['æ—¥æœŸ'].max()
            if isinstance(latest_date_raw, str):
                try:
                    latest_local_date = datetime.strptime(latest_date_raw, '%Y-%m-%d').date()
                except ValueError:
                    try:
                        latest_local_date = datetime.strptime(latest_date_raw, '%Y/%m/%d').date()
                    except ValueError:
                        latest_local_date = datetime.strptime(latest_date_raw, '%Y%m%d').date()
            elif isinstance(latest_date_raw, datetime):
                latest_local_date = latest_date_raw.date()
            elif isinstance(latest_date_raw, date):
                latest_local_date = latest_date_raw
            else:
                print(f"âš ï¸ æœªçŸ¥çš„æ—¥æœŸç±»å‹: {type(latest_date_raw)}, å€¼: {latest_date_raw}")
                return False

            # 2. è·å–å½“å‰æ—¶é—´ä¿¡æ¯
            now = datetime.now()
            current_date = now.date()
            current_time = now.time()

            # 3. å®šä¹‰æ•°æ®æ›´æ–°æ—¶é—´ï¼ˆ18:00åè®¤ä¸ºå½“æ—¥æ•°æ®å·²æ›´æ–°ï¼‰
            from datetime import time as dt_time
            update_time = dt_time(18, 0)  # 18:00

            # 4. ä½¿ç”¨holidaysåº“åˆ¤æ–­èŠ‚å‡æ—¥
            def is_holiday(check_date):
                """ä½¿ç”¨holidaysåº“åˆ¤æ–­æ˜¯å¦ä¸ºä¸­å›½èŠ‚å‡æ—¥"""
                try:
                    import holidays
                    # åˆ›å»ºä¸­å›½èŠ‚å‡æ—¥å¯¹è±¡
                    china_holidays = holidays.China(years=check_date.year)
                    return check_date in china_holidays
                except Exception as e:
                    print(f"âš ï¸ èŠ‚å‡æ—¥åˆ¤æ–­å¤±è´¥: {e}")
                    return False

            # 5. åˆ¤æ–­æ˜¯å¦ä¸ºäº¤æ˜“æ—¥ï¼ˆéå‘¨æœ«ä¸”éèŠ‚å‡æ—¥ï¼‰
            def is_trading_day(check_date):
                """åˆ¤æ–­æ˜¯å¦ä¸ºäº¤æ˜“æ—¥"""
                # å‘¨æœ«ä¸æ˜¯äº¤æ˜“æ—¥
                if check_date.weekday() >= 5:  # 5=å‘¨å…­, 6=å‘¨æ—¥
                    return False
                # èŠ‚å‡æ—¥ä¸æ˜¯äº¤æ˜“æ—¥
                if is_holiday(check_date):
                    return False
                return True

            # 6. è·å–å‰ä¸€ä¸ªäº¤æ˜“æ—¥
            def get_previous_trading_day(from_date):
                """è·å–æŒ‡å®šæ—¥æœŸå‰çš„æœ€è¿‘ä¸€ä¸ªäº¤æ˜“æ—¥"""
                check_date = from_date - timedelta(days=1)
                for _ in range(15):  # æœ€å¤šå¾€å‰æ‰¾15å¤©ï¼ˆè€ƒè™‘é•¿å‡æœŸï¼‰
                    if is_trading_day(check_date):
                        return check_date
                    check_date -= timedelta(days=1)
                # å¦‚æœ15å¤©å†…éƒ½æ²¡æ‰¾åˆ°ï¼Œè¿”å›15å¤©å‰çš„æ—¥æœŸ
                return from_date - timedelta(days=15)

            # 7. è·å–æœ€æ–°åº”è¯¥æ›´æ–°åˆ°çš„äº¤æ˜“æ—¥æœŸ
            def get_latest_expected_trading_date():
                """è·å–æœ€æ–°åº”è¯¥æ›´æ–°åˆ°çš„äº¤æ˜“æ—¥æœŸ"""
                if is_trading_day(current_date):
                    # ä»Šå¤©æ˜¯äº¤æ˜“æ—¥
                    if current_time >= update_time:
                        # å·²è¿‡18:00ï¼Œåº”è¯¥æœ‰ä»Šå¤©çš„æ•°æ®
                        return current_date
                    else:
                        # æœªè¿‡18:00ï¼Œåº”è¯¥æœ‰å‰ä¸€ä¸ªäº¤æ˜“æ—¥çš„æ•°æ®
                        return get_previous_trading_day(current_date)
                else:
                    # ä»Šå¤©ä¸æ˜¯äº¤æ˜“æ—¥ï¼Œåº”è¯¥æœ‰æœ€è¿‘ä¸€ä¸ªäº¤æ˜“æ—¥çš„æ•°æ®
                    return get_previous_trading_day(current_date)

            # 8. æ¯”è¾ƒç°æœ‰æ•°æ®çš„æœ€æ–°æ—¥æœŸä¸æœ€æ–°äº¤æ˜“æ—¥ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦æ›´æ–°
            expected_latest_date = get_latest_expected_trading_date()

            print(f"ğŸ“Š ç°æœ‰æ•°æ®æœ€æ–°æ—¥æœŸ: {latest_local_date}")
            print(f"ğŸ“Š æœ€æ–°äº¤æ˜“æ—¥æœŸ: {expected_latest_date}")

            # å¦‚æœç°æœ‰æ•°æ®æ—¥æœŸ >= æœ€æ–°äº¤æ˜“æ—¥æœŸï¼Œåˆ™è®¤ä¸ºæ˜¯æœ€æ–°çš„
            is_latest = latest_local_date >= expected_latest_date

            if is_latest:
                print("âœ… æ¿å—æ•°æ®å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€æ›´æ–°")
            else:
                print("ğŸ“Š æ¿å—æ•°æ®éœ€è¦æ›´æ–°")

            return is_latest

        except Exception as e:
            print(f"âŒ æ£€æŸ¥æ˜¯å¦ä¸ºæœ€æ–°äº¤æ˜“æ—¥å¤±è´¥: {e}")
            return False

    def get_sector_daily_data(self, date_str: str = None) -> pl.DataFrame:
        """ä»æœ¬åœ°æ•°æ®è·å–æŒ‡å®šæ—¥æœŸçš„æ¿å—æ•°æ®"""
        try:
            df = self.load_sector_data()

            if df.is_empty():
                print("âš ï¸ æœ¬åœ°æ— è¡Œä¸šæ¿å—æ•°æ®ï¼Œè¯·å…ˆæ›´æ–°æ•°æ®")
                return pl.DataFrame()

            if date_str is not None:
                # è½¬æ¢æ—¥æœŸæ ¼å¼
                if len(date_str) == 8:  # YYYYMMDDæ ¼å¼
                    target_date = datetime.strptime(date_str, '%Y%m%d').date()
                else:  # YYYY-MM-DDæ ¼å¼
                    target_date = datetime.strptime(date_str, '%Y-%m-%d').date()

                # ç­›é€‰æŒ‡å®šæ—¥æœŸçš„æ•°æ®ï¼ˆç°åœ¨æ—¥æœŸåˆ—åº”è¯¥æ˜¯Dateç±»å‹ï¼‰
                df = df.filter(pl.col('æ—¥æœŸ') == target_date)

                if df.is_empty():
                    print(f"âš ï¸ æœªæ‰¾åˆ° {date_str} çš„è¡Œä¸šæ¿å—æ•°æ®")
                    return pl.DataFrame()
            else:
                # å¦‚æœæ²¡æœ‰æŒ‡å®šæ—¥æœŸï¼Œè¿”å›æœ€æ–°æ—¥æœŸçš„æ•°æ®
                if 'æ—¥æœŸ' in df.columns:
                    latest_date = df['æ—¥æœŸ'].max()
                    df = df.filter(pl.col('æ—¥æœŸ') == latest_date)

            print(f"ğŸ“Š è·å–åˆ° {df.height} æ¡è¡Œä¸šæ¿å—æ•°æ®")
            return df

        except Exception as e:
            print(f"âŒ è·å–æ¿å—æ•°æ®å¤±è´¥: {e}")
            return pl.DataFrame()

    def update_sector_data(self, source: str = None, start_date: str = None, end_date: str = None) -> bool:
        """ä½¿ç”¨æŒ‡å®šæ•°æ®æºæ›´æ–°æ¿å—æ•°æ®"""
        if source is None:
            source = self.preferred_source

        if start_date is None:
            start_date = (datetime.now() - timedelta(days=30)).strftime('%Y%m%d')
        if end_date is None:
            end_date = datetime.now().strftime('%Y%m%d')

        print(f"ğŸ“Š ä½¿ç”¨{source}æ•°æ®æºæ›´æ–°æ¿å—æ•°æ® ({start_date} - {end_date})")

        all_data = []
        success = False

        if source == "ths":
            # ä½¿ç”¨åŒèŠ±é¡ºæ•°æ®æºæ›´æ–°æ¿å—æ•°æ®
            try:
                print("ğŸ“Š ä½¿ç”¨åŒèŠ±é¡ºæ•°æ®æºæ›´æ–°æ¿å—æ•°æ®...")
                # è°ƒç”¨åŒèŠ±é¡ºæ•°æ®æä¾›å™¨çš„æ¿å—æ•°æ®æ›´æ–°æ–¹æ³•
                # update_all_sectorsåªæ¥å—sector_dirå‚æ•°ï¼Œç”¨äºæ›´æ–°æˆåˆ†è‚¡æ•°æ®
                # å¯¹äºæ¿å—å†å²æ•°æ®ï¼Œä½¿ç”¨update_sector_dataæ–¹æ³•
                success = self.ths_provider.update_sector_data(self.sector_dir, years_back=1, force_update=False)

                if success:
                    # ThsDataProviderå·²ç»å°†æ–°æ•°æ®ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶ï¼Œç°åœ¨å¤„ç†æŠ€æœ¯æŒ‡æ ‡å’Œåˆå¹¶
                    temp_new_data_file = self.sector_dir / "temp_new_data_ths.parquet"

                    if temp_new_data_file.exists():
                        print("ğŸ“Š å¤„ç†ThsDataProviderä¿å­˜çš„æ–°æ•°æ®...")
                        new_data = pl.read_parquet(temp_new_data_file)
                        print(f"ğŸ“Š æ–°æ•°æ®: {new_data.height} æ¡è®°å½•")

                        # è§„èŒƒæ–°æ•°æ®çš„å…³é”®åˆ—ç±»å‹ï¼Œé¿å…ä¸å†å²æ•°æ®æ‹¼æ¥æ—¶æŠ¥ dtype å†²çª
                        cols_to_utf8 = ['æ¿å—ä»£ç ', 'æ¿å—åç§°', 'æ¿å—ç±»å‹', 'æ•°æ®æº']
                        present_cols = [c for c in cols_to_utf8 if c in new_data.columns]
                        if present_cols:
                            new_data = new_data.with_columns([
                                pl.col(c).cast(pl.Utf8).fill_null("").alias(c) for c in present_cols
                            ])

                        # å°†æ—¥æœŸä¸æ•°å€¼åˆ—ç»Ÿä¸€ä¸ºä¸å†å²æ–‡ä»¶ä¸€è‡´çš„ç±»å‹
                        numeric_cols = [
                            'å¼€ç›˜', 'æ”¶ç›˜', 'æœ€é«˜', 'æœ€ä½', 'æˆäº¤é‡', 'æˆäº¤é¢',
                            'æ¢æ‰‹ç‡', 'æ¶¨è·Œå¹…', 'æŒ¯å¹…', '5æ—¥æ¶¨è·Œå¹…', '10æ—¥æ¶¨è·Œå¹…',
                            'MA5', 'MA10', 'MA20', 'æˆäº¤é¢é‡æ¯”'
                        ]
                        present_numeric = [c for c in numeric_cols if c in new_data.columns]
                        cast_exprs = []
                        if 'æ—¥æœŸ' in new_data.columns:
                            # å…ˆç»Ÿä¸€ä¸ºå­—ç¬¦ä¸²å†å®½æ¾è§£æä¸ºæ—¥æœŸ
                            cast_exprs.append(
                                pl.col('æ—¥æœŸ')
                                .cast(pl.Utf8)
                                .str.strptime(pl.Date, strict=False)
                                .alias('æ—¥æœŸ')
                            )
                        for c in present_numeric:
                            cast_exprs.append(pl.col(c).cast(pl.Float64).alias(c))
                        if cast_exprs:
                            new_data = new_data.with_columns(cast_exprs)

                        # ä¸ºæ–°æ•°æ®æ·»åŠ æŠ€æœ¯æŒ‡æ ‡
                        print("ğŸ“Š ä¸ºæ–°æ•°æ®è®¡ç®—æŠ€æœ¯æŒ‡æ ‡...")
                        new_data_with_indicators = self._calculate_technical_indicators(new_data)
                        print(f"ğŸ“Š æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å®Œæˆ: {new_data_with_indicators.height} æ¡è®°å½•, {len(new_data_with_indicators.columns)} åˆ—")

                        # åˆå¹¶å†å²æ•°æ®å’Œæ–°æ•°æ®
                        if self.ths_file.exists():
                            print(f"ğŸ“Š è¯»å–å†å²æ•°æ®: {self.ths_file}")
                            historical_data = pl.read_parquet(self.ths_file)
                            # åŒæ ·è§„èŒƒå†å²æ•°æ®ï¼Œä»¥ç¡®ä¿ç±»å‹ä¸€è‡´
                            present_cols_hist = [c for c in cols_to_utf8 if c in historical_data.columns]
                            if present_cols_hist:
                                historical_data = historical_data.with_columns([
                                    pl.col(c).cast(pl.Utf8).fill_null("").alias(c) for c in present_cols_hist
                                ])
                            print(f"ğŸ“Š å†å²æ•°æ®: {historical_data.height} æ¡è®°å½•")

                            # ç¡®ä¿åˆ—é¡ºåºä¸€è‡´
                            historical_columns = set(historical_data.columns)
                            new_columns = set(new_data_with_indicators.columns)
                            common_columns = list(historical_columns.intersection(new_columns))

                            print(f"ğŸ“Š å…±åŒåˆ—æ•°: {len(common_columns)}")

                            # åœ¨é‡æ’åˆ—ä¹‹å‰ï¼Œå…ˆå°†æ–°æ•°æ®åˆ—ç±»å‹å¯¹é½åˆ°å†å²æ•°æ®çš„schema
                            try:
                                target_schema = historical_data.schema
                                align_exprs = []
                                for col in common_columns:
                                    try:
                                        target_dtype = target_schema.get(col)
                                        if target_dtype is not None:
                                            # å¯¹é½ä¸ºç›®æ ‡ç±»å‹
                                            align_exprs.append(pl.col(col).cast(target_dtype).alias(col))
                                    except Exception:
                                        pass
                                if align_exprs:
                                    new_data_with_indicators = new_data_with_indicators.with_columns(align_exprs)
                            except Exception as _e:
                                print(f"âš ï¸ åˆ—ç±»å‹å¯¹é½æ—¶å‡ºé”™: {_e}")

                            # é‡æ–°æ’åºåˆ—ï¼Œç¡®ä¿ä¸€è‡´æ€§
                            historical_data_aligned = historical_data.select(common_columns)
                            new_data_aligned = new_data_with_indicators.select(common_columns)

                            # åˆå¹¶æ•°æ®
                            unified_data = pl.concat([historical_data_aligned, new_data_aligned])

                            # æŒ‰æ—¥æœŸã€æ¿å—åç§°å»é‡ï¼Œä¿ç•™æœ€æ–°çš„æ•°æ®
                            unified_data = unified_data.unique(subset=['æ—¥æœŸ', 'æ¿å—åç§°','æ¿å—ç±»å‹'], keep='last')
                            print(f"ğŸ“Š å»é‡åæ•°æ®: {unified_data.height} æ¡è®°å½•")
                        else:
                            print("ï¿½ åˆ›å»ºæ–°çš„æ•°æ®æ–‡ä»¶")
                            unified_data = new_data_with_indicators

                        # ä¿å­˜åˆå¹¶åçš„æ•°æ®
                        unified_data.write_parquet(self.ths_file)
                        print(f"âœ… æ•°æ®ä¿å­˜æˆåŠŸ: {self.ths_file}")

                        # æ˜¾ç¤ºæ–°å¢æ•°æ®ç»Ÿè®¡
                        new_records = unified_data.height - historical_data_aligned.height
                        print(f"ğŸ“Š æ–°å¢æ•°æ®ç»Ÿè®¡:")
                        print(f"  åŸæœ‰è®°å½•æ•°: {historical_data_aligned.height}")
                        print(f"  å½“å‰è®°å½•æ•°: {unified_data.height}")
                        print(f"  æ–°å¢è®°å½•æ•°: {new_records}")


                        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                        #temp_new_data_file.unlink()
                        #print("ğŸ—‘ï¸ ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†")

                        success = True
                    else:
                        print("âŒ æœªæ‰¾åˆ°ThsDataProviderä¿å­˜çš„ä¸´æ—¶æ–‡ä»¶")
                        success = False

            except Exception as e:
                print(f"âŒ åŒèŠ±é¡ºæ•°æ®æºæ›´æ–°å¤±è´¥: {e}")
                success = False

        elif source == "eastmoney":
            # ä½¿ç”¨ä¸œè´¢æ•°æ®æºæ›´æ–°æ¿å—æ•°æ®
            try:
                print("ğŸ“Š ä½¿ç”¨ä¸œè´¢æ•°æ®æºæ›´æ–°æ¿å—æ•°æ®...")
                # è°ƒç”¨ä¸œè´¢æ•°æ®æä¾›å™¨çš„æ¿å—æ•°æ®æ›´æ–°æ–¹æ³•
                success = self.eastmoney_provider.update_sector_data(start_date, end_date, self.sector_dir)

                if success:
                    # åŠ è½½æ›´æ–°åçš„æ•°æ®
                    if self.dc_file.exists():
                        df = pl.read_parquet(self.dc_file)

                        # æ£€æŸ¥æ˜¯å¦åŒ…å«æŠ€æœ¯æŒ‡æ ‡
                        required_columns = ['æ¶¨è·Œå¹…', 'æŒ¯å¹…', 'æ¢æ‰‹ç‡', '5æ—¥æ¶¨è·Œå¹…', '10æ—¥æ¶¨è·Œå¹…', 'MA5', 'MA10', 'MA20', 'æˆäº¤é¢é‡æ¯”']
                        missing_columns = [col for col in required_columns if col not in df.columns]

                        if missing_columns:
                            print(f"âš ï¸ æ•°æ®ç¼ºå°‘æŠ€æœ¯æŒ‡æ ‡åˆ—: {missing_columns}")
                            print("ğŸ“Š é‡æ–°è®¡ç®—æŠ€æœ¯æŒ‡æ ‡...")
                            df = self._calculate_technical_indicators(df)

                        all_data.append(df)

                        # ä¿å­˜æ›´æ–°åçš„æ•°æ®
                        print(f"ğŸ’¾ ä¿å­˜ä¸œè´¢æ¿å—æ•°æ®åˆ°æ–‡ä»¶...")
                        df.write_parquet(self.dc_file)
                        print(f"âœ… æ•°æ®å·²ä¿å­˜: {df.height} æ¡è®°å½•, {len(df.columns)} åˆ—")

                        success = True
                    else:
                        success = False

            except Exception as e:
                print(f"âŒ ä¸œè´¢æ•°æ®æºæ›´æ–°å¤±è´¥: {e}")
                success = False

        else:
            print(f"âŒ ä¸æ”¯æŒçš„æ•°æ®æº: {source}")
            return False

        return success


    def _calculate_technical_indicators(self, df: pl.DataFrame) -> pl.DataFrame:
        """è®¡ç®—æŠ€æœ¯æŒ‡æ ‡"""
        try:
            print("ğŸ“Š è®¡ç®—æŠ€æœ¯æŒ‡æ ‡...")

            # æŒ‰æ¿å—åç§°åˆ†ç»„è®¡ç®—
            result_dfs = []

            # ç¡®ä¿å…³é”®åŸºç¡€åˆ—å­˜åœ¨ï¼Œé¿å…åç»­è®¡ç®—æŠ¥é”™
            base_numeric_defaults = {
                'æˆäº¤é¢': 0.0,
            }
            for base_col, default_val in base_numeric_defaults.items():
                if base_col not in df.columns:
                    df = df.with_columns([pl.lit(float(default_val)).alias(base_col)])

            for sector_name in df['æ¿å—åç§°'].unique():
                sector_df = df.filter(pl.col('æ¿å—åç§°') == sector_name).sort('æ—¥æœŸ')

                # éœ€è¦ç»Ÿä¸€è¡¥é½çš„æŠ€æœ¯æŒ‡æ ‡åˆ—ï¼ˆå…¨éƒ¨ä¸ºæµ®ç‚¹ï¼‰
                indicator_numeric_columns = [
                    'æ¶¨è·Œå¹…', 'æŒ¯å¹…', 'æ¢æ‰‹ç‡', '5æ—¥æ¶¨è·Œå¹…', '10æ—¥æ¶¨è·Œå¹…',
                    'MA5', 'MA10', 'MA20', 'æˆäº¤é¢é‡æ¯”', 'è¿é˜³å¤©æ•°'
                ]

                if sector_df.height < 2:
                    # è¡Œæ•°è¿‡å°‘ï¼Œç›´æ¥è¡¥é½æŠ€æœ¯æŒ‡æ ‡ä¸º0.0ï¼Œç¡®ä¿åˆ—é½å…¨ä¸”ç±»å‹ä¸€è‡´
                    sector_df = sector_df.with_columns([
                        pl.lit(0.0).alias('æ¶¨è·Œå¹…'),
                        pl.lit(0.0).alias('æŒ¯å¹…'),
                        pl.lit(0.0).alias('æ¢æ‰‹ç‡'),
                        pl.lit(0.0).alias('5æ—¥æ¶¨è·Œå¹…'),
                        pl.lit(0.0).alias('10æ—¥æ¶¨è·Œå¹…'),
                        pl.lit(0.0).alias('MA5'),
                        pl.lit(0.0).alias('MA10'),
                        pl.lit(0.0).alias('MA20'),
                        pl.lit(0.0).alias('æˆäº¤é¢é‡æ¯”'),
                        pl.lit(0).alias('è¿é˜³å¤©æ•°'),
                    ])

                    # å¼ºåˆ¶ä¸ºFloat64ï¼Œé¿å…concatæ—¶å‡ºç° Null dtypeï¼ˆè¿é˜³å¤©æ•°ä¸ºæ•´æ•°ç±»å‹ï¼‰
                    sector_df = sector_df.with_columns([
                        pl.col(c).cast(pl.Float64).alias(c) if c != 'è¿é˜³å¤©æ•°' else pl.col(c).cast(pl.Int64).alias(c)
                        for c in indicator_numeric_columns
                    ])

                    result_dfs.append(sector_df)
                    continue

                # è®¡ç®—æ¶¨è·Œå¹…
                sector_df = sector_df.with_columns([
                    # å½“æ—¥æ¶¨è·Œå¹… = (æ”¶ç›˜ä»· - å¼€ç›˜ä»·) / å¼€ç›˜ä»· * 100
                    ((pl.col('æ”¶ç›˜') - pl.col('å¼€ç›˜')) / pl.col('å¼€ç›˜') * 100).alias('æ¶¨è·Œå¹…'),

                    # æŒ¯å¹… = (æœ€é«˜ä»· - æœ€ä½ä»·) / å¼€ç›˜ä»· * 100
                    ((pl.col('æœ€é«˜') - pl.col('æœ€ä½')) / pl.col('å¼€ç›˜') * 100).alias('æŒ¯å¹…'),

                    # æ¢æ‰‹ç‡ï¼ˆæš‚æ—¶è®¾ä¸º0ï¼Œéœ€è¦æµé€šè‚¡æœ¬æ•°æ®ï¼‰
                    pl.lit(0.0).alias('æ¢æ‰‹ç‡')
                ])

                # è®¡ç®—5æ—¥å’Œ10æ—¥æ¶¨è·Œå¹…ï¼ˆéœ€è¦è¶³å¤Ÿçš„å†å²æ•°æ®ï¼‰
                if sector_df.height >= 5:
                    # 5æ—¥æ¶¨è·Œå¹… = (å½“å‰æ”¶ç›˜ä»· - 5æ—¥å‰æ”¶ç›˜ä»·) / 5æ—¥å‰æ”¶ç›˜ä»· * 100
                    sector_df = sector_df.with_columns([
                        ((pl.col('æ”¶ç›˜') - pl.col('æ”¶ç›˜').shift(5)) / pl.col('æ”¶ç›˜').shift(5) * 100).alias('5æ—¥æ¶¨è·Œå¹…')
                    ])
                else:
                    sector_df = sector_df.with_columns([pl.lit(0.0).alias('5æ—¥æ¶¨è·Œå¹…')])

                if sector_df.height >= 10:
                    # 10æ—¥æ¶¨è·Œå¹… = (å½“å‰æ”¶ç›˜ä»· - 10æ—¥å‰æ”¶ç›˜ä»·) / 10æ—¥å‰æ”¶ç›˜ä»· * 100
                    sector_df = sector_df.with_columns([
                        ((pl.col('æ”¶ç›˜') - pl.col('æ”¶ç›˜').shift(10)) / pl.col('æ”¶ç›˜').shift(10) * 100).alias('10æ—¥æ¶¨è·Œå¹…')
                    ])
                else:
                    sector_df = sector_df.with_columns([pl.lit(0.0).alias('10æ—¥æ¶¨è·Œå¹…')])

                # è®¡ç®—ç§»åŠ¨å¹³å‡çº¿ - ç¡®ä¿æ•°æ®ç±»å‹ä¸€è‡´
                if sector_df.height >= 5:
                    sector_df = sector_df.with_columns([
                        pl.col('æ”¶ç›˜').rolling_mean(window_size=5).alias('MA5')
                    ])
                else:
                    sector_df = sector_df.with_columns([pl.lit(0.0).alias('MA5')])

                if sector_df.height >= 10:
                    sector_df = sector_df.with_columns([
                        pl.col('æ”¶ç›˜').rolling_mean(window_size=10).alias('MA10')
                    ])
                else:
                    sector_df = sector_df.with_columns([pl.lit(0.0).alias('MA10')])

                if sector_df.height >= 20:
                    sector_df = sector_df.with_columns([
                        pl.col('æ”¶ç›˜').rolling_mean(window_size=20).alias('MA20')
                    ])
                else:
                    sector_df = sector_df.with_columns([pl.lit(0.0).alias('MA20')])

                # è®¡ç®—æˆäº¤é¢é‡æ¯”ï¼ˆéœ€è¦å†å²å¹³å‡æˆäº¤é¢ï¼‰
                if sector_df.height >= 5:
                    # æˆäº¤é¢é‡æ¯” = å½“æ—¥æˆäº¤é¢ / 5æ—¥å¹³å‡æˆäº¤é¢
                    sector_df = sector_df.with_columns([
                        (pl.col('æˆäº¤é¢') / pl.col('æˆäº¤é¢').rolling_mean(window_size=5)).alias('æˆäº¤é¢é‡æ¯”')
                    ])
                else:
                    sector_df = sector_df.with_columns([pl.lit(0.0).alias('æˆäº¤é¢é‡æ¯”')])

                # è®¡ç®—è¿é˜³å¤©æ•°ï¼ˆè¿ç»­æ”¶ç›˜ä»·å¤§äºå¼€ç›˜ä»·çš„å¤©æ•°ï¼‰
                if sector_df.height >= 1:
                    # åˆ¤æ–­å½“æ—¥æ˜¯å¦ä¸ºé˜³çº¿ï¼ˆæ”¶ç›˜ä»· > å¼€ç›˜ä»·ï¼‰
                    sector_df = sector_df.with_columns([
                        (pl.col('æ”¶ç›˜') > pl.col('å¼€ç›˜')).alias('is_positive_day')
                    ])
                    
                    # è®¡ç®—è¿é˜³å¤©æ•°
                    def calculate_consecutive_positive_days(is_positive_series):
                        """è®¡ç®—è¿ç»­é˜³çº¿å¤©æ•°"""
                        consecutive_days = 0
                        result = []
                        
                        for is_positive in is_positive_series:
                            if is_positive:
                                consecutive_days += 1
                            else:
                                consecutive_days = 0
                            result.append(consecutive_days)
                        
                        return result
                    
                    # åº”ç”¨è¿é˜³å¤©æ•°è®¡ç®—
                    is_positive_list = sector_df['is_positive_day'].to_list()
                    consecutive_days_list = calculate_consecutive_positive_days(is_positive_list)
                    
                    sector_df = sector_df.with_columns([
                        pl.Series(consecutive_days_list).alias('è¿é˜³å¤©æ•°')
                    ])
                else:
                    sector_df = sector_df.with_columns([pl.lit(0).alias('è¿é˜³å¤©æ•°')])

                # ç¡®ä¿æ‰€æœ‰æŒ‡æ ‡åˆ—å­˜åœ¨å¹¶ç»Ÿä¸€ç±»å‹ï¼ˆè¿é˜³å¤©æ•°ä¸ºæ•´æ•°ï¼Œå…¶ä»–ä¸ºæµ®ç‚¹ï¼‰
                sector_df = sector_df.with_columns([
                    pl.col(c).cast(pl.Float64).alias(c) if c in sector_df.columns and c != 'è¿é˜³å¤©æ•°' else 
                    pl.col(c).cast(pl.Int64).alias(c) if c == 'è¿é˜³å¤©æ•°' and c in sector_df.columns else
                    pl.lit(0.0).cast(pl.Float64).alias(c) if c != 'è¿é˜³å¤©æ•°' else
                    pl.lit(0).cast(pl.Int64).alias(c)
                    for c in indicator_numeric_columns
                ])

                result_dfs.append(sector_df)

            # åˆå¹¶æ‰€æœ‰ç»“æœ
            if result_dfs:
                # ç¡®ä¿æ‰€æœ‰DataFrameçš„åˆ—å®Œå…¨ä¸€è‡´
                all_columns = set()
                for df_item in result_dfs:
                    all_columns.update(df_item.columns)

                # å®šä¹‰ä¸åŒç±»å‹çš„åˆ—é›†åˆï¼Œé˜²æ­¢è¯¯å°†æ–‡æœ¬åˆ—è½¬ä¸ºæµ®ç‚¹
                numeric_price_cols = {'å¼€ç›˜', 'æ”¶ç›˜', 'æœ€é«˜', 'æœ€ä½', 'æˆäº¤é‡', 'æˆäº¤é¢', 'æ¢æ‰‹ç‡', 'æ¶¨è·Œå¹…', 'æŒ¯å¹…', '5æ—¥æ¶¨è·Œå¹…', '10æ—¥æ¶¨è·Œå¹…', 'MA5', 'MA10', 'MA20', 'æˆäº¤é¢é‡æ¯”'}
                int_cols = {'è¿é˜³å¤©æ•°'}
                bool_cols = {'is_positive_day'}
                date_cols = {'æ—¥æœŸ'}
                text_cols = {'æ¿å—åç§°', 'æ¿å—ç±»å‹', 'æ¿å—ä»£ç ', 'æ•°æ®æº'}

                # ä¸ºæ¯ä¸ªDataFrameè¡¥é½ç¼ºå¤±çš„åˆ—å¹¶ç»Ÿä¸€æ•°æ®ç±»å‹ï¼ˆä»…å¯¹å·²çŸ¥åˆ—åšå¼ºåˆ¶ç±»å‹ï¼‰
                standardized_dfs = []
                for df_item in result_dfs:
                    # è¡¥é½ç¼ºå¤±åˆ—
                    for col in all_columns:
                        if col not in df_item.columns:
                            if col in int_cols:
                                df_item = df_item.with_columns([pl.lit(0).cast(pl.Int64).alias(col)])
                            elif col in bool_cols:
                                df_item = df_item.with_columns([pl.lit(False).cast(pl.Boolean).alias(col)])
                            elif col in date_cols:
                                df_item = df_item.with_columns([pl.lit(None).cast(pl.Date).alias(col)])
                            elif col in text_cols:
                                df_item = df_item.with_columns([pl.lit("").cast(pl.Utf8).alias(col)])
                            elif col in numeric_price_cols:
                                df_item = df_item.with_columns([pl.lit(0.0).cast(pl.Float64).alias(col)])
                            else:
                                # æœªçŸ¥åˆ—ï¼šä¿æŒç¼ºçœä¸å¼ºåˆ¶è®¾ç±»å‹ï¼Œç»™ä¸ªç©ºå­—ç¬¦ä¸²/0.0æ›´å®‰å…¨ï¼Ÿæ­¤å¤„ä¿æŒä¸ºç©ºåˆ—ä»¥é¿å…é”™è¯¯
                                df_item = df_item.with_columns([pl.lit(None).alias(col)])

                    # ç»Ÿä¸€ç°æœ‰åˆ—ç±»å‹
                    unify_exprs = []
                    for col in all_columns:
                        if col in int_cols:
                            unify_exprs.append(pl.col(col).cast(pl.Int64).alias(col))
                        elif col in bool_cols:
                            unify_exprs.append(pl.col(col).cast(pl.Boolean).alias(col))
                        elif col in date_cols:
                            # å®½æ¾è§£æåˆ°Dateï¼Œä¸ç›´æ¥è®¿é—®dtype
                            unify_exprs.append(
                                pl.coalesce([
                                    pl.col(col).cast(pl.Utf8).str.strptime(pl.Date, strict=False),
                                    pl.col(col).cast(pl.Date)
                                ]).alias(col)
                            )
                        elif col in text_cols:
                            unify_exprs.append(pl.col(col).cast(pl.Utf8).fill_null("").alias(col))
                        elif col in numeric_price_cols:
                            unify_exprs.append(pl.col(col).cast(pl.Float64).alias(col))
                        else:
                            # æœªçŸ¥åˆ—ï¼šä¸æ”¹å˜å…¶ç±»å‹
                            unify_exprs.append(pl.col(col).alias(col))

                    df_item = df_item.with_columns(unify_exprs)

                    # ç»Ÿä¸€åˆ—é¡ºåº
                    df_item = df_item.select(sorted(all_columns))
                    standardized_dfs.append(df_item)

                # ç°åœ¨å¯ä»¥å®‰å…¨æ‹¼æ¥
                final_df = pl.concat(standardized_dfs)
            else:
                final_df = df

            print(f"âœ… æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å®Œæˆï¼Œå¤„ç†äº† {len(result_dfs)} ä¸ªæ¿å—")
            return final_df

        except Exception as e:
            print(f"âŒ è®¡ç®—æŠ€æœ¯æŒ‡æ ‡å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return df  # è¿”å›åŸå§‹æ•°æ®

    def update_constituents_data(self, source: str = None, force_update: bool = False) -> bool:
        """
        æ›´æ–°æˆåˆ†è‚¡æ•°æ® - åè°ƒè°ƒç”¨å¯¹åº”çš„æ•°æ®æä¾›å™¨

        Args:
            source: æ•°æ®æº ("ths" æˆ– "eastmoney")ï¼Œé»˜è®¤ä½¿ç”¨preferred_source
            force_update: æ˜¯å¦å¼ºåˆ¶æ›´æ–°

        Returns:
            æ›´æ–°æ˜¯å¦æˆåŠŸ
        """
        if source is None:
            source = self.preferred_source

        print(f"ğŸš€ ä½¿ç”¨{source}æ•°æ®æºæ›´æ–°æˆåˆ†è‚¡æ•°æ®...")



        # è°ƒç”¨å¯¹åº”çš„æ•°æ®æä¾›å™¨
        try:
            if source == "ths":
                # åŒèŠ±é¡ºæ•°æ®æä¾›å™¨çš„æˆåˆ†è‚¡æ›´æ–°æ–¹æ³•åä¸ºupdate_sector_constituents
                return self.ths_provider.update_sector_constituents(self.sector_dir)
            elif source == "eastmoney":
                return self.eastmoney_provider.update_all_constituents(self.sector_dir)
            else:
                print(f"âŒ ä¸æ”¯æŒçš„æ•°æ®æº: {source}")
                return False
        except Exception as e:
            print(f"âŒ æ›´æ–°æˆåˆ†è‚¡æ•°æ®å¤±è´¥: {e}")
            return False

    def _get_cached_constituents(self, source: str) -> Optional[pl.DataFrame]:
        """è·å–ç¼“å­˜çš„æˆåˆ†è‚¡æ•°æ®"""
        cache_key = f"constituents_{source}"
        
        # æ£€æŸ¥ç¼“å­˜æ˜¯å¦å­˜åœ¨ä¸”æœªè¿‡æœŸ
        if cache_key in self._constituents_cache:
            cache_time = self._cache_timestamps.get(cache_key, 0)
            if time.time() - cache_time < self._cache_expire_seconds:
                print(f"ğŸ’¾ ä½¿ç”¨ç¼“å­˜çš„æˆåˆ†è‚¡æ•°æ® ({source})")
                return self._constituents_cache[cache_key]
            else:
                print(f"â° æˆåˆ†è‚¡ç¼“å­˜å·²è¿‡æœŸï¼Œé‡æ–°åŠ è½½ ({source})")
                # æ¸…ç†è¿‡æœŸç¼“å­˜
                del self._constituents_cache[cache_key]
                del self._cache_timestamps[cache_key]
        
        return None
    
    def _cache_constituents(self, source: str, data: pl.DataFrame):
        """ç¼“å­˜æˆåˆ†è‚¡æ•°æ®"""
        cache_key = f"constituents_{source}"
        self._constituents_cache[cache_key] = data
        self._cache_timestamps[cache_key] = time.time()
        
        # ä¸ºæ¿å—åç§°åˆ—å»ºç«‹ç´¢å¼•ä»¥åŠ é€ŸæŸ¥è¯¢
        self._build_sector_index(cache_key, data)
        
        print(f"ğŸ’¾ å·²ç¼“å­˜æˆåˆ†è‚¡æ•°æ® ({source}), è¡Œæ•°: {len(data)}")
    
    def _build_sector_index(self, cache_key: str, data: pl.DataFrame):
        """ä¸ºæ¿å—åç§°å»ºç«‹ç´¢å¼•"""
        try:
            sector_col = None
            if 'æ¿å—åç§°' in data.columns:
                sector_col = 'æ¿å—åç§°'
            elif 'æ‰€å±æ¿å—' in data.columns:
                sector_col = 'æ‰€å±æ¿å—'
            
            if sector_col:
                # å»ºç«‹æ¿å—åç§°åˆ°è¡Œç´¢å¼•çš„æ˜ å°„
                index_dict = {}
                for i, row in enumerate(data.to_dicts()):
                    sector_name = row.get(sector_col)
                    if sector_name:
                        if sector_name not in index_dict:
                            index_dict[sector_name] = []
                        index_dict[sector_name].append(i)
                
                self._index_cache[f"{cache_key}_sector_index"] = {
                    'column': sector_col,
                    'index': index_dict
                }
                print(f"ğŸ” å·²å»ºç«‹æ¿å—ç´¢å¼•ï¼ŒåŒ…å« {len(index_dict)} ä¸ªæ¿å—")
        except Exception as e:
            print(f"âš ï¸ å»ºç«‹ç´¢å¼•å¤±è´¥: {e}")
    
    def _get_stocks_by_sector_fast(self, cache_key: str, sector_name: str, data: pl.DataFrame) -> Optional[pl.DataFrame]:
        """ä½¿ç”¨ç´¢å¼•å¿«é€Ÿè·å–æ¿å—æˆåˆ†è‚¡"""
        index_key = f"{cache_key}_sector_index"
        
        if index_key in self._index_cache:
            index_info = self._index_cache[index_key]
            sector_index = index_info['index']
            
            # ç²¾ç¡®åŒ¹é…
            if sector_name in sector_index:
                row_indices = sector_index[sector_name]
                return data[row_indices]
            
            # æ¨¡ç³ŠåŒ¹é…
            for indexed_sector in sector_index:
                if sector_name in indexed_sector or indexed_sector in sector_name:
                    row_indices = sector_index[indexed_sector]
                    return data[row_indices]
        
        return None

    def get_sector_stocks(self, sector_name: str, source: str = None) -> Optional[pl.DataFrame]:
        """
        è·å–æ¿å—æˆåˆ†è‚¡

        Args:
            sector_name: æ¿å—åç§°
            source: æ•°æ®æº ("ths" æˆ– "eastmoney")ï¼Œé»˜è®¤ä½¿ç”¨preferred_source

        Returns:
            æˆåˆ†è‚¡æ•°æ®DataFrameï¼ŒåŒ…å«è‚¡ç¥¨ä»£ç ã€è‚¡ç¥¨åç§°ç­‰ä¿¡æ¯
        """
        try:
            if source is None:
                source = self.preferred_source

            # é¦–å…ˆå°è¯•ä»ç¼“å­˜è·å–æ•°æ®
            constituents_pl = self._get_cached_constituents(source)
            
            if constituents_pl is None:
                # ç¼“å­˜æœªå‘½ä¸­ï¼Œä»æ–‡ä»¶åŠ è½½æ•°æ®
                if source == "ths" and self.ths_constituents_file.exists():
                    print(f"ğŸ“Š ä½¿ç”¨åŒèŠ±é¡ºæˆåˆ†è‚¡æ•°æ®: {self.ths_constituents_file}")
                    constituents_data = pd.read_excel(self.ths_constituents_file, sheet_name='æ‰€æœ‰æ•°æ®')
                    constituents_pl = pl.from_pandas(constituents_data)
                    self._cache_constituents(source, constituents_pl)
                elif source == "eastmoney" and self.dc_constituents_file.exists():
                    print(f"ğŸ“Š ä½¿ç”¨ä¸œè´¢æˆåˆ†è‚¡æ•°æ®: {self.dc_constituents_file}")
                    # ä¸œè´¢æˆåˆ†è‚¡æ–‡ä»¶ä½¿ç”¨Sheet1
                    constituents_data = pd.read_excel(self.dc_constituents_file, sheet_name='Sheet1')
                    constituents_pl = pl.from_pandas(constituents_data)
                    self._cache_constituents(source, constituents_pl)
                else:
                    # å¦‚æœæŒ‡å®šæ•°æ®æºä¸å¯ç”¨ï¼Œå°è¯•å…¶ä»–æ•°æ®æº
                    if self.ths_constituents_file.exists():
                        print(f"ğŸ“Š å›é€€åˆ°åŒèŠ±é¡ºæˆåˆ†è‚¡æ•°æ®: {self.ths_constituents_file}")
                        constituents_data = pd.read_excel(self.ths_constituents_file, sheet_name='æ‰€æœ‰æ•°æ®')
                        constituents_pl = pl.from_pandas(constituents_data)
                        self._cache_constituents("ths", constituents_pl)
                    elif self.dc_constituents_file.exists():
                        print(f"ğŸ“Š å›é€€åˆ°ä¸œè´¢æˆåˆ†è‚¡æ•°æ®: {self.dc_constituents_file}")
                        constituents_data = pd.read_excel(self.dc_constituents_file, sheet_name='Sheet1')
                        constituents_pl = pl.from_pandas(constituents_data)
                        self._cache_constituents("eastmoney", constituents_pl)
                    else:
                        print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°æˆåˆ†è‚¡æ•°æ®æ–‡ä»¶")
                        return None

            # ç­›é€‰æŒ‡å®šæ¿å—çš„æˆåˆ†è‚¡ - ä½¿ç”¨ç´¢å¼•ä¼˜åŒ–
            cache_key = f"constituents_{source}"
            sector_stocks = self._get_stocks_by_sector_fast(cache_key, sector_name, constituents_pl)
            
            # å¦‚æœç´¢å¼•æŸ¥è¯¢å¤±è´¥ï¼Œå›é€€åˆ°ä¼ ç»ŸæŸ¥è¯¢æ–¹æ³•
            if sector_stocks is None or sector_stocks.is_empty():
                print("ğŸ” ç´¢å¼•æŸ¥è¯¢æœªæ‰¾åˆ°ç»“æœï¼Œä½¿ç”¨ä¼ ç»ŸæŸ¥è¯¢æ–¹æ³•")
                sector_stocks = pl.DataFrame()

                if 'æ¿å—åç§°' in constituents_pl.columns:
                    # ç²¾ç¡®åŒ¹é…
                    sector_stocks = constituents_pl.filter(pl.col('æ¿å—åç§°') == sector_name)
                    # å¦‚æœç²¾ç¡®åŒ¹é…å¤±è´¥ï¼Œå°è¯•æ¨¡ç³ŠåŒ¹é…
                    if sector_stocks.is_empty():
                        sector_stocks = constituents_pl.filter(pl.col('æ¿å—åç§°').str.contains(sector_name))

                elif 'æ‰€å±æ¿å—' in constituents_pl.columns:
                    # ç²¾ç¡®åŒ¹é…
                    sector_stocks = constituents_pl.filter(pl.col('æ‰€å±æ¿å—') == sector_name)
                    # å¦‚æœç²¾ç¡®åŒ¹é…å¤±è´¥ï¼Œå°è¯•æ¨¡ç³ŠåŒ¹é…
                    if sector_stocks.is_empty():
                        sector_stocks = constituents_pl.filter(pl.col('æ‰€å±æ¿å—').str.contains(sector_name))
                else:
                    print(f"âŒ æˆåˆ†è‚¡æ•°æ®ä¸­æ²¡æœ‰æ‰¾åˆ°æ¿å—åç§°åˆ—ï¼Œå¯ç”¨åˆ—: {constituents_pl.columns}")
                    return None
            else:
                print("âš¡ ä½¿ç”¨ç´¢å¼•å¿«é€ŸæŸ¥è¯¢æ¿å—æˆåˆ†è‚¡")

            if not sector_stocks.is_empty():
                # ç¡®ä¿è‚¡ç¥¨ä»£ç ä¸º6ä½æ ¼å¼
                sector_stocks = sector_stocks.with_columns([
                    pl.col('è‚¡ç¥¨ä»£ç ').cast(pl.Utf8).str.zfill(6).alias('è‚¡ç¥¨ä»£ç ')
                ])

                # ç»Ÿä¸€åˆ—åï¼Œç¡®ä¿æœ‰æ ‡å‡†çš„åˆ—å
                if 'æ‰€å±æ¿å—' in sector_stocks.columns and 'æ¿å—åç§°' not in sector_stocks.columns:
                    sector_stocks = sector_stocks.rename({'æ‰€å±æ¿å—': 'æ¿å—åç§°'})

                # ç¡®ä¿æœ‰å¿…è¦çš„åˆ—åæ˜ å°„
                if 'è‚¡ç¥¨ä»£ç ' in sector_stocks.columns and 'ä»£ç ' not in sector_stocks.columns:
                    sector_stocks = sector_stocks.with_columns([
                        pl.col('è‚¡ç¥¨ä»£ç ').alias('ä»£ç ')
                    ])

                if 'è‚¡ç¥¨åç§°' in sector_stocks.columns and 'åç§°' not in sector_stocks.columns:
                    sector_stocks = sector_stocks.with_columns([
                        pl.col('è‚¡ç¥¨åç§°').alias('åç§°')
                    ])

                # å»é‡ï¼šæŒ‰æ ‡å‡†åŒ–åçš„ä»£ç å”¯ä¸€
                try:
                    if 'ä»£ç ' in sector_stocks.columns:
                        sector_stocks = sector_stocks.unique(subset=['ä»£ç '], keep='first')
                    elif 'è‚¡ç¥¨ä»£ç ' in sector_stocks.columns:
                        sector_stocks = sector_stocks.unique(subset=['è‚¡ç¥¨ä»£ç '], keep='first')
                except Exception as _e:
                    print(f"âš ï¸ æˆåˆ†è‚¡å»é‡å¤±è´¥(å¿½ç•¥): {_e}")

                return sector_stocks
            else:
                return None

        except Exception as e:
            print(f"âŒ è·å–æ¿å—æˆåˆ†è‚¡å¤±è´¥: {e}")
            return None

    def get_sector_names(self, sector_type: str = 'both') -> dict:
        """
        ç»Ÿä¸€è·å–æ¿å—åç§°çš„æ–¹æ³•

        Args:
            sector_type: 'sectors', 'concepts', 'both'

        Returns:
            dict: åŒ…å«æ¿å—åç§°çš„å­—å…¸
        """
        try:
            result = {}

            if sector_type in ['sectors', 'both']:
                # è·å–è¡Œä¸šæ¿å—åç§°
                try:
                    df = self.load_sector_data(include_sectors=True, include_concepts=False)
                    if not df.is_empty():
                        sector_names = df.filter(pl.col('æ¿å—ç±»å‹') == 'è¡Œä¸š')['æ¿å—åç§°'].unique().to_list()
                        sector_names = sorted(sector_names)
                    else:
                        sector_names = []
                except Exception as e:
                    print(f"âŒ è·å–è¡Œä¸šæ¿å—åç§°å¤±è´¥: {e}")
                    sector_names = []

                result['sector_names'] = sector_names
                result['sector_count'] = len(sector_names)

            if sector_type in ['concepts', 'both']:
                # è·å–æ¦‚å¿µæ¿å—åç§°
                try:
                    df = self.load_sector_data(include_sectors=False, include_concepts=True)
                    if not df.is_empty():
                        concept_names = df.filter(pl.col('æ¿å—ç±»å‹') == 'æ¦‚å¿µ')['æ¿å—åç§°'].unique().to_list()
                        concept_names = sorted(concept_names)
                    else:
                        concept_names = []
                except Exception as e:
                    print(f"âŒ è·å–æ¦‚å¿µæ¿å—åç§°å¤±è´¥: {e}")
                    concept_names = []

                result['concept_names'] = concept_names
                result['concept_count'] = len(concept_names)

            return result

        except Exception as e:
            print(f"âŒ ç»Ÿä¸€è·å–æ¿å—åç§°å¤±è´¥: {e}")
            return {}
