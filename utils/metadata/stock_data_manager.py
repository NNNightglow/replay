#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‚¡ç¥¨å…ƒæ•°æ®ç®¡ç†å™¨

ä¸»æ¿ä½¿ç”¨baostockï¼ŒåŒ—äº¤æ‰€ä½¿ç”¨ak.stock_zh_a_histæ¥å£
"""

import polars as pl
from datetime import datetime, timedelta, date
from pathlib import Path
import os
import time
from typing import Optional, Dict, List, Tuple
import akshare as ak
import pandas as pd
import numpy as np
import baostock as bs
import threading
import tempfile
import shutil
# from akshare.utils.requests_fun import requests_obj

# requests_obj.headers.update({
#     "User-Agent": "Mozilla/5.0 ...",
#     "Referer": "https://quote.eastmoney.com/"
# })
def safe_network_request(func, *args, max_retries=3, timeout_seconds=30, **kwargs):
    """å®‰å…¨çš„ç½‘ç»œè¯·æ±‚åŒ…è£…å™¨ï¼Œå¸¦é‡è¯•æœºåˆ¶"""
    import time
    import random

    for attempt in range(max_retries):
        try:
            result = func(*args, **kwargs)
            return result

        except Exception as e:
            print(f"âš ï¸ ç½‘ç»œè¯·æ±‚å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}")

            if attempt < max_retries - 1:
                # æŒ‡æ•°é€€é¿é‡è¯•
                wait_time = (2 ** attempt) + random.uniform(0, 1)
                print(f"â³ ç­‰å¾… {wait_time:.1f} ç§’åé‡è¯•...")
                time.sleep(wait_time)
            else:
                print(f"âŒ ç½‘ç»œè¯·æ±‚æœ€ç»ˆå¤±è´¥ï¼Œå·²é‡è¯• {max_retries} æ¬¡")

    return None


try:
    import fcntl
except ImportError:
    fcntl = None  # Windows doesn't have fcntl

# å…¨å±€é”ï¼Œé˜²æ­¢å¹¶å‘å†™å…¥
_file_locks = {}
_lock_mutex = threading.Lock()


def safe_write_parquet(df: pl.DataFrame, file_path: str, max_retries: int = 3) -> bool:
    """
    å®‰å…¨å†™å…¥parquetæ–‡ä»¶ï¼Œæ”¯æŒé‡è¯•å’Œæ–‡ä»¶é”
    
    Args:
        df: è¦å†™å…¥çš„DataFrame
        file_path: æ–‡ä»¶è·¯å¾„
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
    
    Returns:
        bool: æ˜¯å¦å†™å…¥æˆåŠŸ
    """
    if df is None or df.is_empty():
        print(f"âš ï¸ DataFrameä¸ºç©ºï¼Œè·³è¿‡å†™å…¥: {file_path}")
        return False
    
    file_path = str(file_path)
    
    for attempt in range(max_retries):
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            
            # ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶å†™å…¥ï¼Œç„¶ååŸå­æ€§ç§»åŠ¨
            temp_file = None
            with tempfile.NamedTemporaryFile(
                mode='wb', 
                delete=False, 
                dir=os.path.dirname(file_path),
                suffix='.tmp'
            ) as temp_file:
                temp_path = temp_file.name
            
            # å†™å…¥ä¸´æ—¶æ–‡ä»¶
            df.write_parquet(temp_path)
            
            # åŸå­æ€§ç§»åŠ¨åˆ°ç›®æ ‡ä½ç½®
            shutil.move(temp_path, file_path)
            
            print(f"âœ… æˆåŠŸå†™å…¥æ–‡ä»¶: {file_path} ({df.height} è¡Œ)")
            return True
            
        except Exception as e:
            print(f"âŒ å†™å…¥æ–‡ä»¶å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}")
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if temp_file and os.path.exists(temp_file.name):
                try:
                    os.unlink(temp_file.name)
                except:
                    pass
            
            if attempt < max_retries - 1:
                time.sleep(1)  # ç­‰å¾…1ç§’åé‡è¯•
            else:
                return False
    
    return False





class StockMetadataManager:
    """è‚¡ç¥¨å…ƒæ•°æ®ç®¡ç†ç±»ï¼Œä¸»æ¿ä½¿ç”¨baostock,åŒ—äº¤æ‰€ä½¿ç”¨ak.stock_zh_a_histæ¥å£"""

    def __init__(self, metadata_path: str = None):
        if metadata_path is None:
            # ä½¿ç”¨é¡¹ç›®æ ¹ç›®å½•çš„data_cache
            self.metadata_path = Path("data_cache/stock_daily")
        else:
            self.metadata_path = Path(metadata_path)

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.metadata_path.mkdir(parents=True, exist_ok=True)

        # è‚¡ç¥¨å…ƒæ•°æ®æ–‡ä»¶è·¯å¾„
        self.stock_metadata_file = self.metadata_path / "stock_daily_metadata.parquet"

        print(f"ğŸ“Š è‚¡ç¥¨å…ƒæ•°æ®ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")

    def load_metadata(self) -> Optional[pl.DataFrame]:
        """åŠ è½½è‚¡ç¥¨å…ƒæ•°æ®"""
        try:
            if self.stock_metadata_file.exists():
                df = pl.read_parquet(self.stock_metadata_file)
                print(f"âœ… æˆåŠŸåŠ è½½è‚¡ç¥¨å…ƒæ•°æ®: {df.height} æ¡è®°å½•")
                return df
            else:
                print(f"âš ï¸ è‚¡ç¥¨å…ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {self.stock_metadata_file}")
                return None
        except Exception as e:
            print(f"âŒ åŠ è½½è‚¡ç¥¨å…ƒæ•°æ®å¤±è´¥: {e}")
            return None

    def is_latest_trading_day(self) -> bool:
        """æ£€æŸ¥è‚¡ç¥¨å…ƒæ•°æ®æ˜¯å¦æ˜¯æœ€æ–°äº¤æ˜“æ—¥çš„æ•°æ®

        é€»è¾‘ï¼š
        1. è·å–ç°æœ‰æ•°æ®çš„æœ€æ–°æ—¥æœŸ
        2. è·å–å½“å‰åº”è¯¥æ›´æ–°åˆ°çš„æœ€æ–°äº¤æ˜“æ—¥æœŸ
        3. åˆ¤æ–­å½“å¤©æ˜¯å¦ä¸ºäº¤æ˜“æ—¥ï¼Œæ˜¯å¦å·²è¿‡18:00
        4. è€ƒè™‘å‘¨æœ«å’ŒèŠ‚å‡æ—¥çš„å½±å“
        """
        try:
            # 1. è·å–ç°æœ‰æ•°æ®çš„æœ€æ–°æ—¥æœŸ
            metadata = self.load_metadata()
            if metadata is None or metadata.is_empty():
                print("è‚¡ç¥¨å…ƒæ•°æ®ä¸ºç©ºï¼Œéœ€è¦æ›´æ–°")
                return False

            if 'æ—¥æœŸ' not in metadata.columns:
                print("è­¦å‘Š: è‚¡ç¥¨å…ƒæ•°æ®ä¸­ç¼ºå°‘æ—¥æœŸåˆ—")
                return False

            # è§£æç°æœ‰æ•°æ®çš„æœ€æ–°æ—¥æœŸ
            latest_date_raw = metadata['æ—¥æœŸ'].max()
            if isinstance(latest_date_raw, str):
                try:
                    latest_local_date = datetime.strptime(latest_date_raw, '%Y-%m-%d').date()
                except ValueError:
                    try:
                        latest_local_date = datetime.strptime(latest_date_raw, '%Y/%m/%d').date()
                    except ValueError:
                        latest_local_date = datetime.strptime(latest_date_raw, '%Y%m%d').date()
            elif isinstance(latest_date_raw, datetime):
                latest_local_date = latest_date_raw.date()
            elif isinstance(latest_date_raw, date):
                latest_local_date = latest_date_raw
            else:
                print(f"âš ï¸ æœªçŸ¥çš„æ—¥æœŸç±»å‹: {type(latest_date_raw)}, å€¼: {latest_date_raw}")
                return False

            # 2. è·å–å½“å‰æ—¶é—´ä¿¡æ¯
            now = datetime.now()
            current_date = now.date()
            current_time = now.time()

            # 3. å®šä¹‰æ•°æ®æ›´æ–°æ—¶é—´ï¼ˆ18:00åè®¤ä¸ºå½“æ—¥æ•°æ®å·²æ›´æ–°ï¼‰
            from datetime import time as dt_time
            update_time = dt_time(18, 0)  # 18:00

            # 4. ä½¿ç”¨holidaysåº“åˆ¤æ–­èŠ‚å‡æ—¥
            def is_holiday(check_date):
                """ä½¿ç”¨holidaysåº“åˆ¤æ–­æ˜¯å¦ä¸ºä¸­å›½èŠ‚å‡æ—¥"""
                try:
                    import holidays
                    # åˆ›å»ºä¸­å›½èŠ‚å‡æ—¥å¯¹è±¡
                    china_holidays = holidays.China(years=check_date.year)
                    return check_date in china_holidays
                except Exception as e:
                    print(f"âš ï¸ èŠ‚å‡æ—¥åˆ¤æ–­å¤±è´¥: {e}")
                    return False

            # 5. åˆ¤æ–­æ˜¯å¦ä¸ºäº¤æ˜“æ—¥ï¼ˆéå‘¨æœ«ä¸”éèŠ‚å‡æ—¥ï¼‰
            def is_trading_day(check_date):
                """åˆ¤æ–­æ˜¯å¦ä¸ºäº¤æ˜“æ—¥"""
                # å‘¨æœ«ä¸æ˜¯äº¤æ˜“æ—¥
                if check_date.weekday() >= 5:  # 5=å‘¨å…­, 6=å‘¨æ—¥
                    return False
                # èŠ‚å‡æ—¥ä¸æ˜¯äº¤æ˜“æ—¥
                if is_holiday(check_date):
                    return False
                return True

            # 6. è·å–å‰ä¸€ä¸ªäº¤æ˜“æ—¥
            def get_previous_trading_day(from_date):
                """è·å–æŒ‡å®šæ—¥æœŸå‰çš„æœ€è¿‘ä¸€ä¸ªäº¤æ˜“æ—¥"""
                check_date = from_date - timedelta(days=1)
                for _ in range(15):  # æœ€å¤šå¾€å‰æ‰¾15å¤©ï¼ˆè€ƒè™‘é•¿å‡æœŸï¼‰
                    if is_trading_day(check_date):
                        return check_date
                    check_date -= timedelta(days=1)
                # å¦‚æœ15å¤©å†…éƒ½æ²¡æ‰¾åˆ°ï¼Œè¿”å›15å¤©å‰çš„æ—¥æœŸ
                return from_date - timedelta(days=15)

            # 7. è·å–æœ€æ–°åº”è¯¥æ›´æ–°åˆ°çš„äº¤æ˜“æ—¥æœŸ
            def get_latest_expected_trading_date():
                """è·å–æœ€æ–°åº”è¯¥æ›´æ–°åˆ°çš„äº¤æ˜“æ—¥æœŸ"""
                if is_trading_day(current_date):
                    # ä»Šå¤©æ˜¯äº¤æ˜“æ—¥
                    if current_time >= update_time:
                        # å·²è¿‡18:00ï¼Œåº”è¯¥æœ‰ä»Šå¤©çš„æ•°æ®
                        return current_date
                    else:
                        # æœªè¿‡18:00ï¼Œåº”è¯¥æœ‰å‰ä¸€ä¸ªäº¤æ˜“æ—¥çš„æ•°æ®
                        return get_previous_trading_day(current_date)
                else:
                    # ä»Šå¤©ä¸æ˜¯äº¤æ˜“æ—¥ï¼Œåº”è¯¥æœ‰æœ€è¿‘ä¸€ä¸ªäº¤æ˜“æ—¥çš„æ•°æ®
                    return get_previous_trading_day(current_date)

            # 8. æ¯”è¾ƒç°æœ‰æ•°æ®çš„æœ€æ–°æ—¥æœŸä¸æœ€æ–°äº¤æ˜“æ—¥ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦æ›´æ–°
            expected_latest_date = get_latest_expected_trading_date()

            print(f"ğŸ“Š ç°æœ‰æ•°æ®æœ€æ–°æ—¥æœŸ: {latest_local_date}")
            print(f"ğŸ“Š æœ€æ–°äº¤æ˜“æ—¥æœŸ: {expected_latest_date}")


            # å¦‚æœç°æœ‰æ•°æ®æ—¥æœŸ >= æœ€æ–°äº¤æ˜“æ—¥æœŸï¼Œåˆ™è®¤ä¸ºæ˜¯æœ€æ–°çš„
            is_latest = latest_local_date >= expected_latest_date

            if is_latest:
                print("âœ… è‚¡ç¥¨å…ƒæ•°æ®å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€æ›´æ–°")
            else:
                print("ğŸ“Š è‚¡ç¥¨å…ƒæ•°æ®éœ€è¦æ›´æ–°")

            return is_latest

        except Exception as e:
            print(f"âŒ æ£€æŸ¥æ˜¯å¦ä¸ºæœ€æ–°äº¤æ˜“æ—¥å¤±è´¥: {e}")
            return False

    def update_metadata(self, start_date: str = None, end_date: str = None, 
                       progress_callback=None) -> bool:
        """æ›´æ–°è‚¡ç¥¨å…ƒæ•°æ®"""
        if progress_callback:
            progress_callback(0, 100, "å¼€å§‹æ›´æ–°è‚¡ç¥¨å…ƒæ•°æ®")
        
        # è·å–ç°æœ‰å…ƒæ•°æ®
        existing_metadata = self.load_metadata()
        
        # ç¡®å®šæ—¥æœŸèŒƒå›´
        if start_date is None or end_date is None:
            latest_date = None
            if existing_metadata is not None and not existing_metadata.is_empty():
                if 'æ—¥æœŸ' in existing_metadata.columns:
                    latest_date = existing_metadata['æ—¥æœŸ'].max()
                    if isinstance(latest_date, str):
                        try:
                            latest_date = datetime.strptime(latest_date, '%Y-%m-%d').date()
                        except Exception:
                            latest_date = None

            if latest_date is None:
                latest_date = (datetime.now() - timedelta(days=30)).date()

            if start_date is None:
                start_date = (latest_date + timedelta(days=1)).strftime('%Y-%m-%d')
            if end_date is None:
                # è®¡ç®—åº”å½“æ›´æ–°åˆ°çš„â€œæœ€æ–°äº¤æ˜“æ—¥â€
                from datetime import time as dt_time
                try:
                    from utils.holiday_utils import china_holiday_util
                except Exception:
                    china_holiday_util = None

                now_dt = datetime.now()
                current_date = now_dt.date()
                update_time = dt_time(18, 0)

                def get_prev_trading_day(d):
                    if china_holiday_util is not None:
                        return china_holiday_util.get_previous_trading_day(d)
                    # å…œåº•ï¼šä»…æ ¹æ®å‘¨æœ«å›é€€
                    check = d - timedelta(days=1)
                    for _ in range(15):
                        if check.weekday() < 5:
                            return check
                        check -= timedelta(days=1)
                    return d - timedelta(days=1)

                def is_trading(d):
                    if china_holiday_util is not None:
                        return china_holiday_util.is_trading_day(d)
                    return d.weekday() < 5

                if is_trading(current_date):
                    if now_dt.time() >= update_time:
                        expected = current_date
                    else:
                        expected = get_prev_trading_day(current_date)
                else:
                    expected = get_prev_trading_day(current_date)

                end_date = expected.strftime('%Y-%m-%d')
        else:
            # å¦‚æœä¼ å…¥çš„end_dateæ˜¯éäº¤æ˜“æ—¥ï¼Œåˆ™å›é€€åˆ°ä¸Šä¸€ä¸ªäº¤æ˜“æ—¥
            try:
                from utils.holiday_utils import china_holiday_util
                end_date_obj = datetime.strptime(end_date, '%Y-%m-%d').date()
                if not china_holiday_util.is_trading_day(end_date_obj):
                    end_date = china_holiday_util.get_previous_trading_day(end_date_obj).strftime('%Y-%m-%d')
            except Exception:
                pass

        # é˜²æ­¢å¼€å§‹æ—¥æœŸæ™šäºç»“æŸæ—¥æœŸ
        try:
            if datetime.strptime(start_date, '%Y-%m-%d') > datetime.strptime(end_date, '%Y-%m-%d'):
                start_date = (datetime.strptime(end_date, '%Y-%m-%d') - timedelta(days=30)).strftime('%Y-%m-%d')
        except Exception:
            pass

        print(start_date, end_date)

        #### ç™»é™†ç³»ç»Ÿ ####
        lg = bs.login()
        print('login respond error_code:'+lg.error_code)
        print('login respond error_msg:'+lg.error_msg)

        #### è·å–æ‰€æœ‰Aè‚¡è‚¡ç¥¨ä»£ç å’Œåç§°ï¼ˆåœ¨éäº¤æ˜“æ—¥è‡ªåŠ¨å›é€€ï¼‰ ####
        max_back_steps = 5
        attempt_end_date = end_date
        stock_rs = None
        for _ in range(max_back_steps):
            rs = bs.query_all_stock(day=attempt_end_date)
            # baostockè‹¥è¿”å›é”™è¯¯ï¼Œç›´æ¥å›é€€åˆ°ä¸Šä¸€ä¸ªäº¤æ˜“æ—¥
            if hasattr(rs, 'error_code') and rs.error_code != '0':
                print(f"è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {getattr(rs, 'error_msg', '')}ï¼Œå›é€€é‡è¯•: {attempt_end_date}")
                try:
                    from utils.holiday_utils import china_holiday_util
                    d = datetime.strptime(attempt_end_date, '%Y-%m-%d').date()
                    attempt_end_date = china_holiday_util.get_previous_trading_day(d).strftime('%Y-%m-%d')
                except Exception:
                    d = datetime.strptime(attempt_end_date, '%Y-%m-%d').date() - timedelta(days=1)
                    attempt_end_date = d.strftime('%Y-%m-%d')
                continue

            stock_rs = rs.get_data()
            # ç¡®ä¿æ˜¯DataFrame
            if not isinstance(stock_rs, pd.DataFrame):
                stock_rs = pd.DataFrame(stock_rs)

            # éç©ºä¸”åŒ…å«codeåˆ—åˆ™è®¤ä¸ºæˆåŠŸ
            if stock_rs is not None and len(stock_rs) > 0 and ('code' in stock_rs.columns):
                break

            print(f"è·å–åˆ°0åªè‚¡ç¥¨æˆ–ç¼ºå°‘codeåˆ—ï¼Œå›é€€åˆ°ä¸Šä¸€ä¸ªäº¤æ˜“æ—¥é‡è¯•: {attempt_end_date}")
            try:
                from utils.holiday_utils import china_holiday_util
                d = datetime.strptime(attempt_end_date, '%Y-%m-%d').date()
                attempt_end_date = china_holiday_util.get_previous_trading_day(d).strftime('%Y-%m-%d')
            except Exception:
                d = datetime.strptime(attempt_end_date, '%Y-%m-%d').date() - timedelta(days=1)
                attempt_end_date = d.strftime('%Y-%m-%d')

        # æ›´æ–°æœ€ç»ˆä½¿ç”¨çš„end_dateä¸ºæœ‰æ•ˆäº¤æ˜“æ—¥
        end_date = attempt_end_date
        if stock_rs is None:
            stock_rs = pd.DataFrame()
        print(f"è·å–åˆ°{len(stock_rs)}åªè‚¡ç¥¨")

        #### ç­›é€‰Aè‚¡è‚¡ç¥¨ï¼ˆæ²ªæ·±ä¸¤å¸‚ï¼‰ ####
        if isinstance(stock_rs, pd.DataFrame) and 'code' in stock_rs.columns:
            a_stocks = stock_rs[stock_rs['code'].astype(str).str.startswith(('sh.6', 'sz.0', 'sz.30'))]
            print(f"ç­›é€‰åAè‚¡æ•°é‡ï¼š{len(a_stocks)}")
        else:
            print("âš ï¸ è‚¡ç¥¨åˆ—è¡¨ç¼ºå¤±codeåˆ—ï¼Œæ— æ³•ç­›é€‰Aè‚¡ï¼Œåç»­ä»…å°è¯•åŒ—äº¤æ‰€æ•°æ®")
            a_stocks = pd.DataFrame(columns=['code', 'code_name'])

        #### è·å–æ‰€æœ‰Aè‚¡å†å²Kçº¿æ•°æ® ####
        all_data = []
        failed_stocks = []
        i=0
        for index, stock in a_stocks.iterrows():
            stock_code = stock['code']
            stock_name = stock['code_name']
            
            try:
                #print(f"æ­£åœ¨è·å– {stock_code} {stock_name} çš„æ•°æ®...")
                
                rs = bs.query_history_k_data_plus(stock_code,
                    "date,code,open,high,low,close,volume,amount,adjustflag,turn,pctChg",
                    start_date=start_date, end_date=end_date,
                    frequency="d", adjustflag="2")
                
                if rs.error_code != '0':
                    print(f"è·å– {stock_code} æ•°æ®å¤±è´¥: {rs.error_msg}")
                    failed_stocks.append((stock_code, stock_name))
                    continue
                    
                # è·å–æ•°æ®
                data_list = []
                while (rs.error_code == '0') & rs.next():
                    data_list.append(rs.get_row_data())
                
                if data_list:
                    temp_df = pd.DataFrame(data_list, columns=rs.fields)
                    # æ·»åŠ è‚¡ç¥¨åç§°åˆ—
                    temp_df['åç§°'] = stock_name
                    all_data.append(temp_df)
                    i+=1
                    if i%100==0:
                        print(f"è·å–åˆ°{i}/{len(stock_rs)}åªè‚¡ç¥¨")
                        # æ·»åŠ å»¶æ—¶ï¼Œé¿å…è¯·æ±‚è¿‡å¿«
                        time.sleep(0.1)
                
            except Exception as e:
                print(f"å¤„ç† {stock_code} {stock_name} æ—¶å‡ºé”™: {str(e)}")
                failed_stocks.append((stock_code, stock_name))
                continue
        
        # è·å–æ‰€æœ‰è‚¡ç¥¨åˆ—è¡¨ï¼ˆè·å–åŒ—äº¤æ‰€è‚¡ç¥¨æ•°æ®ï¼‰
        print('æ­£åœ¨è·å–è‚¡ç¥¨åˆ—è¡¨ä¿¡æ¯...')
        stock_info = safe_network_request(ak.stock_info_a_code_name, max_retries=3, timeout_seconds=60)

        if stock_info is not None and not stock_info.empty:
            print(f'æˆåŠŸè·å–è‚¡ç¥¨åˆ—è¡¨ï¼Œå…± {len(stock_info)} åªè‚¡ç¥¨')
        else:
            print("âš ï¸ è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥ï¼Œè·³è¿‡åŒ—äº¤æ‰€æ•°æ®æ›´æ–°")
            stock_info = pd.DataFrame()

        if not stock_info.empty:
            # è¿‡æ»¤codeä»¥4, 8, 9å¼€å¤´çš„è¡Œ
            filtered_stocks = stock_info[stock_info['code'].str.startswith(('4', '8', '9'))]
            all_stock_data = []
            print(f'æ›´æ–°åŒ—äº¤æ‰€æ•°æ®ï¼Œå…± {len(filtered_stocks)} åªè‚¡ç¥¨')

            for code in filtered_stocks['code']:
                try:
                    df = ak.stock_zh_a_hist(symbol=code, period='daily', start_date=datetime.strptime(start_date, '%Y-%m-%d').strftime('%Y%m%d')
                                            , end_date=datetime.strptime(end_date, '%Y-%m-%d').strftime('%Y%m%d'), adjust="qfq")
                    if not df.empty:
                        all_stock_data.append(df)
                except Exception as e:
                    print(f"è·å–è‚¡ç¥¨ {code} æ•°æ®å¤±è´¥: {e}")
                    continue

            if all_stock_data:
                combined_df = pd.concat(all_stock_data, ignore_index=True)
                combined_df = combined_df.rename(columns={'è‚¡ç¥¨ä»£ç ': 'ä»£ç ',})
                # ç”¨filtered_stocksé‡Œcodeå’Œnameåšmergeï¼Œè¡¥å…¨åç§°å­—æ®µ
                merged_df = combined_df.merge(
                    filtered_stocks[['code', 'name']],
                    how='left',
                    left_on='ä»£ç ',
                    right_on='code'
                )
                # æŠŠåŸåç§°ï¼ˆå‡è®¾æ˜¯ç©ºçš„æˆ–ç¼ºå¤±ï¼‰æ›¿æ¢ä¸ºfiltered_stocksé‡Œçš„name
                merged_df['åç§°'] = merged_df['name']

                # åˆ é™¤å¤šä½™çš„åˆ— 'code' å’Œ 'name'
                merged_df.drop(['code', 'name'], axis=1, inplace=True)

                # è½¬æ¢ä¸ºpolars
                beijiao_pl = pl.from_pandas(merged_df)

                # ä¿å­˜ä¸ºparquet
                #beijiao_pl.write_parquet("åŒ—äº¤æ‰€è‚¡ç¥¨å†å²è¡Œæƒ….parquet")
                print(f'æˆåŠŸå¤„ç†åŒ—äº¤æ‰€æ•°æ®ï¼Œå…± {len(combined_df)} æ¡è®°å½•')
            else:
                print("æ²¡æœ‰è·å–åˆ°åŒ—äº¤æ‰€æ•°æ®")
        else:
            print('è·³è¿‡åŒ—äº¤æ‰€æ•°æ®å¤„ç†ï¼ˆè‚¡ç¥¨åˆ—è¡¨è·å–å¤±è´¥ï¼‰')

        #### åˆå¹¶æ‰€æœ‰æ–°æ•°æ®å¹¶è½¬æ¢ä¸ºPolarsæ ¼å¼ ####
        new_data_pl = None
        if all_data:
            # åˆå¹¶æ‰€æœ‰pandasæ•°æ®
            new_data_pd = pd.concat(all_data, ignore_index=True)
            # åœ¨è½¬æ¢ä¸ºPolarsä¹‹å‰ï¼Œå…ˆå¤„ç†pandas DataFrameä¸­çš„ç©ºå€¼
            if 'volume' in new_data_pd.columns:
                new_data_pd = new_data_pd[(new_data_pd['volume'] != '') & (new_data_pd['volume'].notna())]

            # è½¬æ¢ä¸ºPolars DataFrame
            new_data_pl = pl.from_pandas(new_data_pd)

            # é‡å‘½ååˆ—åå¹¶è°ƒæ•´åˆ—é¡ºåºï¼ŒåŒ¹é…ç°æœ‰parquetæ–‡ä»¶æ ¼å¼
            select_exprs = []
            if 'date' in new_data_pl.columns: select_exprs.append(pl.col("date").alias("æ—¥æœŸ"))
            if 'open' in new_data_pl.columns: select_exprs.append(pl.col("open").cast(pl.Float64).alias("å¼€ç›˜"))
            if 'close' in new_data_pl.columns: select_exprs.append(pl.col("close").cast(pl.Float64).alias("æ”¶ç›˜"))
            if 'high' in new_data_pl.columns: select_exprs.append(pl.col("high").cast(pl.Float64).alias("æœ€é«˜"))
            if 'low' in new_data_pl.columns: select_exprs.append(pl.col("low").cast(pl.Float64).alias("æœ€ä½"))
            if 'volume' in new_data_pl.columns: select_exprs.append(pl.col("volume").cast(pl.Int64).alias("æˆäº¤é‡"))
            if 'amount' in new_data_pl.columns: select_exprs.append(pl.col("amount").cast(pl.Float64).alias("æˆäº¤é¢"))
            if 'turn' in new_data_pl.columns: select_exprs.append(pl.col("turn").cast(pl.Float64).alias("æ¢æ‰‹ç‡"))
            if 'pctChg' in new_data_pl.columns: select_exprs.append(pl.col("pctChg").cast(pl.Float64).alias("æ¶¨è·Œå¹…"))
            if 'åç§°' in new_data_pl.columns: select_exprs.append(pl.col("åç§°"))
            if 'code' in new_data_pl.columns: select_exprs.append(pl.col("code").str.slice(3).alias("ä»£ç "))

            if select_exprs:
                new_data_pl = new_data_pl.select(select_exprs)

            # è®¡ç®—æŒ¯å¹…å’Œæ¶¨è·Œé¢
            if all([c in new_data_pl.columns for c in ["æœ€é«˜", "æœ€ä½", "æ”¶ç›˜", "æ¶¨è·Œå¹…"]]):
                new_data_pl = new_data_pl.with_columns([
                    ((pl.col("æœ€é«˜") - pl.col("æœ€ä½")) / pl.col("æœ€ä½") * 100).round(2).alias("æŒ¯å¹…"),
                    (pl.col("æ”¶ç›˜") * pl.col("æ¶¨è·Œå¹…") / 100).round(2).alias("æ¶¨è·Œé¢")
                ])

            # è½¬æ¢æ—¥æœŸæ ¼å¼ä¸ºDateç±»å‹
            if 'æ—¥æœŸ' in new_data_pl.columns:
                new_data_pl = new_data_pl.with_columns([
                    pl.col("æ—¥æœŸ").str.strptime(pl.Date, format='%Y-%m-%d')
                ])
        else:
            print("æœªè·å–åˆ°ä¸»æ¿æ–°æ•°æ®")

        # ç»Ÿä¸€å¯¹åŒ—äº¤æ‰€æ•°æ®è¿›è¡Œåˆ—å¯¹é½
        # è‹¥æœªæˆåŠŸè·å–åŒ—äº¤æ‰€æ•°æ®ï¼Œåˆ™beijiao_plå¯èƒ½æœªå®šä¹‰
        try:
            beijiao_pl
        except NameError:
            beijiao_pl = None

        # ç»„åˆå¯ç”¨çš„æ•°æ®æº
        frames = []
        base_columns = None
        if existing_metadata is not None and not existing_metadata.is_empty():
            frames.append(existing_metadata)
            base_columns = existing_metadata.columns
        if new_data_pl is not None and not new_data_pl.is_empty():
            if base_columns is None:
                base_columns = new_data_pl.columns
            # å¯¹é½åˆ—
            new_cols = [c for c in base_columns if c in new_data_pl.columns]
            if new_cols:
                frames.append(new_data_pl.select(new_cols))
        if beijiao_pl is not None and not beijiao_pl.is_empty():
            if base_columns is None:
                base_columns = beijiao_pl.columns
            bj_cols = [c for c in base_columns if c in beijiao_pl.columns]
            if bj_cols:
                frames.append(beijiao_pl.select(bj_cols))

        if frames:
            combined = pl.concat(frames, how="vertical")
            if ('æ—¥æœŸ' in combined.columns) and ('ä»£ç ' in combined.columns):
                combined = combined.unique(subset=["æ—¥æœŸ", "ä»£ç "], keep="last")
            print(f"åˆå¹¶åæ€»è®°å½•æ•°ï¼š{len(combined)}")
            combined.write_parquet('data_cache/stock_daily/stock_daily_metadata.parquet')
        else:
            print("æ²¡æœ‰å¯åˆå¹¶çš„æ•°æ®ï¼Œä¿æŒç°æœ‰æ•°æ®ä¸å˜")

        #### ç™»å‡ºç³»ç»Ÿ ####
        bs.logout()
        
        # è‹¥æ‰§è¡Œåˆ°æ­¤å¤„ï¼Œè¯´æ˜æµç¨‹æœªæŠ›å‡ºå¼‚å¸¸ï¼Œè§†ä¸ºæ›´æ–°æˆåŠŸ
        return True