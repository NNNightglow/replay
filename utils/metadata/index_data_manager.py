
import os
from datetime import datetime, date, timedelta, time as dt_time
from pathlib import Path
from typing import Optional, Union, Dict, List, Tuple, Callable
import importlib
import polars as pl
import akshare as ak
import pandas as pd
import baostock as bs

requests_obj = None
try:
    requests_fun_module = importlib.import_module('akshare.utils.requests_fun')
    requests_obj = getattr(requests_fun_module, 'requests_obj', None)
except Exception:
    requests_obj = None

if requests_obj is not None:
    requests_obj.headers.update({
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",
        "Referer": "https://quote.eastmoney.com/",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8",
        "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
        "Connection": "keep-alive"
    })

class IndexMetadataManager:
    """æŒ‡æ•°å…ƒæ•°æ®ç®¡ç†ç±»ï¼ŒåŸºäºak.index_zh_a_histæ¥å£"""
    def __init__(self, metadata_path: str = None):
        if metadata_path is None:
            # ä½¿ç”¨é¡¹ç›®æ ¹ç›®å½•çš„data_cache
            self.metadata_path = Path("data_cache/indices/index_daily_metadata.parquet")
        else:
            self.metadata_path = Path(metadata_path)

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.metadata_path.parent.mkdir(parents=True, exist_ok=True)
        
        # åˆ†é’Ÿæ•°æ®å­˜å‚¨è·¯å¾„ - ç»Ÿä¸€å­˜å‚¨åœ¨ä¸€ä¸ªæ–‡ä»¶ä¸­
        self.minute_metadata_path = Path("data_cache/indices/index_minute_metadata.parquet")

        print(f"ğŸ“Š æŒ‡æ•°å…ƒæ•°æ®ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def load_metadata(self) -> Optional[pl.DataFrame]:
        """åŠ è½½æŒ‡æ•°å…ƒæ•°æ®æ–‡ä»¶"""
        if not os.path.exists(self.metadata_path):
            return None
            
        try:
            return pl.read_parquet(self.metadata_path)
        except Exception as e:
            print(f"è¯»å–æŒ‡æ•°å…ƒæ•°æ®æ–‡ä»¶å¤±è´¥: {str(e)}")
            return None
    
    def is_latest_trading_day(self) -> bool:
        """æ£€æŸ¥æŒ‡æ•°å…ƒæ•°æ®æ˜¯å¦æ˜¯æœ€æ–°äº¤æ˜“æ—¥çš„æ•°æ®

        é€»è¾‘ï¼š
        1. è·å–ç°æœ‰æ•°æ®çš„æœ€æ–°æ—¥æœŸ
        2. è·å–å½“å‰åº”è¯¥æ›´æ–°åˆ°çš„æœ€æ–°äº¤æ˜“æ—¥æœŸ
        3. åˆ¤æ–­å½“å¤©æ˜¯å¦ä¸ºäº¤æ˜“æ—¥ï¼Œæ˜¯å¦å·²è¿‡18:00
        4. è€ƒè™‘å‘¨æœ«å’ŒèŠ‚å‡æ—¥çš„å½±å“
        """
        try:
            # 1. è·å–ç°æœ‰æ•°æ®çš„æœ€æ–°æ—¥æœŸ
            metadata = self.load_metadata()
            if metadata is None or metadata.is_empty():
                print("æŒ‡æ•°å…ƒæ•°æ®ä¸ºç©ºï¼Œéœ€è¦æ›´æ–°")
                return False

            if 'æ—¥æœŸ' not in metadata.columns:
                print("è­¦å‘Š: æŒ‡æ•°å…ƒæ•°æ®ä¸­ç¼ºå°‘æ—¥æœŸåˆ—")
                return False

            # æ£€æŸ¥æ˜¯å¦æœ‰å‡çº¿åˆ—
            ma_cols = ['MA5', 'MA10', 'MA20']
            missing_ma_cols = [col for col in ma_cols if col not in metadata.columns]
            if missing_ma_cols:
                print(f"æŒ‡æ•°å…ƒæ•°æ®ç¼ºå°‘å‡çº¿åˆ—: {missing_ma_cols}ï¼Œéœ€è¦æ›´æ–°")
                return False

            # è§£æç°æœ‰æ•°æ®çš„æœ€æ–°æ—¥æœŸ
            latest_date_raw = metadata['æ—¥æœŸ'].max()
            if isinstance(latest_date_raw, str):
                try:
                    latest_local_date = datetime.strptime(latest_date_raw, '%Y-%m-%d').date()
                except ValueError:
                    try:
                        latest_local_date = datetime.strptime(latest_date_raw, '%Y/%m/%d').date()
                    except ValueError:
                        latest_local_date = datetime.strptime(latest_date_raw, '%Y%m%d').date()
            elif isinstance(latest_date_raw, datetime):
                latest_local_date = latest_date_raw.date()
            elif isinstance(latest_date_raw, date):
                latest_local_date = latest_date_raw
            else:
                print(f"âš ï¸ æœªçŸ¥çš„æ—¥æœŸç±»å‹: {type(latest_date_raw)}, å€¼: {latest_date_raw}")
                return False

            # 2. è·å–å½“å‰æ—¶é—´ä¿¡æ¯
            now = datetime.now()
            current_date = now.date()
            current_time = now.time()

            # 3. å®šä¹‰æ•°æ®æ›´æ–°æ—¶é—´ï¼ˆ18:00åè®¤ä¸ºå½“æ—¥æ•°æ®å·²æ›´æ–°ï¼‰
            from datetime import time as dt_time
            update_time = dt_time(18, 0)  # 18:00

            # 4. ä½¿ç”¨holidaysåº“åˆ¤æ–­èŠ‚å‡æ—¥
            def is_holiday(check_date):
                """ä½¿ç”¨holidaysåº“åˆ¤æ–­æ˜¯å¦ä¸ºä¸­å›½èŠ‚å‡æ—¥"""
                try:
                    import holidays
                    # åˆ›å»ºä¸­å›½èŠ‚å‡æ—¥å¯¹è±¡
                    china_holidays = holidays.China(years=check_date.year)
                    return check_date in china_holidays
                except Exception as e:
                    print(f"âš ï¸ èŠ‚å‡æ—¥åˆ¤æ–­å¤±è´¥: {e}")
                    return False

            # 5. åˆ¤æ–­æ˜¯å¦ä¸ºäº¤æ˜“æ—¥ï¼ˆéå‘¨æœ«ä¸”éèŠ‚å‡æ—¥ï¼‰
            def is_trading_day(check_date):
                """åˆ¤æ–­æ˜¯å¦ä¸ºäº¤æ˜“æ—¥"""
                # å‘¨æœ«ä¸æ˜¯äº¤æ˜“æ—¥
                if check_date.weekday() >= 5:  # 5=å‘¨å…­, 6=å‘¨æ—¥
                    return False
                # èŠ‚å‡æ—¥ä¸æ˜¯äº¤æ˜“æ—¥
                if is_holiday(check_date):
                    return False
                return True

            # 6. è·å–å‰ä¸€ä¸ªäº¤æ˜“æ—¥
            def get_previous_trading_day(from_date):
                """è·å–æŒ‡å®šæ—¥æœŸå‰çš„æœ€è¿‘ä¸€ä¸ªäº¤æ˜“æ—¥"""
                check_date = from_date - timedelta(days=1)
                for _ in range(15):  # æœ€å¤šå¾€å‰æ‰¾15å¤©ï¼ˆè€ƒè™‘é•¿å‡æœŸï¼‰
                    if is_trading_day(check_date):
                        return check_date
                    check_date -= timedelta(days=1)
                # å¦‚æœ15å¤©å†…éƒ½æ²¡æ‰¾åˆ°ï¼Œè¿”å›15å¤©å‰çš„æ—¥æœŸ
                return from_date - timedelta(days=15)

            # 7. è·å–æœ€æ–°åº”è¯¥æ›´æ–°åˆ°çš„äº¤æ˜“æ—¥æœŸ
            def get_latest_expected_trading_date():
                """è·å–æœ€æ–°åº”è¯¥æ›´æ–°åˆ°çš„äº¤æ˜“æ—¥æœŸ"""
                if is_trading_day(current_date):
                    # ä»Šå¤©æ˜¯äº¤æ˜“æ—¥
                    if current_time >= update_time:
                        # å·²è¿‡18:00ï¼Œåº”è¯¥æœ‰ä»Šå¤©çš„æ•°æ®
                        return current_date
                    else:
                        # æœªè¿‡18:00ï¼Œåº”è¯¥æœ‰å‰ä¸€ä¸ªäº¤æ˜“æ—¥çš„æ•°æ®
                        return get_previous_trading_day(current_date)
                else:
                    # ä»Šå¤©ä¸æ˜¯äº¤æ˜“æ—¥ï¼Œåº”è¯¥æœ‰æœ€è¿‘ä¸€ä¸ªäº¤æ˜“æ—¥çš„æ•°æ®
                    return get_previous_trading_day(current_date)

            # 8. æ¯”è¾ƒç°æœ‰æ•°æ®çš„æœ€æ–°æ—¥æœŸä¸æœ€æ–°äº¤æ˜“æ—¥ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦æ›´æ–°
            expected_latest_date = get_latest_expected_trading_date()

            print(f"ğŸ“Š ç°æœ‰æ•°æ®æœ€æ–°æ—¥æœŸ: {latest_local_date}")
            print(f"ğŸ“Š æœ€æ–°äº¤æ˜“æ—¥æœŸ: {expected_latest_date}")

            # å¦‚æœç°æœ‰æ•°æ®æ—¥æœŸ >= æœ€æ–°äº¤æ˜“æ—¥æœŸï¼Œåˆ™è®¤ä¸ºæ˜¯æœ€æ–°çš„
            is_latest = latest_local_date >= expected_latest_date

            if is_latest:
                print("âœ… æŒ‡æ•°å…ƒæ•°æ®å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€æ›´æ–°")
            else:
                print("ğŸ“Š æŒ‡æ•°å…ƒæ•°æ®éœ€è¦æ›´æ–°")

            return is_latest

        except Exception as e:
            print(f"âŒ æ£€æŸ¥æ˜¯å¦ä¸ºæœ€æ–°äº¤æ˜“æ—¥å¤±è´¥: {e}")
            return False

    def update_metadata(self,  start_date=None, end_date=None, progress_callback=None) -> bool:
        """æ›´æ–°æŒ‡æ•°å…ƒæ•°æ®

        Args:
            start_date: å¼€å§‹æ—¥æœŸï¼Œé»˜è®¤ä¸ºNoneæ—¶ä½¿ç”¨æœ€è¿‘ä¸€æ¬¡æ›´æ–°åçš„æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸï¼Œé»˜è®¤ä¸ºNoneæ—¶ä½¿ç”¨å½“å‰æ—¥æœŸ
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°

        Returns:
            æ›´æ–°æ˜¯å¦æˆåŠŸ
        """
        try:
            if progress_callback:
                progress_callback(0, 100, "å¼€å§‹æ›´æ–°æŒ‡æ•°å…ƒæ•°æ®")
            
            # é»˜è®¤æŒ‡æ•°åˆ—è¡¨
            index_list = [
                {'code': '000001', 'name': 'ä¸Šè¯æŒ‡æ•°'},
                {'code': '399001', 'name': 'æ·±è¯æˆæŒ‡'},
                {'code': '399006', 'name': 'åˆ›ä¸šæ¿æŒ‡'},
                {'code': '000016', 'name': 'ä¸Šè¯50'},
                {'code': '000300', 'name': 'æ²ªæ·±300'},
                {'code': '000905', 'name': 'ä¸­è¯500'},
                {'code': '000852', 'name': 'ä¸­è¯1000'},
                {'code': '000688', 'name': 'ç§‘åˆ›50'},
                {'code': '932000', 'name': 'ä¸­è¯2000'},
                {'code': '899050', 'name': 'åŒ—è¯50'},
                {'code': '800007', 'name': 'å¾®ç›˜è‚¡'}
            ]
            
            # è·å–ç°æœ‰å…ƒæ•°æ®
            existing_metadata = self.load_metadata()
            
            # ç¡®å®šæ—¥æœŸèŒƒå›´
            # å°è¯•ä»ç°æœ‰å…ƒæ•°æ®ä¸­è·å–æœ€å¤§æ—¥æœŸ
            metadata_latest_date = None
            if existing_metadata is not None and not existing_metadata.is_empty():
                if 'æ—¥æœŸ' in existing_metadata.columns:
                    metadata_latest_date = existing_metadata['æ—¥æœŸ'].max()
                    print(f"ä»ç°æœ‰æŒ‡æ•°å…ƒæ•°æ®ä¸­è·å–åˆ°çš„æœ€å¤§æ—¥æœŸ: {metadata_latest_date}")
            
                
            if start_date is None and metadata_latest_date is not None:
                # å°†å¼€å§‹æ—¥æœŸè®¾ç½®ä¸ºæœ€å¤§æ—¥æœŸçš„ä¸‹ä¸€å¤©
                if isinstance(metadata_latest_date, str):
                    latest_date_obj = datetime.strptime(metadata_latest_date, '%Y-%m-%d')
                else:
                    latest_date_obj = metadata_latest_date
                start_date = (latest_date_obj + timedelta(days=1)).strftime('%Y%m%d')
                print(f"è®¾ç½®å¼€å§‹æ—¥æœŸä¸º: {start_date}")
                
            if end_date is None:
                end_date = datetime.now().strftime('%Y%m%d')

            # å…ˆè½¬ä¸ºdatetimeå¯¹è±¡
            end_date_dt = datetime.strptime(end_date, '%Y%m%d')
            start_date = (end_date_dt - timedelta(days=30)).strftime('%Y%m%d')
            print(start_date,end_date)
            all_index_data = []
            total_indices = len(index_list)
            
            for i, index_info in enumerate(index_list):
                try:
                    if progress_callback:
                        progress_callback(
                            10 + int(80 * i / total_indices),
                            100,
                            f"è·å–æŒ‡æ•° {index_info['name']} æ•°æ® ({i+1}/{total_indices})"
                        )

                    df_pl = self._fetch_index_with_fallback(index_info, start_date, end_date)
                    if df_pl is not None and not df_pl.is_empty():
                        all_index_data.append(df_pl)
                    else:
                        print(f"âš ï¸ æ— æ³•è·å–æŒ‡æ•° {index_info['name']} çš„æœ‰æ•ˆæ•°æ®")

                except Exception as e:
                    print(f"è·å–æŒ‡æ•° {index_info['name']} æ•°æ®å¤±è´¥: {str(e)}")
                    continue
            
            if not all_index_data:
                return False


            # åˆå¹¶æ–°æ•°æ®
            new_index_data = pl.concat(all_index_data,how="vertical")

            # ä¸ºæ–°æ•°æ®è®¡ç®—å‡çº¿
            print("ä¸ºæ–°è·å–çš„æŒ‡æ•°æ•°æ®è®¡ç®—å‡çº¿...")
            new_index_data = self._calculate_index_ma(new_index_data)

            # åˆå¹¶æ–°æ—§æ•°æ®
            if existing_metadata is not None and not existing_metadata.is_empty():
                # ç¡®ä¿ç°æœ‰æ•°æ®ä¹Ÿæœ‰å‡çº¿åˆ—ï¼Œå¦‚æœæ²¡æœ‰åˆ™è®¡ç®—
                existing_cols = existing_metadata.columns
                ma_cols = ['MA5', 'MA10', 'MA20', '5æ—¥æ¶¨è·Œå¹…', '10æ—¥æ¶¨è·Œå¹…', '20æ—¥æ¶¨è·Œå¹…']
                missing_ma_cols = [col for col in ma_cols if col not in existing_cols]

                if missing_ma_cols:
                    print(f"ç°æœ‰æ•°æ®ç¼ºå°‘å‡çº¿åˆ—: {missing_ma_cols}ï¼Œé‡æ–°è®¡ç®—...")
                    existing_metadata = self._calculate_index_ma(existing_metadata)

                # å¤„ç†åˆ—é¡ºåºä¸åŒ¹é…é—®é¢˜
                existing_cols = existing_metadata.columns
                new_cols = new_index_data.columns

                # æ‰¾å‡ºå…±åŒçš„åˆ—
                common_cols = [col for col in existing_cols if col in new_cols]

                if common_cols:
                    # æŒ‰ç…§åŸæ¥çš„åˆ—é¡ºåºè¿›è¡Œé€‰æ‹©
                    existing_subset = existing_metadata.select(common_cols)
                    new_subset = new_index_data.select(common_cols)
                    updated_metadata = pl.concat([existing_subset, new_subset], how="vertical")
                else:
                    # å¦‚æœæ²¡æœ‰å…±åŒåˆ—ï¼Œç›´æ¥ä½¿ç”¨æ–°æ•°æ®
                    updated_metadata = new_index_data
            else:
                updated_metadata = new_index_data
            updated_metadata = updated_metadata.unique(subset=['æ—¥æœŸ', 'ä»£ç '])

            # ä¿å­˜æ•°æ®
            updated_metadata.write_parquet(self.metadata_path)
            
            # æ›´æ–°åˆ†é’Ÿæ•°æ®ï¼ˆæ ¹æ®æ—¶é—´é€‰æ‹©åº”æ›´æ–°çš„ç›®æ ‡äº¤æ˜“æ—¥ï¼Œé¿å…æœªå¼€ç›˜æ—¶ä½¿ç”¨æœªæ¥æ—¥æœŸï¼‰
            if end_date:
                try:
                    if progress_callback:
                        progress_callback(95, 100, "æ›´æ–°åˆ†é’Ÿæ•°æ®...")
                    
                    # è®¡ç®—åˆ†é’Ÿæ•°æ®ç›®æ ‡æ—¥æœŸï¼š
                    # - éäº¤æ˜“æ—¥ï¼šä½¿ç”¨æœ€è¿‘ä¸€ä¸ªäº¤æ˜“æ—¥
                    # - äº¤æ˜“æ—¥æœªå¼€ç›˜ï¼ˆ<09:30ï¼‰ï¼šä½¿ç”¨å‰ä¸€äº¤æ˜“æ—¥
                    # - å…¶å®ƒæ—¶é—´ï¼šä½¿ç”¨å½“æ—¥
                    now = datetime.now()
                    current_date = now.date()
                    current_time = now.time()

                    def is_holiday(check_date):
                        try:
                            import holidays
                            china_holidays = holidays.China(years=check_date.year)
                            return check_date in china_holidays
                        except Exception:
                            return False

                    def is_trading_day(check_date):
                        if check_date.weekday() >= 5:
                            return False
                        if is_holiday(check_date):
                            return False
                        return True

                    def get_previous_trading_day(from_date):
                        d = from_date - timedelta(days=1)
                        for _ in range(15):
                            if is_trading_day(d):
                                return d
                            d -= timedelta(days=1)
                        return from_date - timedelta(days=1)

                    if not is_trading_day(current_date):
                        minute_target_date = get_previous_trading_day(current_date)
                    elif current_time < dt_time(9, 30):
                        minute_target_date = get_previous_trading_day(current_date)
                    else:
                        minute_target_date = current_date

                    end_date_formatted = minute_target_date.strftime('%Y-%m-%d')

                    print(f"ğŸ“Š å¼€å§‹æ›´æ–° {end_date_formatted} çš„åˆ†é’Ÿæ•°æ®...")
                    minute_data = self._fetch_and_cache_market_minute_data_akshare(end_date_formatted)
                    if minute_data is not None:
                        print(f"âœ… {end_date_formatted} åˆ†é’Ÿæ•°æ®æ›´æ–°æˆåŠŸï¼Œå·²ä¿å­˜åˆ° {self.minute_metadata_path}")
                    else:
                        print(f"âš ï¸ {end_date_formatted} åˆ†é’Ÿæ•°æ®æ›´æ–°å¤±è´¥")
                        # è‹¥å½“æ—¥æœªèƒ½è·å–ï¼Œåˆ™å›é€€åˆ°å‰ä¸€äº¤æ˜“æ—¥å†å°è¯•ä¸€æ¬¡
                        prev_trade = get_previous_trading_day(minute_target_date)
                        prev_str = prev_trade.strftime('%Y-%m-%d')
                        print(f"ğŸ” å›é€€å°è¯•æ›´æ–°å‰ä¸€äº¤æ˜“æ—¥ {prev_str} çš„åˆ†é’Ÿæ•°æ®...")
                        minute_data_prev = self._fetch_and_cache_market_minute_data_akshare(prev_str)
                        if minute_data_prev is not None:
                            print(f"âœ… å‰ä¸€äº¤æ˜“æ—¥ {prev_str} åˆ†é’Ÿæ•°æ®æ›´æ–°æˆåŠŸ")
                        else:
                            print(f"âš ï¸ å‰ä¸€äº¤æ˜“æ—¥ {prev_str} åˆ†é’Ÿæ•°æ®ä¹Ÿä¸å¯ç”¨")
                        
                except Exception as e:
                    print(f"âš ï¸ æ›´æ–°åˆ†é’Ÿæ•°æ®æ—¶å‡ºé”™: {e}")
                
            if progress_callback:
                progress_callback(100, 100, "æŒ‡æ•°å…ƒæ•°æ®æ›´æ–°å®Œæˆ")

            return True
            
        except Exception as e:
            print(f"æ›´æ–°æŒ‡æ•°å…ƒæ•°æ®å¤±è´¥: {str(e)}")
            return False
    
    def _fetch_index_with_fallback(self, index_info: Dict[str, str], start_date: str, end_date: str) -> Optional[pl.DataFrame]:
        """è·å–æŒ‡æ•°æ•°æ®ï¼ŒåŒ…å«å¤šæ•°æ®æºé™çº§ç­–ç•¥"""

        fetch_strategies: List[Tuple[str, Callable[[Dict[str, str], str, str], Optional[pd.DataFrame]]]] = [
            ("baostock", self._fetch_index_via_baostock),
            ("ak.index_zh_a_hist", self._fetch_index_via_akshare_hist)
        ]

        for source_name, fetcher in fetch_strategies:
            try:
                df = fetcher(index_info, start_date, end_date)
                if df is not None and not df.empty:
                    standardized = self._standardize_index_dataframe(df, index_info)
                    if standardized is not None and not standardized.is_empty():
                        print(f"âœ… ä½¿ç”¨ {source_name} è·å–æŒ‡æ•° {index_info['name']} æ•°æ®æˆåŠŸ")
                        return standardized
            except Exception as fetch_error:
                print(f"âš ï¸ ä½¿ç”¨ {source_name} è·å–æŒ‡æ•° {index_info['name']} æ•°æ®å¤±è´¥: {fetch_error}")

        return None

    def _fetch_index_via_baostock(self, index_info: Dict[str, str], start_date: str, end_date: str) -> Optional[pd.DataFrame]:
        """ä½¿ç”¨baostockè·å–æŒ‡æ•°æ—¥çº¿æ•°æ®"""
        try:
            # ç™»å½•baostock
            lg = bs.login()
            if lg.error_code != '0':
                print(f"âš ï¸ baostockç™»å½•å¤±è´¥: {lg.error_msg}")
                return None
            
            # æ„å»ºbaostockæŒ‡æ•°ä»£ç æ ¼å¼ï¼šsh.000001 æˆ– sz.399001
            code = index_info['code'].zfill(6)
            if code.startswith('000') or code.startswith('001'):
                bs_code = f"sh.{code}"
            elif code.startswith('399'):
                bs_code = f"sz.{code}"
            elif code.startswith('932') or code.startswith('899') or code.startswith('800'):
                # ä¸­è¯ç³»åˆ—æŒ‡æ•°ä½¿ç”¨shå‰ç¼€
                bs_code = f"sh.{code}"
            else:
                bs_code = f"sh.{code}"
            
            # è½¬æ¢æ—¥æœŸæ ¼å¼ï¼šYYYYMMDD -> YYYY-MM-DD
            start_date_formatted = self._format_date_for_baostock(start_date)
            end_date_formatted = self._format_date_for_baostock(end_date)
            
            # æŸ¥è¯¢æŒ‡æ•°Kçº¿æ•°æ®
            rs = bs.query_history_k_data_plus(
                bs_code,
                "date,code,open,high,low,close,preclose,volume,amount,pctChg",
                start_date=start_date_formatted,
                end_date=end_date_formatted,
                frequency="d"
            )
            
            if rs.error_code != '0':
                bs.logout()
                return None
            
            # è·å–æ•°æ®
            data_list = []
            while (rs.error_code == '0') and rs.next():
                data_list.append(rs.get_row_data())
            
            # ç™»å‡º
            bs.logout()
            
            if not data_list:
                return None
            
            # è½¬æ¢ä¸ºDataFrame
            df = pd.DataFrame(data_list, columns=rs.fields)
            
            # æ•°æ®ç±»å‹è½¬æ¢
            numeric_cols = ['open', 'high', 'low', 'close', 'preclose', 'volume', 'amount', 'pctChg']
            for col in numeric_cols:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce')
            
            df['date'] = pd.to_datetime(df['date'])
            
            return df
            
        except Exception as e:
            try:
                bs.logout()
            except:
                pass
            raise e
    
    @staticmethod
    def _format_date_for_baostock(date_str: str) -> str:
        """å°†æ—¥æœŸæ ¼å¼è½¬æ¢ä¸ºbaostockè¦æ±‚çš„æ ¼å¼ YYYY-MM-DD"""
        if not date_str:
            return datetime.now().strftime('%Y-%m-%d')
        
        # å¦‚æœæ˜¯YYYYMMDDæ ¼å¼ï¼Œè½¬æ¢ä¸ºYYYY-MM-DD
        if len(date_str) == 8 and date_str.isdigit():
            return f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}"
        
        # å¦‚æœå·²ç»æ˜¯YYYY-MM-DDæ ¼å¼ï¼Œç›´æ¥è¿”å›
        if len(date_str) == 10 and '-' in date_str:
            return date_str
        
        return date_str

    def _fetch_index_via_akshare_hist(self, index_info: Dict[str, str], start_date: str, end_date: str):
        return ak.index_zh_a_hist(
            symbol=index_info['code'],
            period="daily",
            start_date=start_date,
            end_date=end_date,
        )

    def _fetch_index_via_tencent(self, index_info: Dict[str, str], start_date: str, end_date: str):
        symbol = self._build_exchange_symbol(index_info['code'])
        df = ak.stock_zh_index_daily_tx(symbol=symbol)
        if df is None or df.empty:
            return df

        df = df.copy()
        df['date'] = pd.to_datetime(df['date'])
        start_dt = self._safe_parse_date(start_date, default=df['date'].min())
        end_dt = self._safe_parse_date(end_date, default=df['date'].max())
        mask = (df['date'] >= start_dt) & (df['date'] <= end_dt)
        return df.loc[mask]

    def _fetch_index_via_sina(self, index_info: Dict[str, str], start_date: str, end_date: str):
        symbol = self._build_exchange_symbol(index_info['code'])
        df = ak.stock_zh_index_daily(symbol=symbol)
        if df is None or df.empty:
            return df

        df = df.copy()
        df['date'] = pd.to_datetime(df['date'])
        start_dt = self._safe_parse_date(start_date, default=df['date'].min())
        end_dt = self._safe_parse_date(end_date, default=df['date'].max())
        mask = (df['date'] >= start_dt) & (df['date'] <= end_dt)
        return df.loc[mask]

    def _fetch_index_minute_with_fallback(self, code: str, start_dt: str, end_dt: str, period: str = "5") -> pd.DataFrame:
        strategies: List[Tuple[str, Callable[[], Optional[pd.DataFrame]]]] = [
            (
                "ak.index_zh_a_hist_min_em",
                lambda: ak.index_zh_a_hist_min_em(symbol=code, period=period, start_date=start_dt, end_date=end_dt)
            ),
            (
                "ak.stock_zh_index_minute",
                lambda: self._fetch_index_minute_tencent(code, period, start_dt, end_dt)
            )
        ]

        for source_name, fetcher in strategies:
            try:
                df = fetcher()
                if df is not None and not df.empty:
                    print(f"âœ… ä½¿ç”¨ {source_name} è·å– {code} {period}åˆ†é’Ÿæ•°æ®æˆåŠŸ")
                    return df
            except Exception as fetch_error:
                print(f"âš ï¸ ä½¿ç”¨ {source_name} è·å– {code} {period}åˆ†é’Ÿæ•°æ®å¤±è´¥: {fetch_error}")

        return pd.DataFrame()

    def _fetch_index_minute_tencent(self, code: str, period: str, start_dt: str, end_dt: str) -> Optional[pd.DataFrame]:
        symbol = self._build_exchange_symbol(code)
        df = ak.stock_zh_index_minute(symbol=symbol, period=period)
        if df is None or df.empty:
            return df

        df = df.copy()

        if 'day' in df.columns:
            df['æ—¶é—´'] = pd.to_datetime(df['day'])
        elif 'æ—¶é—´' in df.columns:
            df['æ—¶é—´'] = pd.to_datetime(df['æ—¶é—´'])
        else:
            return df

        start_dt_obj = self._safe_parse_datetime(start_dt, default=df['æ—¶é—´'].min())
        end_dt_obj = self._safe_parse_datetime(end_dt, default=df['æ—¶é—´'].max())
        df = df[(df['æ—¶é—´'] >= start_dt_obj) & (df['æ—¶é—´'] <= end_dt_obj)]

        if df.empty:
            return df

        if 'amount' in df.columns:
            df['æˆäº¤é¢'] = pd.to_numeric(df['amount'], errors='coerce') * 10000  # amountå•ä½ä¸ºä¸‡å…ƒ
        elif 'æˆäº¤é¢' in df.columns:
            df['æˆäº¤é¢'] = pd.to_numeric(df['æˆäº¤é¢'], errors='coerce')
        else:
            close_series = pd.to_numeric(df.get('close', df.get('æ”¶ç›˜', 0)), errors='coerce')
            volume_series = pd.to_numeric(df.get('volume', df.get('æˆäº¤é‡', 0)), errors='coerce')
            df['æˆäº¤é¢'] = close_series * volume_series

        df = df[['æ—¶é—´', 'æˆäº¤é¢']].dropna()
        return df

    @staticmethod
    def _safe_parse_date(date_str: Optional[str], default: datetime) -> datetime:
        if not date_str:
            return default
        if len(date_str) == 8 and date_str.isdigit():
            return datetime.strptime(date_str, '%Y%m%d')
        if len(date_str) == 10 and '-' in date_str:
            return datetime.strptime(date_str, '%Y-%m-%d')
        return default

    @staticmethod
    def _safe_parse_datetime(date_time_str: Optional[str], default: datetime) -> datetime:
        if not date_time_str:
            return default
        try:
            return datetime.strptime(date_time_str, '%Y-%m-%d %H:%M:%S')
        except ValueError:
            try:
                return datetime.strptime(date_time_str, '%Y/%m/%d %H:%M:%S')
            except ValueError:
                return default

    @staticmethod
    def _build_exchange_symbol(code: str) -> str:
        code = code.zfill(6)
        if code.startswith('000') or code.startswith('001'):
            return f"sh{code}"
        elif code.startswith('399'):
            return f"sz{code}"
        elif code.startswith('932') or code.startswith('899'):
            # åŒ—äº¤æ‰€ä¸ä¸­è¯éƒ¨åˆ†æŒ‡æ•°åœ¨è…¾è®¯æ¥å£ä½¿ç”¨ sh å‰ç¼€
            return f"sh{code}"
        else:
            return f"sh{code}"

    def _standardize_index_dataframe(self, df: pd.DataFrame, index_info: Dict[str, str]) -> Optional[pl.DataFrame]:
        if df is None or df.empty:
            return None

        df_copy = df.copy()

        column_mapping = {
            'æ—¥æœŸ': 'æ—¥æœŸ',
            'date': 'æ—¥æœŸ',
            'day': 'æ—¥æœŸ',
            'å¼€ç›˜ä»·': 'å¼€ç›˜',
            'open': 'å¼€ç›˜',
            'æ”¶ç›˜ä»·': 'æ”¶ç›˜',
            'close': 'æ”¶ç›˜',
            'æœ€é«˜ä»·': 'æœ€é«˜',
            'high': 'æœ€é«˜',
            'æœ€ä½ä»·': 'æœ€ä½',
            'low': 'æœ€ä½',
            'æˆäº¤é‡': 'æˆäº¤é‡',
            'volume': 'æˆäº¤é‡',
            'æˆäº¤é¢': 'æˆäº¤é¢',
            'amount': 'æˆäº¤é¢'
        }

        df_copy = df_copy.rename(columns={k: v for k, v in column_mapping.items() if k in df_copy.columns})

        # æ—¥æœŸåˆ—ç»Ÿä¸€ä¸ºæ—¥æœŸç±»å‹
        if 'æ—¥æœŸ' in df_copy.columns:
            df_copy['æ—¥æœŸ'] = pd.to_datetime(df_copy['æ—¥æœŸ']).dt.date
        else:
            return None

        # æŒ‰æ—¥æœŸæ’åº
        df_copy = df_copy.sort_values('æ—¥æœŸ')

        df_pl = pl.from_pandas(df_copy)

        # æ·»åŠ æŒ‡æ•°ä»£ç ã€åç§°ã€äº¤æ˜“æ‰€
        df_pl = df_pl.with_columns([
            pl.lit(index_info['code']).cast(pl.Utf8).str.zfill(6).alias('ä»£ç '),
            pl.lit(index_info['name']).alias('åç§°'),
            pl.lit(self._infer_exchange(index_info['code'])).alias('äº¤æ˜“æ‰€')
        ])

        # ç¡®ä¿æ—¥æœŸåˆ—æ˜¯Dateç±»å‹
        if 'æ—¥æœŸ' in df_pl.columns and df_pl['æ—¥æœŸ'].dtype != pl.Date:
            df_pl = df_pl.with_columns([
                pl.col('æ—¥æœŸ').cast(pl.Date).alias('æ—¥æœŸ')
            ])

        return df_pl

    @staticmethod
    def _infer_exchange(code: str) -> str:
        if code.startswith('399'):
            return 'sz'
        return 'sh'

    def get_index_data(self, code: str, start_date: str = None, 
                      end_date: str = None) -> Optional[pl.DataFrame]:
        """è·å–æŒ‡å®šæŒ‡æ•°çš„æ•°æ®"""
        metadata = self.load_metadata()
        if metadata is None or metadata.is_empty():
            return None
            
        # ç­›é€‰æŒ‡å®šä»£ç çš„æ•°æ®
        index_data = metadata.filter(pl.col('ä»£ç ') == code)
        
        # ç¡®ä¿æ—¥æœŸåˆ—æ˜¯dateç±»å‹
        if 'æ—¥æœŸ' in index_data.columns and index_data['æ—¥æœŸ'].dtype == pl.Utf8:
            index_data = index_data.with_columns([
                pl.col('æ—¥æœŸ').str.strptime(pl.Date, '%Y-%m-%d').alias('æ—¥æœŸ')
            ])
        
        # ç¡®ä¿æœ‰äº¤æ˜“æ‰€åˆ—
        if 'äº¤æ˜“æ‰€' not in index_data.columns and 'ä»£ç ' in index_data.columns:
            index_data = index_data.with_columns([
                pl.col('ä»£ç ').str.slice(0, 2).alias('äº¤æ˜“æ‰€')
            ])
        
        # ç­›é€‰æ—¥æœŸèŒƒå›´æ—¶ä½¿ç”¨pl.lit()
        if start_date:
            start_date_obj = datetime.strptime(start_date, '%Y%m%d' if len(start_date) == 8 else '%Y-%m-%d').date()
            index_data = index_data.filter(pl.col('æ—¥æœŸ') >= pl.lit(start_date_obj))
        
        if end_date:
            end_date_obj = datetime.strptime(end_date, '%Y%m%d' if len(end_date) == 8 else '%Y-%m-%d').date()
            index_data = index_data.filter(pl.col('æ—¥æœŸ') <= pl.lit(end_date_obj))
        
        return index_data if not index_data.is_empty() else None

    def _calculate_index_ma(self, df: pl.DataFrame) -> pl.DataFrame:
        """ä¸ºæŒ‡æ•°æ•°æ®è®¡ç®—MA5ã€MA10ã€MA20å‡çº¿"""
        if df is None or df.is_empty():
            return df

        # ç¡®ä¿æ•°æ®æŒ‰æŒ‡æ•°åç§°å’Œæ—¥æœŸæ’åº
        df_sorted = df.sort(['åç§°', 'æ—¥æœŸ'])

        # è®¡ç®—æ¶¨è·Œå¹…ï¼ˆåŸºäºæ”¶ç›˜ä»·ï¼‰
        df_with_changes = df_sorted.with_columns([
            # 5æ—¥æ¶¨è·Œå¹…
            ((pl.col('æ”¶ç›˜') / pl.col('æ”¶ç›˜').shift(5).over('åç§°') - 1) * 100)
            .round(2)
            .alias('5æ—¥æ¶¨è·Œå¹…'),

            # 10æ—¥æ¶¨è·Œå¹…
            ((pl.col('æ”¶ç›˜') / pl.col('æ”¶ç›˜').shift(10).over('åç§°') - 1) * 100)
            .round(2)
            .alias('10æ—¥æ¶¨è·Œå¹…'),

            # 20æ—¥æ¶¨è·Œå¹…
            ((pl.col('æ”¶ç›˜') / pl.col('æ”¶ç›˜').shift(20).over('åç§°') - 1) * 100)
            .round(2)
            .alias('20æ—¥æ¶¨è·Œå¹…')
        ])

        # è®¡ç®—ç§»åŠ¨å‡çº¿
        df_with_ma = df_with_changes.with_columns([
            # 5æ—¥å‡çº¿
            pl.col('æ”¶ç›˜')
            .rolling_mean(window_size=5, min_periods=1)
            .over('åç§°')
            .round(2)
            .alias('MA5'),

            # 10æ—¥å‡çº¿
            pl.col('æ”¶ç›˜')
            .rolling_mean(window_size=10, min_periods=1)
            .over('åç§°')
            .round(2)
            .alias('MA10'),

            # 20æ—¥å‡çº¿
            pl.col('æ”¶ç›˜')
            .rolling_mean(window_size=20, min_periods=1)
            .over('åç§°')
            .round(2)
            .alias('MA20'),
        ])

        print(f"æŒ‡æ•°å‡çº¿è®¡ç®—å®Œæˆï¼Œæ•°æ®è¡Œæ•°: {df_with_ma.height}")
        return df_with_ma

    # ==================== åˆ†é’Ÿæ•°æ®ç®¡ç†åŠŸèƒ½ ====================
    
    def _should_initialize_minute_data(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦éœ€è¦åˆå§‹åŒ–åˆ†é’Ÿæ•°æ®"""
        try:
            if not self.minute_metadata_path.exists():
                return True
                
            # æ£€æŸ¥æ•°æ®æ˜¯å¦è¶³å¤Ÿæ–°ï¼ˆæœ€è¿‘7å¤©å†…æœ‰æ•°æ®ï¼‰
            all_data = pl.read_parquet(self.minute_metadata_path)
            if all_data.is_empty():
                return True
                
            # è·å–æœ€æ–°æ—¥æœŸ
            latest_date = all_data['æ—¥æœŸ'].max()
            if latest_date is None:
                return True
                
            # æ£€æŸ¥æœ€æ–°æ—¥æœŸæ˜¯å¦åœ¨æœ€è¿‘7å¤©å†…
            from datetime import datetime, timedelta
            latest_date_obj = datetime.strptime(latest_date, '%Y-%m-%d').date()
            seven_days_ago = datetime.now().date() - timedelta(days=7)
            
            return latest_date_obj < seven_days_ago
            
        except Exception as e:
            print(f"âš ï¸ æ£€æŸ¥åˆ†é’Ÿæ•°æ®çŠ¶æ€å¤±è´¥: {e}")
            return True
    
    def _initialize_two_months_minute_data(self) -> bool:
        """åˆå§‹åŒ–è¿‘ä¸¤ä¸ªæœˆçš„åˆ†é’Ÿæ•°æ®"""
        try:
            from datetime import datetime, timedelta
            
            # è®¡ç®—è¿‘ä¸¤ä¸ªæœˆçš„æ—¥æœŸèŒƒå›´
            end_date = datetime.now().date()
            start_date = end_date - timedelta(days=60)  # è¿‘ä¸¤ä¸ªæœˆ
            
            print(f"ğŸ“Š åˆå§‹åŒ–åˆ†é’Ÿæ•°æ®æ—¥æœŸèŒƒå›´: {start_date} åˆ° {end_date}")
            
            # è·å–äº¤æ˜“æ—¥åˆ—è¡¨ï¼ˆæ’é™¤å‘¨æœ«ï¼‰
            trading_days = []
            current_date = start_date
            while current_date <= end_date:
                # æ’é™¤å‘¨æœ«
                if current_date.weekday() < 5:  # å‘¨ä¸€åˆ°å‘¨äº”
                    trading_days.append(current_date.strftime('%Y-%m-%d'))
                current_date += timedelta(days=1)
            
            print(f"ğŸ“… å…±éœ€è·å– {len(trading_days)} ä¸ªäº¤æ˜“æ—¥çš„åˆ†é’Ÿæ•°æ®")
            
            success_count = 0
            for i, trading_day in enumerate(trading_days):
                try:
                    print(f"ğŸ“ˆ è·å– {trading_day} åˆ†é’Ÿæ•°æ® ({i+1}/{len(trading_days)})...")
                    result = self._fetch_and_cache_market_minute_data_akshare(trading_day)
                    if result is not None:
                        success_count += 1
                except Exception as e:
                    print(f"âŒ è·å– {trading_day} æ•°æ®å¤±è´¥: {e}")
                    continue
            
            print(f"âœ… åˆ†é’Ÿæ•°æ®åˆå§‹åŒ–å®Œæˆï¼ŒæˆåŠŸè·å– {success_count}/{len(trading_days)} ä¸ªäº¤æ˜“æ—¥")
            return success_count > 0
            
        except Exception as e:
            print(f"âŒ åˆå§‹åŒ–åˆ†é’Ÿæ•°æ®å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def get_market_minute_data(self, target_date: str, aggregate_minutes: int = 5) -> Optional[pl.DataFrame]:
        """è·å–æŒ‡å®šæ—¥æœŸçš„å¸‚åœºåˆ†é’Ÿçº§æˆäº¤é¢æ•°æ®ï¼Œæ”¯æŒèšåˆ
        ä½¿ç”¨baostockè·å–çš„æ—¥çº¿æ•°æ®ï¼Œèšåˆä¸º5åˆ†é’Ÿé—´éš”
        
        Args:
            target_date: ç›®æ ‡æ—¥æœŸï¼Œæ ¼å¼ä¸º YYYY-MM-DD æˆ– YYYYMMDD
            aggregate_minutes: èšåˆåˆ†é’Ÿæ•°ï¼Œé»˜è®¤ä¸º5åˆ†é’Ÿ
            
        Returns:
            åŒ…å«åˆ†é’Ÿçº§å¸‚åœºæˆäº¤é¢æ•°æ®çš„DataFrameï¼Œåˆ—åŒ…æ‹¬ï¼š
            - æ—¥æœŸ: äº¤æ˜“æ—¥æœŸ
            - æ—¶é—´: èšåˆåçš„æ—¶é—´æˆ³
            - æ·±äº¤æ‰€æˆäº¤é¢: æ·±äº¤æ‰€èšåˆæˆäº¤é¢(äº¿å…ƒ)
            - æ²ªäº¤æ‰€æˆäº¤é¢: æ²ªäº¤æ‰€èšåˆæˆäº¤é¢(äº¿å…ƒ) 
            - åŒ—äº¤æ‰€æˆäº¤é¢: åŒ—äº¤æ‰€èšåˆæˆäº¤é¢(äº¿å…ƒ)
            - æ€»æˆäº¤é¢: ä¸‰ä¸ªäº¤æ˜“æ‰€æˆäº¤é¢ä¹‹å’Œ(äº¿å…ƒ)
        """
        try:
            # æ ‡å‡†åŒ–æ—¥æœŸæ ¼å¼
            if len(target_date) == 8:
                date_str = f"{target_date[:4]}-{target_date[4:6]}-{target_date[6:]}"
            else:
                date_str = target_date
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆå§‹åŒ–è¿‘ä¸¤ä¸ªæœˆçš„æ•°æ®
            if not self.minute_metadata_path.exists() or self._should_initialize_minute_data():
                print(f"ğŸ”„ æ•°æ®ä¸è¶³ï¼Œå¼€å§‹è·å–è¿‘ä¸¤ä¸ªæœˆçš„åˆ†é’Ÿæ•°æ®...")
                self._initialize_two_months_minute_data()
                
            # ä»ç»Ÿä¸€çš„åˆ†é’Ÿæ•°æ®æ–‡ä»¶ä¸­è¯»å–
            if self.minute_metadata_path.exists():
                print(f"ğŸ“Š ä»ç»Ÿä¸€æ–‡ä»¶åŠ è½½ {date_str} å¸‚åœºåˆ†é’Ÿæ•°æ®")
                all_minute_data = pl.read_parquet(self.minute_metadata_path)
                
                # ç­›é€‰æŒ‡å®šæ—¥æœŸçš„æ•°æ®
                minute_data = all_minute_data.filter(pl.col('æ—¥æœŸ') == date_str)
                
                if not minute_data.is_empty():
                    # æ£€æŸ¥æ•°æ®æ ¼å¼ï¼Œå¦‚æœæ˜¯æ—¥çº¿æ•°æ®åˆ™è·å–5åˆ†é’Ÿæ•°æ®
                    if 'æ—¶é—´' not in minute_data.columns:
                        print(f"ğŸ“Š æ£€æµ‹åˆ°æ—¥çº¿æ•°æ®æ ¼å¼ï¼Œè·å–5åˆ†é’Ÿæ•°æ®...")
                        minute_data = self._fetch_and_cache_market_minute_data_akshare(date_str)
                        # æºæ•°æ®å·²ä¸º5åˆ†é’Ÿç²’åº¦ï¼Œé™¤éè¯·æ±‚çš„èšåˆç²’åº¦ä¸æ˜¯5ï¼Œæ‰è¿›è¡Œèšåˆ
                        if minute_data is not None and aggregate_minutes and aggregate_minutes not in (0, 5) and aggregate_minutes > 1:
                            minute_data = self._aggregate_minute_data(minute_data, aggregate_minutes)
                    else:
                        # æºæ•°æ®å·²ä¸º5åˆ†é’Ÿï¼Œåªæœ‰å½“èšåˆç²’åº¦ä¸5ä¸åŒä¸”å¤§äº1æ—¶æ‰è¿›è¡Œèšåˆ
                        if aggregate_minutes and aggregate_minutes not in (0, 5) and aggregate_minutes > 1:
                            minute_data = self._aggregate_minute_data(minute_data, aggregate_minutes)
                    return minute_data
                else:
                    print(f"ğŸ“Š {date_str} å¸‚åœºåˆ†é’Ÿæ•°æ®ä¸å­˜åœ¨ï¼Œå¼€å§‹è·å–...")
                    raw_data = self._fetch_and_cache_market_minute_data_akshare(date_str)
                    if raw_data is not None and aggregate_minutes and aggregate_minutes not in (0, 5) and aggregate_minutes > 1:
                        return self._aggregate_minute_data(raw_data, aggregate_minutes)
                    return raw_data
            else:
                print(f"ğŸ“Š åˆ†é’Ÿæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå¼€å§‹è·å– {date_str} æ•°æ®...")
                raw_data = self._fetch_and_cache_market_minute_data_akshare(date_str)
                if raw_data is not None and aggregate_minutes and aggregate_minutes not in (0, 5) and aggregate_minutes > 1:
                    return self._aggregate_minute_data(raw_data, aggregate_minutes)
                return raw_data
                
        except Exception as e:
            print(f"âŒ è·å–å¸‚åœºåˆ†é’Ÿæ•°æ®å¤±è´¥: {e}")
            return None
    
    def _convert_daily_to_minute_data(self, daily_data: pl.DataFrame, date_str: str, aggregate_minutes: int = 5) -> pl.DataFrame:
        """å°†æ—¥çº¿æ•°æ®è½¬æ¢ä¸ºåˆ†é’Ÿæ•°æ®æ ¼å¼
        
        Args:
            daily_data: æ—¥çº¿æ•°æ®
            date_str: æ—¥æœŸå­—ç¬¦ä¸²
            aggregate_minutes: èšåˆåˆ†é’Ÿæ•°
            
        Returns:
            è½¬æ¢åçš„åˆ†é’Ÿæ•°æ®
        """
        try:
            print(f"ğŸ”„ å°†æ—¥çº¿æ•°æ®è½¬æ¢ä¸º {aggregate_minutes} åˆ†é’Ÿé—´éš”çš„åˆ†é’Ÿæ•°æ®...")
            
            # åˆ›å»º5åˆ†é’Ÿé—´éš”çš„æ—¶é—´ç‚¹
            morning_times = [
                f"{date_str} 09:30:00", f"{date_str} 09:35:00", f"{date_str} 09:40:00", f"{date_str} 09:45:00", f"{date_str} 09:50:00",
                f"{date_str} 09:55:00", f"{date_str} 10:00:00", f"{date_str} 10:05:00", f"{date_str} 10:10:00", f"{date_str} 10:15:00",
                f"{date_str} 10:20:00", f"{date_str} 10:25:00", f"{date_str} 10:30:00", f"{date_str} 10:35:00", f"{date_str} 10:40:00",
                f"{date_str} 10:45:00", f"{date_str} 10:50:00", f"{date_str} 10:55:00", f"{date_str} 11:00:00", f"{date_str} 11:05:00",
                f"{date_str} 11:10:00", f"{date_str} 11:15:00", f"{date_str} 11:20:00", f"{date_str} 11:25:00", f"{date_str} 11:30:00"
            ]
            afternoon_times = [
                f"{date_str} 13:00:00", f"{date_str} 13:05:00", f"{date_str} 13:10:00", f"{date_str} 13:15:00", f"{date_str} 13:20:00",
                f"{date_str} 13:25:00", f"{date_str} 13:30:00", f"{date_str} 13:35:00", f"{date_str} 13:40:00", f"{date_str} 13:45:00",
                f"{date_str} 13:50:00", f"{date_str} 13:55:00", f"{date_str} 14:00:00", f"{date_str} 14:05:00", f"{date_str} 14:10:00",
                f"{date_str} 14:15:00", f"{date_str} 14:20:00", f"{date_str} 14:25:00", f"{date_str} 14:30:00", f"{date_str} 14:35:00",
                f"{date_str} 14:40:00", f"{date_str} 14:45:00", f"{date_str} 14:50:00", f"{date_str} 14:55:00", f"{date_str} 15:00:00"
            ]
            all_times = morning_times + afternoon_times
            
            # è·å–æˆäº¤é¢åˆ—
            turnover_cols = [col for col in daily_data.columns if col.endswith('æˆäº¤é¢')]
            
            # åˆ›å»ºåˆ†é’Ÿæ•°æ®
            minute_data_list = []
            for row in daily_data.to_dicts():
                for time_str in all_times:
                    minute_row = {
                        'æ—¥æœŸ': row['æ—¥æœŸ'],
                        'æ—¶é—´': time_str
                    }
                    
                    # ä¸ºæ¯ä¸ªæˆäº¤é¢åˆ—åˆ†é…å¹³å‡åˆ°æ¯ä¸ªæ—¶é—´ç‚¹
                    for col in turnover_cols:
                        if col in row and row[col] is not None:
                            minute_row[col] = float(row[col]) / len(all_times)
                        else:
                            minute_row[col] = 0.0
                    
                    minute_data_list.append(minute_row)
            
            if minute_data_list:
                minute_df = pl.DataFrame(minute_data_list)
                
                # è®¡ç®—ç´¯è®¡æˆäº¤é¢
                for col in turnover_cols:
                    if col in minute_df.columns:
                        cumulative_col = col.replace('æˆäº¤é¢', 'ç´¯è®¡æˆäº¤é¢')
                        minute_df = minute_df.with_columns([
                            pl.col(col).cumsum().alias(cumulative_col)
                        ])
                
                print(f"âœ… æ—¥çº¿æ•°æ®è½¬æ¢å®Œæˆï¼Œç”Ÿæˆ {minute_df.height} æ¡åˆ†é’Ÿæ•°æ®")
                return minute_df
            else:
                print("âŒ æ—¥çº¿æ•°æ®è½¬æ¢å¤±è´¥")
                return daily_data
                
        except Exception as e:
            print(f"âŒ æ—¥çº¿æ•°æ®è½¬æ¢å¤±è´¥: {e}")
            return daily_data

    def _aggregate_minute_data(self, minute_data: pl.DataFrame, aggregate_minutes: int) -> pl.DataFrame:
        """å°†åˆ†é’Ÿæ•°æ®æŒ‰æŒ‡å®šåˆ†é’Ÿæ•°èšåˆ
        
        Args:
            minute_data: åŸå§‹åˆ†é’Ÿæ•°æ®
            aggregate_minutes: èšåˆåˆ†é’Ÿæ•°
            
        Returns:
            èšåˆåçš„æ•°æ®
        """
        try:
            print(f"ğŸ”„ å¼€å§‹è¿›è¡Œ {aggregate_minutes} åˆ†é’Ÿèšåˆ...")
            
            # ç¡®ä¿æ—¶é—´åˆ—æ˜¯datetimeç±»å‹
            if minute_data['æ—¶é—´'].dtype == pl.Utf8:
                minute_data = minute_data.with_columns([
                    pl.col('æ—¶é—´').str.strptime(pl.Datetime, '%Y-%m-%d %H:%M:%S').alias('æ—¶é—´')
                ])
            
            # åˆ›å»ºèšåˆæ—¶é—´æˆ³ï¼ˆå‘ä¸‹å–æ•´åˆ°èšåˆé—´éš”ï¼‰
            minute_data = minute_data.with_columns([
                (pl.col('æ—¶é—´').dt.truncate(f"{aggregate_minutes}m")).alias('èšåˆæ—¶é—´')
            ])
            
            # æŒ‰èšåˆæ—¶é—´åˆ†ç»„å¹¶æ±‚å’Œ
            # æ’é™¤"æ€»æˆäº¤é¢"ï¼ŒåªåŒ…å«å„äº¤æ˜“æ‰€çš„æˆäº¤é¢
            exchange_cols = [col for col in minute_data.columns if col.endswith('æˆäº¤é¢') and col != 'æ€»æˆäº¤é¢']
            
            aggregated_data = minute_data.group_by(['æ—¥æœŸ', 'èšåˆæ—¶é—´']).agg([
                pl.col('æ—¶é—´').first().alias('æ—¶é—´'),  # å–ç¬¬ä¸€ä¸ªæ—¶é—´ä½œä¸ºä»£è¡¨
                *[pl.col(col).sum().alias(col) for col in exchange_cols]
            ])
            
            # é‡æ–°è®¡ç®—æ€»æˆäº¤é¢ï¼ˆä½¿ç”¨å„äº¤æ˜“æ‰€æˆäº¤é¢ä¹‹å’Œï¼‰
            aggregated_data = aggregated_data.with_columns([
                pl.sum_horizontal([pl.col(col) for col in exchange_cols]).alias('æ€»æˆäº¤é¢')
            ])
            
            # æŒ‰æ—¶é—´æ’åº
            aggregated_data = aggregated_data.sort('èšåˆæ—¶é—´')
            
            # è®¡ç®—ç´¯è®¡æˆäº¤é¢
            aggregated_data = aggregated_data.with_columns([
                pl.col('æ·±äº¤æ‰€æˆäº¤é¢').cumsum().alias('æ·±äº¤æ‰€ç´¯è®¡æˆäº¤é¢'),
                pl.col('æ²ªäº¤æ‰€æˆäº¤é¢').cumsum().alias('æ²ªäº¤æ‰€ç´¯è®¡æˆäº¤é¢'),
                pl.col('åŒ—äº¤æ‰€æˆäº¤é¢').cumsum().alias('åŒ—äº¤æ‰€ç´¯è®¡æˆäº¤é¢'),
                pl.col('æ€»æˆäº¤é¢').cumsum().alias('æ€»ç´¯è®¡æˆäº¤é¢')
            ])
            
            # èšåˆæ—¶é—´åˆ—å·²ç»æ˜¯æ­£ç¡®çš„æ—¶é—´ï¼Œä¸éœ€è¦é‡å‘½å
            
            print(f"âœ… {aggregate_minutes} åˆ†é’Ÿèšåˆå®Œæˆï¼Œä» {minute_data.height} æ¡è®°å½•èšåˆä¸º {aggregated_data.height} æ¡è®°å½•")
            return aggregated_data
            
        except Exception as e:
            print(f"âŒ åˆ†é’Ÿæ•°æ®èšåˆå¤±è´¥: {e}")
            return minute_data
    
    def _fetch_and_cache_market_minute_data_akshare(self, date_str: str) -> Optional[pl.DataFrame]:
        """ä½¿ç”¨akshareè·å–å¹¶ç¼“å­˜æŒ‡å®šæ—¥æœŸçš„å¸‚åœº5åˆ†é’Ÿæ•°æ®"""
        try:
            print(f"ğŸ”„ å¼€å§‹è·å– {date_str} å¸‚åœº5åˆ†é’Ÿæ•°æ®...")
            # å®šä¹‰ç›®æ ‡æ—¶é—´èŒƒå›´
            start_dt = f"{date_str} 09:30:00"
            end_dt = f"{date_str} 15:00:00"

            # è·å–ä¸‰å¤§æŒ‡æ•°çš„5åˆ†é’Ÿæ•°æ®
            print("ğŸ“ˆ è·å–æŒ‡æ•°5åˆ†é’Ÿåˆ†æ—¶æ•°æ®...")
            def fetch_min_df(symbol: str) -> pd.DataFrame:
                df = self._fetch_index_minute_with_fallback(symbol, start_dt, end_dt, period="5")
                if df is None or df.empty:
                    print(f"âŒ è·å– {symbol} 5åˆ†é’Ÿæ•°æ®å¤±è´¥: æ•°æ®ä¸ºç©º")
                    return pd.DataFrame()
                return df

            sh_min = fetch_min_df("000001")  # ä¸Šè¯æŒ‡æ•°
            sz_min = fetch_min_df("399001")  # æ·±è¯æˆæŒ‡
            bj_min = fetch_min_df("899050")  # åŒ—è¯50ï¼ˆå¯é€‰ï¼‰

            # å¦‚æœåˆ†æ—¶æ•°æ®ä¸å¯ç”¨ï¼Œåˆ™å›é€€åˆ°æ—§é€»è¾‘
            if (sh_min is None or sh_min.empty) and (sz_min is None or sz_min.empty):
                print("âš ï¸ åˆ†æ—¶æ•°æ®ä¸å¯ç”¨ï¼Œå›é€€åˆ°æ—¥çº¿ä¼°ç®—é€»è¾‘")
                # å›é€€ï¼šä½¿ç”¨æ—§å®ç°ï¼ˆè¿”å›Noneç”±ä¸Šå±‚å†³å®šå¦‚ä½•å¤„ç†ï¼‰
                return None

            # åªä¿ç•™ç›®æ ‡æ—¥æœŸçš„æ•°æ®ï¼Œå¹¶è½¬æ¢ä¸ºäº¿å…ƒ
            def prep_minute(df: pd.DataFrame) -> pl.DataFrame:
                if df is None or df.empty:
                    return pl.DataFrame({"æ—¶é—´": [], "æˆäº¤é¢": []})
                df = df.copy()
                # è¿‡æ»¤å½“å¤©
                df["æ—¶é—´"] = pd.to_datetime(df["æ—¶é—´"])  # pandas
                df = df[(df["æ—¶é—´"].dt.strftime('%Y-%m-%d') == date_str)]
                if df.empty:
                    return pl.DataFrame({"æ—¶é—´": [], "æˆäº¤é¢": []})
                # è½¬æ¢ä¸ºpolarså¹¶å•ä½æ¢ç®—ä¸ºäº¿å…ƒ
                pl_df = pl.from_pandas(df[["æ—¶é—´", "æˆäº¤é¢"]])
                pl_df = pl_df.with_columns([
                    pl.col("æˆäº¤é¢").cast(pl.Float64) / 100000000
                ])
                return pl_df

            sh_pl = prep_minute(sh_min).rename({"æˆäº¤é¢": "æ²ªäº¤æ‰€æˆäº¤é¢"})
            sz_pl = prep_minute(sz_min).rename({"æˆäº¤é¢": "æ·±äº¤æ‰€æˆäº¤é¢"})
            bj_pl = prep_minute(bj_min).rename({"æˆäº¤é¢": "åŒ—äº¤æ‰€æˆäº¤é¢"})

            # åˆå¹¶åˆ°ç»Ÿä¸€çš„æ—¶é—´è½´ï¼ˆå¤–è¿æ¥ï¼‰
            merged_data = None
            for df in [sh_pl, sz_pl, bj_pl]:
                if df is None or df.is_empty():
                    continue
                if merged_data is None:
                    merged_data = df
                else:
                    merged_data = merged_data.join(df, on="æ—¶é—´", how="outer")

            if merged_data is None or merged_data.is_empty():
                print("âŒ åˆå¹¶åçš„åˆ†é’Ÿæ•°æ®ä¸ºç©º")
                return None

            # å¡«å……ç¼ºå¤±å€¼ä¸º0
            for col in ["æ²ªäº¤æ‰€æˆäº¤é¢", "æ·±äº¤æ‰€æˆäº¤é¢", "åŒ—äº¤æ‰€æˆäº¤é¢"]:
                if col not in merged_data.columns:
                    merged_data = merged_data.with_columns([pl.lit(0.0).alias(col)])
                else:
                    merged_data = merged_data.with_columns([pl.col(col).fill_null(0.0).alias(col)])

            # è®¡ç®—æ€»æˆäº¤é¢ï¼ˆäº¿å…ƒï¼‰
            merged_data = merged_data.with_columns([
                (pl.col("æ²ªäº¤æ‰€æˆäº¤é¢") + pl.col("æ·±äº¤æ‰€æˆäº¤é¢") + pl.col("åŒ—äº¤æ‰€æˆäº¤é¢")).alias("æ€»æˆäº¤é¢")
            ])

            # ä¸ºäº†ä¸æ—¥æ€»é¢å¯¹é½ï¼ŒæŒ‰æ—¥çº¿æ€»é¢è¿›è¡Œç¼©æ”¾æ ¡å‡†
            print("ğŸ“ˆ è·å–å½“æ—¥æ—¥çº¿æŒ‡æ•°æˆäº¤é¢ç”¨äºç¼©æ”¾...")
            sh_daily = ak.index_zh_a_hist(symbol='000001', period='daily', start_date=date_str.replace('-', ''), end_date=date_str.replace('-', ''))
            sz_daily = ak.index_zh_a_hist(symbol='399001', period='daily', start_date=date_str.replace('-', ''), end_date=date_str.replace('-', ''))
            bj_daily = None
            try:
                bj_daily = ak.index_zh_a_hist(symbol='899050', period='daily', start_date=date_str.replace('-', ''), end_date=date_str.replace('-', ''))
            except Exception:
                bj_daily = None

            target_total = 0.0
            if sh_daily is not None and not sh_daily.empty:
                target_total += float(sh_daily['æˆäº¤é¢'].iloc[-1]) / 100000000
            if sz_daily is not None and not sz_daily.empty:
                target_total += float(sz_daily['æˆäº¤é¢'].iloc[-1]) / 100000000
            if bj_daily is not None and not bj_daily.empty and 'æˆäº¤é¢' in bj_daily.columns:
                target_total += float(bj_daily['æˆäº¤é¢'].iloc[-1]) / 100000000

            # åˆ†é’Ÿåˆè®¡
            minute_sum = float(merged_data.select(pl.col("æ€»æˆäº¤é¢").sum()).to_series()[0]) if "æ€»æˆäº¤é¢" in merged_data.columns else 0.0
            scale_factor = (target_total / minute_sum) if minute_sum and minute_sum > 0 else 1.0
            if abs(scale_factor - 1.0) > 0.05:
                print(f"âš–ï¸ æŒ‰æ—¥çº¿æ€»é¢æ ¡å‡†åˆ†é’Ÿæ•°æ®: scale={scale_factor:.4f} (åˆ†é’Ÿåˆè®¡:{minute_sum:.2f}äº¿, æ—¥çº¿ç›®æ ‡:{target_total:.2f}äº¿)")
            merged_data = merged_data.with_columns([
                (pl.col("æ²ªäº¤æ‰€æˆäº¤é¢") * scale_factor).alias("æ²ªäº¤æ‰€æˆäº¤é¢"),
                (pl.col("æ·±äº¤æ‰€æˆäº¤é¢") * scale_factor).alias("æ·±äº¤æ‰€æˆäº¤é¢"),
                (pl.col("åŒ—äº¤æ‰€æˆäº¤é¢") * scale_factor).alias("åŒ—äº¤æ‰€æˆäº¤é¢"),
            ])
            merged_data = merged_data.with_columns([
                (pl.col("æ²ªäº¤æ‰€æˆäº¤é¢") + pl.col("æ·±äº¤æ‰€æˆäº¤é¢") + pl.col("åŒ—äº¤æ‰€æˆäº¤é¢")).alias("æ€»æˆäº¤é¢")
            ])

            # æ·»åŠ æ—¥æœŸåˆ—å¹¶æ’åº
            merged_data = merged_data.with_columns([
                pl.lit(date_str).alias('æ—¥æœŸ')
            ])
            merged_data = merged_data.sort('æ—¶é—´')

            # è®¡ç®—ç´¯è®¡æˆäº¤é¢ - æŒ‰æ—¥æœŸåˆ†ç»„ç´¯è®¡
            merged_data = merged_data.with_columns([
                pl.col('æ·±äº¤æ‰€æˆäº¤é¢').cumsum().over('æ—¥æœŸ').alias('æ·±äº¤æ‰€ç´¯è®¡æˆäº¤é¢'),
                pl.col('æ²ªäº¤æ‰€æˆäº¤é¢').cumsum().over('æ—¥æœŸ').alias('æ²ªäº¤æ‰€ç´¯è®¡æˆäº¤é¢'),
                pl.col('åŒ—äº¤æ‰€æˆäº¤é¢').cumsum().over('æ—¥æœŸ').alias('åŒ—äº¤æ‰€ç´¯è®¡æˆäº¤é¢'),
                pl.col('æ€»æˆäº¤é¢').cumsum().over('æ—¥æœŸ').alias('æ€»ç´¯è®¡æˆäº¤é¢')
            ])
            
            # è¯»å–ç°æœ‰æ•°æ®å¹¶åˆå¹¶
            if self.minute_metadata_path.exists():
                existing_data = pl.read_parquet(self.minute_metadata_path)
                # åˆ é™¤åŒä¸€å¤©çš„æ•°æ®ï¼ˆé¿å…é‡å¤ï¼‰
                existing_data = existing_data.filter(pl.col('æ—¥æœŸ') != date_str)
                
                # ç¡®ä¿åˆ—ç»“æ„ä¸€è‡´
                existing_cols = set(existing_data.columns)
                new_cols = set(merged_data.columns)
                
                # å¦‚æœåˆ—ç»“æ„ä¸åŒï¼Œéœ€è¦ç»Ÿä¸€åˆ—ç»“æ„
                if existing_cols != new_cols:
                    print(f"âš ï¸ åˆ—ç»“æ„ä¸ä¸€è‡´ï¼Œç°æœ‰åˆ—: {existing_cols}, æ–°åˆ—: {new_cols}")
                    
                    # ä¸ºç¼ºå¤±çš„åˆ—æ·»åŠ é»˜è®¤å€¼
                    for col in new_cols - existing_cols:
                        existing_data = existing_data.with_columns([
                            pl.lit(0.0).alias(col)
                        ])
                    
                    for col in existing_cols - new_cols:
                        merged_data = merged_data.with_columns([
                            pl.lit(0.0).alias(col)
                        ])
                    
                    # ç¡®ä¿åˆ—é¡ºåºä¸€è‡´
                    merged_data = merged_data.select(existing_data.columns)
                
                # åˆå¹¶æ–°æ—§æ•°æ®
                updated_data = pl.concat([existing_data, merged_data], how="vertical")
            else:
                updated_data = merged_data
            
            # å»é‡å¤„ç† - æŒ‰æ—¶é—´å’Œæ—¥æœŸå»é‡
            updated_data = updated_data.unique(subset=['æ—¥æœŸ', 'æ—¶é—´'], keep='first')
            print(f"ğŸ”„ å»é‡å¤„ç†å®Œæˆï¼Œä¿ç•™ {updated_data.height} æ¡è®°å½•")
            
            # ä¿å­˜åˆ°ç»Ÿä¸€æ–‡ä»¶
            updated_data.write_parquet(self.minute_metadata_path)
            
            print(f"âœ… {date_str} å¸‚åœº5åˆ†é’Ÿæ•°æ®è·å–å¹¶ç¼“å­˜æˆåŠŸï¼Œå…±{merged_data.height}æ¡è®°å½•")
            return merged_data
            
        except Exception as e:
            print(f"âŒ è·å–å¹¶ç¼“å­˜å¸‚åœº5åˆ†é’Ÿæ•°æ®å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None

    def _fetch_and_cache_market_minute_data(self, date_str: str) -> Optional[pl.DataFrame]:
        """è·å–å¹¶ç¼“å­˜æŒ‡å®šæ—¥æœŸçš„å¸‚åœºåˆ†é’Ÿæ•°æ®"""
        try:
            print(f"ğŸ”„ å¼€å§‹è·å– {date_str} å¸‚åœºåˆ†é’Ÿæ•°æ®...")
            
            # äº¤æ˜“æ‰€æŒ‡æ•°ä»£ç æ˜ å°„
            exchange_indices = {
                'æ·±äº¤æ‰€': '399001',  # æ·±è¯æˆæŒ‡
                'æ²ªäº¤æ‰€': '000001',  # ä¸Šè¯æŒ‡æ•°
                'åŒ—äº¤æ‰€': '899050'   # åŒ—è¯50
            }
            
            all_minute_data = {}
            
            # è·å–å„äº¤æ˜“æ‰€æŒ‡æ•°åˆ†é’Ÿæ•°æ®
            for exchange, code in exchange_indices.items():
                try:
                    print(f"  ğŸ“ˆ è·å–{exchange}æŒ‡æ•°{code}åˆ†é’Ÿæ•°æ®...")
                    
                    # ä½¿ç”¨akshareè·å–åˆ†é’Ÿæ•°æ®
                    minute_df = ak.index_zh_a_hist_min_em(
                        symbol=code,
                        period='1',  # 1åˆ†é’ŸKçº¿
                        start_date=date_str.replace('-', ''),
                        end_date=date_str.replace('-', '')
                    )
                    
                    if minute_df is not None and not minute_df.empty:
                        # è½¬æ¢ä¸ºpolars
                        minute_pl = pl.from_pandas(minute_df)
                        
                        # æ ‡å‡†åŒ–åˆ—åå¹¶è®¡ç®—æˆäº¤é¢
                        if 'æ—¶é—´' in minute_pl.columns and 'æˆäº¤é‡' in minute_pl.columns:
                            # æˆäº¤é¢ = æˆäº¤é‡ * å¹³å‡ä»·æ ¼ï¼Œè¿™é‡Œç”¨æ”¶ç›˜ä»·è¿‘ä¼¼
                            if 'æ”¶ç›˜' in minute_pl.columns:
                                minute_pl = minute_pl.with_columns([
                                    (pl.col('æˆäº¤é‡') * pl.col('æ”¶ç›˜') / 100000000).alias(f'{exchange}æˆäº¤é¢')
                                ])
                            else:
                                # å¦‚æœæ²¡æœ‰ä»·æ ¼æ•°æ®ï¼Œä½¿ç”¨æˆäº¤é‡ä½œä¸ºæˆäº¤é¢çš„ä»£ç†
                                minute_pl = minute_pl.with_columns([
                                    (pl.col('æˆäº¤é‡') / 100000000).alias(f'{exchange}æˆäº¤é¢')
                                ])
                            
                            all_minute_data[exchange] = minute_pl.select(['æ—¶é—´', f'{exchange}æˆäº¤é¢'])
                            print(f"  âœ… {exchange}æ•°æ®è·å–æˆåŠŸï¼Œ{minute_pl.height}æ¡è®°å½•")
                        else:
                            print(f"  âš ï¸ {exchange}æ•°æ®æ ¼å¼å¼‚å¸¸ï¼Œè·³è¿‡")
                    else:
                        print(f"  âŒ {exchange}æ•°æ®è·å–å¤±è´¥æˆ–ä¸ºç©º")
                        
                except Exception as e:
                    print(f"  âŒ è·å–{exchange}æ•°æ®å¤±è´¥: {e}")
                    continue
            
            if not all_minute_data:
                print(f"âŒ æœªèƒ½è·å–åˆ°ä»»ä½•äº¤æ˜“æ‰€çš„åˆ†é’Ÿæ•°æ®")
                return None
            
            # åˆå¹¶æ‰€æœ‰äº¤æ˜“æ‰€çš„æ•°æ®
            print(f"ğŸ”— åˆå¹¶ {len(all_minute_data)} ä¸ªäº¤æ˜“æ‰€çš„åˆ†é’Ÿæ•°æ®...")
            
            # ä»¥æ—¶é—´ä¸ºåŸºå‡†è¿›è¡Œå¤–è¿æ¥
            merged_data = None
            for exchange, data in all_minute_data.items():
                if merged_data is None:
                    merged_data = data
                else:
                    merged_data = merged_data.join(data, on='æ—¶é—´', how='outer')
            
            if merged_data is None:
                return None
            
            # å¡«å……ç¼ºå¤±å€¼ä¸º0å¹¶è®¡ç®—æ€»æˆäº¤é¢
            # æ’é™¤"æ€»æˆäº¤é¢"ï¼ŒåªåŒ…å«å„äº¤æ˜“æ‰€çš„æˆäº¤é¢
            exchange_cols = [col for col in merged_data.columns if col.endswith('æˆäº¤é¢') and col != 'æ€»æˆäº¤é¢']
            
            # å¡«å……ç©ºå€¼ä¸º0
            for col in exchange_cols:
                merged_data = merged_data.with_columns([
                    pl.col(col).fill_null(0).alias(col)
                ])
            
            # è®¡ç®—æ€»æˆäº¤é¢ï¼ˆä½¿ç”¨å„äº¤æ˜“æ‰€æˆäº¤é¢ä¹‹å’Œï¼‰
            merged_data = merged_data.with_columns([
                pl.sum_horizontal([pl.col(col) for col in exchange_cols]).alias('æ€»æˆäº¤é¢')
            ])
            
            # æ·»åŠ æ—¥æœŸåˆ—
            merged_data = merged_data.with_columns([
                pl.lit(date_str).alias('æ—¥æœŸ')
            ])
            
            # æŒ‰æ—¶é—´æ’åº
            merged_data = merged_data.sort('æ—¶é—´')
            
            # è¯»å–ç°æœ‰æ•°æ®å¹¶åˆå¹¶
            if self.minute_metadata_path.exists():
                existing_data = pl.read_parquet(self.minute_metadata_path)
                # åˆ é™¤åŒä¸€å¤©çš„æ•°æ®ï¼ˆé¿å…é‡å¤ï¼‰
                existing_data = existing_data.filter(pl.col('æ—¥æœŸ') != date_str)
                
                # ç¡®ä¿åˆ—ç»“æ„ä¸€è‡´
                existing_cols = set(existing_data.columns)
                new_cols = set(merged_data.columns)
                
                # å¦‚æœåˆ—ç»“æ„ä¸åŒï¼Œéœ€è¦ç»Ÿä¸€åˆ—ç»“æ„
                if existing_cols != new_cols:
                    print(f"âš ï¸ åˆ—ç»“æ„ä¸ä¸€è‡´ï¼Œç°æœ‰åˆ—: {existing_cols}, æ–°åˆ—: {new_cols}")
                    
                    # ä¸ºç¼ºå¤±çš„åˆ—æ·»åŠ é»˜è®¤å€¼
                    for col in new_cols - existing_cols:
                        existing_data = existing_data.with_columns([
                            pl.lit(0.0).alias(col)
                        ])
                    
                    for col in existing_cols - new_cols:
                        merged_data = merged_data.with_columns([
                            pl.lit(0.0).alias(col)
                        ])
                    
                    # ç¡®ä¿åˆ—é¡ºåºä¸€è‡´
                    merged_data = merged_data.select(existing_data.columns)
                
                # åˆå¹¶æ–°æ—§æ•°æ®
                updated_data = pl.concat([existing_data, merged_data], how="vertical")
            else:
                updated_data = merged_data
            
            # å»é‡å¤„ç† - æŒ‰æ—¶é—´å’Œæ—¥æœŸå»é‡
            updated_data = updated_data.unique(subset=['æ—¥æœŸ', 'æ—¶é—´'], keep='first')
            print(f"ğŸ”„ å»é‡å¤„ç†å®Œæˆï¼Œä¿ç•™ {updated_data.height} æ¡è®°å½•")
            
            # ä¿å­˜åˆ°ç»Ÿä¸€æ–‡ä»¶
            updated_data.write_parquet(self.minute_metadata_path)
            
            print(f"âœ… {date_str} å¸‚åœºåˆ†é’Ÿæ•°æ®è·å–å¹¶ç¼“å­˜æˆåŠŸï¼Œå…±{merged_data.height}æ¡è®°å½•")
            return merged_data
            
        except Exception as e:
            print(f"âŒ è·å–å¹¶ç¼“å­˜å¸‚åœºåˆ†é’Ÿæ•°æ®å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def get_market_volume_comparison(self, current_date: str, previous_date: str = None) -> Optional[Dict]:
        """è·å–å¸‚åœºé‡èƒ½å¯¹æ¯”æ•°æ®
        
        Args:
            current_date: å½“å‰æ—¥æœŸ (YYYY-MM-DD)
            previous_date: å¯¹æ¯”æ—¥æœŸï¼Œé»˜è®¤ä¸ºå‰ä¸€äº¤æ˜“æ—¥ (YYYY-MM-DD)
            
        Returns:
            åŒ…å«é‡èƒ½å¯¹æ¯”æ•°æ®çš„å­—å…¸ï¼š
            {
                'current_data': å½“æ—¥åˆ†é’Ÿæ•°æ®,
                'previous_data': å‰æ—¥åˆ†é’Ÿæ•°æ®,
                'comparison_data': å¯¹æ¯”ç»Ÿè®¡æ•°æ®
            }
        """
        try:
            # è·å–å½“æ—¥æ•°æ®ï¼ˆä½¿ç”¨5åˆ†é’Ÿèšåˆï¼‰
            current_data = self.get_market_minute_data(current_date, aggregate_minutes=5)
            if current_data is None:
                print(f"âŒ æ— æ³•è·å– {current_date} çš„åˆ†é’Ÿæ•°æ®")
                return None
            
            # å¦‚æœæ²¡æœ‰æŒ‡å®šå¯¹æ¯”æ—¥æœŸï¼Œä½¿ç”¨å‰ä¸€äº¤æ˜“æ—¥
            if previous_date is None:
                previous_date = self._get_previous_trading_day(current_date)
            
            # è·å–å‰æ—¥æ•°æ®ï¼ˆä½¿ç”¨5åˆ†é’Ÿèšåˆï¼‰
            previous_data = self.get_market_minute_data(previous_date, aggregate_minutes=5)
            if previous_data is None:
                print(f"âŒ æ— æ³•è·å– {previous_date} çš„åˆ†é’Ÿæ•°æ®")
                return None
            
            # è®¡ç®—å¯¹æ¯”ç»Ÿè®¡ - ä½¿ç”¨ç´¯è®¡æˆäº¤é¢
            current_total = current_data['æ€»ç´¯è®¡æˆäº¤é¢'].max() if 'æ€»ç´¯è®¡æˆäº¤é¢' in current_data.columns else current_data['æ€»æˆäº¤é¢'].sum()
            previous_total = previous_data['æ€»ç´¯è®¡æˆäº¤é¢'].max() if 'æ€»ç´¯è®¡æˆäº¤é¢' in previous_data.columns else previous_data['æ€»æˆäº¤é¢'].sum()
            change_amount = current_total - previous_total
            change_pct = (change_amount / previous_total * 100) if previous_total > 0 else 0
            
            comparison_data = {
                'current_total': float(current_total),
                'previous_total': float(previous_total),
                'change_amount': float(change_amount),
                'change_pct': float(change_pct),
                'current_date': current_date,
                'previous_date': previous_date
            }
            
            print(f"ğŸ“Š å¸‚åœºé‡èƒ½å¯¹æ¯”: {current_date}({current_total:.2f}äº¿) vs {previous_date}({previous_total:.2f}äº¿), å˜åŒ–: {change_amount:.2f}äº¿({change_pct:.2f}%)")
            
            return {
                'current_data': current_data,
                'previous_data': previous_data,
                'comparison_data': comparison_data
            }
            
        except Exception as e:
            print(f"âŒ è·å–å¸‚åœºé‡èƒ½å¯¹æ¯”æ•°æ®å¤±è´¥: {e}")
            return None
    
    def _get_previous_trading_day(self, date_str: str) -> str:
        """è·å–å‰ä¸€ä¸ªäº¤æ˜“æ—¥"""
        try:
            current_date = datetime.strptime(date_str, '%Y-%m-%d').date()
            
            # ç®€å•åœ°å‡å»1-3å¤©æ¥æ‰¾å‰ä¸€ä¸ªäº¤æ˜“æ—¥
            for i in range(1, 8):  # æœ€å¤šå¾€å‰æ‰¾ä¸€å‘¨
                prev_date = current_date - timedelta(days=i)
                
                # è·³è¿‡å‘¨æœ«
                if prev_date.weekday() < 5:  # å‘¨ä¸€åˆ°å‘¨äº”
                    return prev_date.strftime('%Y-%m-%d')
            
            # å¦‚æœæ‰¾ä¸åˆ°ï¼Œè¿”å›ä¸€å‘¨å‰
            return (current_date - timedelta(days=7)).strftime('%Y-%m-%d')
            
        except Exception as e:
            print(f"âŒ è®¡ç®—å‰ä¸€äº¤æ˜“æ—¥å¤±è´¥: {e}")
            return (datetime.strptime(date_str, '%Y-%m-%d').date() - timedelta(days=1)).strftime('%Y-%m-%d')
    
